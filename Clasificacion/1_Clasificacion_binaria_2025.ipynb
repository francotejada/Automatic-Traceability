{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francotejada/Automatic-Traceability/blob/main/Clasificacion/1_Clasificacion_binaria_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNvs5noJlVz3"
      },
      "source": [
        "\n",
        "# install the requirements\n",
        "!pip install spacy\n",
        "#!python -m spacy download es_core_news_md\n",
        "#!python -m spacy download en_core_web_md\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "!pip install torch\n",
        "!pip install transformers\n",
        "#!pip install contextualSpellCheck\n",
        "#!pip install textblob\n",
        "!pip install wordninja"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j7U-l1alwCV"
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from transformers import AutoTokenizer # BertTokenizer\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification #BertForSequenceClassification\n",
        "\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrLGKfVUupfP",
        "outputId": "5668d25a-27ca-4c3a-a995-6f762981de26"
      },
      "source": [
        "# TEST\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "# Function checks if the string\n",
        "# contains any special character\n",
        "def check_token_accepted(string):\n",
        "\n",
        "    special_characters = \"!@#$%^&*()-+?_=,<>\\/\"\n",
        "    s=string\n",
        "    # Example: $tackoverflow\n",
        "\n",
        "    if any(c in special_characters for c in s):\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "def clean_tokens_special_char(string):\n",
        "    out = ''\n",
        "    for word in string.split():\n",
        "        if check_token_accepted(word) == 1:\n",
        "           out = out + word + ' '\n",
        "    return(out)\n",
        "\n",
        "sen = 'Newline escape has the wrong order of \\n\\r CandidateStep value.replaceAll(\"\"(\\n)|(\\r\\n)\"\", System.getProperty(\"\"line.separator\"\")); must be: value.replaceAll(\"\"(\\n)|(\\n\\r)\"\", System.getProperty(\"\"line.separator\"\"));'\n",
        "sen1 = \"that don't need to be in a stack\"\n",
        "print(clean_tokens_special_char(sen))\n",
        "\n",
        "for t in sen1.split(\" \"):\n",
        "  print(t)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Newline escape has the wrong order of CandidateStep must be: \n",
            "that\n",
            "don't\n",
            "need\n",
            "to\n",
            "be\n",
            "in\n",
            "a\n",
            "stack\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnG6qmikmxgk"
      },
      "source": [
        "import re\n",
        "from typing import List\n",
        "import wordninja\n",
        "import pandas as pd\n",
        "\n",
        "import spacy\n",
        "from spacy.tokens import Doc\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "class SpacyPreprocessor:\n",
        "    def __init__(\n",
        "        self,\n",
        "        spacy_model=None,\n",
        "        #remove_numbers=False,\n",
        "        remove_numbers=True,\n",
        "        remove_special=True,\n",
        "        pos_to_remove=None,\n",
        "        #remove_stopwords=False,\n",
        "        remove_stopwords=True,\n",
        "        lemmatize=False,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Preprocesses text using spaCy\n",
        "        :param remove_numbers: Whether to remove numbers from text\n",
        "        :param remove_stopwords: Whether to remove stopwords from text\n",
        "        :param remove_special: Whether to remove special characters (including numbers)\n",
        "        :param pos_to_remove: list of PoS tags to remove\n",
        "        :param lemmatize:  Whether to apply lemmatization\n",
        "        \"\"\"\n",
        "\n",
        "        self._remove_numbers = remove_numbers\n",
        "        self._pos_to_remove = pos_to_remove\n",
        "        self._remove_stopwords = remove_stopwords\n",
        "        self._remove_special = remove_special\n",
        "        self._lemmatize = lemmatize\n",
        "\n",
        "        if not spacy_model:\n",
        "            self.model = spacy.load(\"en_core_web_sm\")\n",
        "        else:\n",
        "            self.model = spacy_model\n",
        "\n",
        "    @staticmethod\n",
        "    def download_spacy_model(model=\"en_core_web_sm\"):\n",
        "        print(f\"Downloading spaCy model {model}\")\n",
        "        spacy.cli.download(model)\n",
        "        print(f\"Finished downloading model\")\n",
        "\n",
        "    @staticmethod\n",
        "    def load_model(model=\"en_core_web_sm\"):\n",
        "        return spacy.load(model, disable=[\"ner\", \"parser\"])\n",
        "\n",
        "    def tokenize(self, text) -> List[str]:\n",
        "        \"\"\"\n",
        "        Tokenize text using a spaCy pipeline\n",
        "        :param text: Text to tokenize\n",
        "        :return: list of str\n",
        "        \"\"\"\n",
        "        doc = self.model(text)\n",
        "        return [token.text for token in doc]\n",
        "\n",
        "    def preprocess_text(self, text) -> str:\n",
        "        \"\"\"\n",
        "        Runs a spaCy pipeline and removes unwanted parts from text\n",
        "        :param text: text string to clean\n",
        "        :return: str, clean text\n",
        "        \"\"\"\n",
        "        doc = self.model(text)\n",
        "        return self.__clean(doc)\n",
        "\n",
        "    def preprocess_text2(self, text) -> str:\n",
        "        \"\"\"\n",
        "        Runs a spaCy pipeline and removes unwanted parts from text\n",
        "        :param text: text string to clean\n",
        "        :return: str, clean text\n",
        "        \"\"\"\n",
        "        doc = self.model(text)\n",
        "        return self.__clean2(doc)\n",
        "\n",
        "    def preprocess_text_list(self, texts=List[str]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Runs a spaCy pipeline and removes unwantes parts from a list of text.\n",
        "        Leverages spaCy's `pipe` for faster batch processing.\n",
        "        :param texts: List of texts to clean\n",
        "        :return: List of clean texts\n",
        "        \"\"\"\n",
        "        clean_texts = []\n",
        "        for doc in tqdm(self.model.pipe(texts)):\n",
        "            clean_texts.append(self.__clean(doc))\n",
        "\n",
        "        return clean_texts\n",
        "\n",
        "    def __clean(self, doc: Doc) -> str:\n",
        "\n",
        "        tokens = []\n",
        "        # POS Tags removal\n",
        "        if self._pos_to_remove:\n",
        "            for token in doc:\n",
        "                if token.pos_ not in self._pos_to_remove:\n",
        "                    tokens.append(token)\n",
        "        else:\n",
        "            tokens = doc\n",
        "\n",
        "        # Remove Numbers\n",
        "        if self._remove_numbers:\n",
        "            tokens = [\n",
        "                token for token in tokens if not (token.like_num or token.is_currency)\n",
        "            ]\n",
        "\n",
        "        # Remove Stopwords\n",
        "        if self._remove_stopwords:\n",
        "            tokens = [token for token in tokens if not token.is_stop]\n",
        "        # remove unwanted tokens\n",
        "        tokens = [\n",
        "            token\n",
        "            for token in tokens\n",
        "            if not (\n",
        "                token.is_punct or token.is_space or token.is_quote or token.is_bracket #or len(token) > 30\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        # Remove empty tokens\n",
        "        tokens = [token for token in tokens if token.text.strip() != \"\"]\n",
        "\n",
        "        # Lemmatize\n",
        "        if self._lemmatize:\n",
        "            text = \" \".join([token.lemma_ for token in tokens])\n",
        "        else:\n",
        "            text = \" \".join([token.text for token in tokens])\n",
        "\n",
        "        if self._remove_special:\n",
        "            # Remove non alphabetic characters\n",
        "            text = re.sub(r\"[^a-zA-Z\\']\", \" \", text)\n",
        "        # remove non-Unicode characters\n",
        "        text = re.sub(r\"[^\\x00-\\x7F]+\", \"\", text)\n",
        "\n",
        "        text = text.lower()\n",
        "\n",
        "        return text\n",
        "\n",
        "    def __clean2(self, doc: Doc) -> str:\n",
        "\n",
        "        tokens = []\n",
        "\n",
        "        tokens = doc\n",
        "\n",
        "        tokens = [\n",
        "                token for token in tokens if not (token.like_num or token.is_currency)\n",
        "        ]\n",
        "\n",
        "        # Remove empty tokens\n",
        "        tokens = [token for token in tokens if token.text.strip() != \"\" or len(token) > 30]\n",
        "\n",
        "        text = \" \".join([token.text for token in tokens])\n",
        "\n",
        "        # Remove non alphabetic characters\n",
        "        text = re.sub(r\"[^a-zA-Z\\']\", \" \", text)\n",
        "\n",
        "        # remove non-Unicode characters\n",
        "        text = re.sub(r\"[^\\x00-\\x7F]+\", \"\", text)\n",
        "\n",
        "        text = text.lower()\n",
        "\n",
        "        return doc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nS87Z4AwbUs"
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "from spacy import displacy\n",
        "import re\n",
        "#from textblob import TextBlob\n",
        "#import wordninja\n",
        "#import contextualSpellCheck\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    spacy_model = SpacyPreprocessor.load_model()\n",
        "    preprocessor = SpacyPreprocessor(spacy_model=spacy_model, lemmatize=True, remove_numbers=True, remove_stopwords=True)\n",
        "\n",
        "    #clean_text = preprocessor.preprocess_text(\"spaCy is awesome! 123\")\n",
        "    #print(clean_text)\n",
        "\n",
        "    #df = pd.read_csv('jbehave_all.csv')\n",
        "    df = pd.read_csv('jboss features.csv')\n",
        "    df.head()\n",
        "    #print(df['summary'])\n",
        "\n",
        "    texto = df.loc[:,\"summary\"]\n",
        "    tipo = df.loc[:,\"type\"]\n",
        "\n",
        "    cols = np.array(texto)\n",
        "    cols2 = np.array(tipo)\n",
        "\n",
        "    file =\"jbehave_cleaned.csv\"\n",
        "\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    #nlp = spacy.load(\"en_core_web_md\")\n",
        "    #en_core_web_sm\n",
        "\n",
        "    #contextualSpellCheck.add_to_pipe(nlp)\n",
        "\n",
        "    #doc = nlp(\"This is a sentence.\")\n",
        "    #displacy.serve(doc, style=\"dep\")\n",
        "\n",
        "    with open(file,\"w\", newline='', encoding='utf8') as rf:\n",
        "        fieldnames=['summary','type']\n",
        "\n",
        "        writer= csv.DictWriter(rf,fieldnames=fieldnames)\n",
        "        writer.writerow({'summary':'summary','type':'type'})\n",
        "\n",
        "        for i in range(0,len(cols)):\n",
        "            #texto_col = cols[i].split(\" \")\n",
        "            # 06.09.2021 print(cols[i], ' ')\n",
        "            #clean_text = preprocessor.preprocess_text(cols[i])\n",
        "            clean_text = re.sub(r'{code}.*$', \"\", cols[i])\n",
        "\n",
        "            clean_text = re.sub(r'{noformat}.*$', \"\", cols[i])\n",
        "\n",
        "            # Remove URLs\n",
        "            clean_text = re.sub(\"(?P<url>https?://[^\\s]+)0123456789\", '', clean_text, flags=re.MULTILINE)\n",
        "\n",
        "            # Elimina tokens con caracteres especiales\n",
        "            clean_text = clean_tokens_special_char(clean_text)\n",
        "\n",
        "            clean_text = preprocessor.preprocess_text2(clean_text)\n",
        "            print(clean_text)\n",
        "\n",
        "            # FT 21.10.2021\n",
        "            #clean_text = re.sub(' +', ' ',clean_text)\n",
        "\n",
        "            #doc = nlp(clean_text)\n",
        "            #print(doc._.outcome_spellCheck)\n",
        "            #writer.writerow({'summary':doc._.outcome_spellCheck,'type':cols2[i]})\n",
        "\n",
        "            # 06 09 2021 #\n",
        "            #text = wordninja.split(clean_text)\n",
        "            #text = TextBlob(str(text))\n",
        "\n",
        "            # FT 21.10.2021\n",
        "            #clean_text = clean_text.replace(',', '')\n",
        "\n",
        "            #print(i, ' ')\n",
        "            #print(i, ' ')\n",
        "            writer.writerow({'summary':clean_text,'type':cols2[i] })  #cols[i]})\n",
        "\n",
        "            #writer.writerow({'summary':str(text.correct()),'type':cols2[i]})\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzLQLrpyInq-"
      },
      "source": [
        "df = pd.read_csv('jbehave_cleaned.csv')\n",
        "#df = pd.read_csv('jbehave_feat.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3tkJpxuOInrB",
        "outputId": "f309c1eb-f135-4a11-8f36-2ff7968b4c63"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             summary                    type\n",
              "0  BASubordinateCrashDuringComplete.txt byteman s...  non-feature containing\n",
              "1  Can't find resource for bundle key com.arjuna....  non-feature containing\n",
              "2  Could not invoke deployment method: It looks l...  non-feature containing\n",
              "3  failure The root cause of the failure is that ...  non-feature containing\n",
              "4  When is used with JTS then no participant for ...      feature containing"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-741e0596-ab8c-405a-b4d6-53cf061c39c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>summary</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BASubordinateCrashDuringComplete.txt byteman s...</td>\n",
              "      <td>non-feature containing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Can't find resource for bundle key com.arjuna....</td>\n",
              "      <td>non-feature containing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Could not invoke deployment method: It looks l...</td>\n",
              "      <td>non-feature containing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>failure The root cause of the failure is that ...</td>\n",
              "      <td>non-feature containing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>When is used with JTS then no participant for ...</td>\n",
              "      <td>feature containing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-741e0596-ab8c-405a-b4d6-53cf061c39c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-91f34158-3eda-46da-bbd0-bd1d4be4d07a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-91f34158-3eda-46da-bbd0-bd1d4be4d07a')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-91f34158-3eda-46da-bbd0-bd1d4be4d07a button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-741e0596-ab8c-405a-b4d6-53cf061c39c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-741e0596-ab8c-405a-b4d6-53cf061c39c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lre1CviXInrF",
        "outputId": "3056836b-82b4-4504-9055-e95a51794d79"
      },
      "source": [
        "df['type'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "non-feature containing    1212\n",
              "feature containing         379\n",
              "Name: type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH9Qh9aAInrI",
        "outputId": "e5abddef-7618-4a18-b3c5-34f5d5a161ca"
      },
      "source": [
        "possible_labels = df.type.unique()\n",
        "\n",
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index\n",
        "label_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'non-feature containing': 0, 'feature containing': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lsxjH2WInrN"
      },
      "source": [
        "df['label'] = df.type.replace(label_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zr0SvIonInrQ",
        "outputId": "dc728b29-1c84-4e59-975b-1bff9794e8e6"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             summary                    type  \\\n",
              "0  BASubordinateCrashDuringComplete.txt byteman s...  non-feature containing   \n",
              "1  Can't find resource for bundle key com.arjuna....  non-feature containing   \n",
              "2  Could not invoke deployment method: It looks l...  non-feature containing   \n",
              "3  failure The root cause of the failure is that ...  non-feature containing   \n",
              "4  When is used with JTS then no participant for ...      feature containing   \n",
              "\n",
              "   label  \n",
              "0      0  \n",
              "1      0  \n",
              "2      0  \n",
              "3      0  \n",
              "4      1  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-c3f12409-c535-42f3-89c4-6cb971d79ca1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>summary</th>\n",
              "      <th>type</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BASubordinateCrashDuringComplete.txt byteman s...</td>\n",
              "      <td>non-feature containing</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Can't find resource for bundle key com.arjuna....</td>\n",
              "      <td>non-feature containing</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Could not invoke deployment method: It looks l...</td>\n",
              "      <td>non-feature containing</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>failure The root cause of the failure is that ...</td>\n",
              "      <td>non-feature containing</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>When is used with JTS then no participant for ...</td>\n",
              "      <td>feature containing</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3f12409-c535-42f3-89c4-6cb971d79ca1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-842b2841-abf0-470f-aa7e-d9192bf53a05\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-842b2841-abf0-470f-aa7e-d9192bf53a05')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-842b2841-abf0-470f-aa7e-d9192bf53a05 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c3f12409-c535-42f3-89c4-6cb971d79ca1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c3f12409-c535-42f3-89c4-6cb971d79ca1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPrtUPExInrT"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(df.index.values,\n",
        "                                                  df.label.values,\n",
        "                                                  test_size=0.15,\n",
        "                                                  random_state=42,\n",
        "                                                  stratify=df.label.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qcc6gO6InrW"
      },
      "source": [
        "df['data_type'] = ['not_set']*df.shape[0]\n",
        "\n",
        "df.loc[X_train, 'data_type'] = 'train'\n",
        "df.loc[X_val, 'data_type'] = 'val'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mLxWepY7InrY",
        "outputId": "15e34dfa-6f2b-46b7-ca13-20ba16d926c6"
      },
      "source": [
        "df.groupby(['type', 'label', 'data_type']).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        summary\n",
              "type                   label data_type         \n",
              "feature containing     1     train          322\n",
              "                             val             57\n",
              "non-feature containing 0     train         1030\n",
              "                             val            182"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-aaaef103-6522-481c-b79d-aef95189c75b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>type</th>\n",
              "      <th>label</th>\n",
              "      <th>data_type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">feature containing</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th>train</th>\n",
              "      <td>322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">non-feature containing</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
              "      <th>train</th>\n",
              "      <td>1030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>182</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aaaef103-6522-481c-b79d-aef95189c75b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-b86b814d-8527-4e66-80be-b5801935b3ca\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b86b814d-8527-4e66-80be-b5801935b3ca')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-b86b814d-8527-4e66-80be-b5801935b3ca button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aaaef103-6522-481c-b79d-aef95189c75b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aaaef103-6522-481c-b79d-aef95189c75b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vfQaJneInre"
      },
      "source": [
        "#tokenizer = BertTokenizer.from_pretrained('distilbert-base-uncased',#'allenai/scibert_scivocab_uncased') # 'bert-base-uncased',\n",
        "#                                          do_lower_case=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base',#'allenai/scibert_scivocab_uncased') # 'bert-base-uncased',\n",
        "                                                do_lower_case=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7aPxLIuCxyt",
        "outputId": "cd8deeb0-624c-4e9b-f9df-67f4f4c16571"
      },
      "source": [
        "text_file = open(\"vocab.txt\", \"r\")\n",
        "new_tokens = text_file.readlines()\n",
        "print(new_tokens)\n",
        "print(len(new_tokens))\n",
        "text_file.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Acceptance \\n', 'Acceptance criteria\\n', 'Acceptance test\\n', 'Activity\\n', 'Activity model\\n', 'Actor\\n', 'Adequacy\\n', 'Agile\\n', 'Ambiguity\\n', 'Artifact\\n', 'Association\\n', 'Attribute\\n', 'Backlog\\n', 'Baseline\\n', 'Behavior\\n', 'Behavior model\\n', 'Bug\\n', 'Burndown chart\\n', 'Business requirement\\n', 'Cardinality\\n', 'Change management\\n', 'Change request\\n', 'Changeability\\n', 'Class\\n', 'Class diagram\\n', 'Class model\\n', 'Completeness\\n', 'Composition\\n', 'Conflict\\n', 'Requirements conflict\\n', 'Consistency\\n', 'Constraint\\n', 'Context\\n', 'Context boundary\\n', 'Context diagram\\n', 'Context model\\n', 'Control flow\\n', 'Correctness\\n', 'Customer\\n', 'specification\\n', 'customer\\n', 'Decision table\\n', 'Defect\\n', 'Design\\n', 'Document template\\n', 'Domain\\n', 'Domain model\\n', 'Domain requirement\\n', 'Effectiveness\\n', 'Efficiency\\n', 'Elaboration\\n', 'Elicitation\\n', 'Entity\\n', 'diagram\\n', 'Error\\n', 'Evolutionary prototype\\n', 'Exploratory prototype\\n', 'Fault\\n', 'Fault tolerance\\n', 'Feasibility\\n', 'Feature\\n', 'Feature diagram\\n', 'Feature model\\n', 'Functional requirement\\n', 'Functionality\\n', 'Glossary\\n', 'Goal\\n', 'Goal model\\n', 'Increment\\n', 'Iteration\\n', 'Kind of requirement\\n', 'requirements\\n', 'Mock-up\\n', 'Model\\n', 'Modeling language\\n', 'Modifiability\\n', 'Natural language\\n', 'Necessity\\n', 'requirement\\n', 'Object\\n', 'Object model\\n', 'Performance\\n', 'Persona\\n', 'Priority\\n', 'Prioritization\\n', 'Problem\\n', 'Process\\n', 'Process model\\n', 'Product\\n', 'Product backlog\\n', 'Product line\\n', 'Product owner\\n', 'Prototype\\n', 'Prototyping\\n', 'Quality\\n', 'requirements\\n', 'functional requirements\\n', 'Refactoring\\n', 'Redundancy\\n', 'Release\\n', 'Reliability\\n', 'Requirements analysis\\n', 'Requirements baseline\\n', 'Requirements branching\\n', 'Requirements conflict\\n', 'Requirements discovery\\n', 'elicitation\\n', 'Requirements document\\n', 'Requirements elicitation\\n', 'Requirements Engineer\\n', 'Engineering\\n', 'stakeholders\\n', 'system\\n', 'management\\n', 'Requirements model\\n', 'negotiation\\n', 'Requirements source\\n', 'Requirements specification\\n', 'Review\\n', 'Risk\\n', 'Role\\n', 'Safety\\n', 'Scope\\n', 'Security\\n', 'Semantics\\n', 'Sequence diagram\\n', 'Service\\n', 'Specification\\n', 'Sprint\\n', 'Stakeholder\\n', 'Standard\\n', 'State machine\\n', 'State machine diagram\\n', 'Statechart\\n', 'Synonym\\n', 'Syntax\\n', 'System\\n', 'System boundary\\n', 'System context\\n', 'System requirement\\n', 'specification\\n', 'Tool\\n', 'Traceability\\n', 'UML\\n', 'Unambiguity\\n', 'Understandability\\n', 'Usability\\n', 'Use case\\n', 'Use case diagram\\n', 'User\\n', 'User story\\n', 'Validation\\n', 'Variability\\n', 'Variant\\n', 'Variation\\n', 'Verifiability\\n', 'Verification\\n', 'Version\\n', 'View\\n', 'Viewpoint\\n', 'Vision\\n', 'Walkthrough\\n', 'Wireframe\\n', 'ADC\\n', 'ALU\\n', 'ANSI\\n', 'ASCII\\n', 'abstraction\\n', 'access\\n', 'access time\\n', 'accident\\n', 'accuracy\\n', 'accuracy study processor\\n', 'actuator\\n', 'adaptive maintenance\\n', 'address\\n', 'addressing exception\\n', 'algorithm\\n', 'algorithm analysis\\n', 'alphanumeric\\n', 'American National Standards Institute\\n', 'American Standard Code for Information Interchange\\n', 'analog\\n', 'analog device\\n', 'analog-to-digital converter\\n', 'analysis\\n', 'anomaly\\n', 'application program\\n', 'application software\\n', 'architectural design\\n', 'architecture\\n', 'archival database\\n', 'archive\\n', 'archive file\\n', 'arithmetic logic unit\\n', 'arithmetic overflow\\n', 'arithmetic underflow\\n', 'array\\n', 'as built\\n', 'assemble\\n', 'assembler\\n', 'assembling\\n', 'assembly code\\n', 'assembly language\\n', 'assertion\\n', 'assertion checking\\n', 'asynchronous\\n', 'asynchronous transmission\\n', 'audit\\n', 'audit trail\\n', 'auxiliary storage\\n', 'band\\n', 'bandwidth\\n', 'bar code\\n', 'baseline\\n', 'BASIC\\n', 'basic input/output system\\n', 'batch\\n', 'batch processing\\n', 'baud\\n', 'benchmark\\n', 'bias\\n', 'binary\\n', 'BIOS\\n', 'bit\\n', 'bits per second\\n', 'black-box testing\\n', 'block\\n', 'block check\\n', 'block diagram\\n', 'block length\\n', 'block transfer\\n', 'blocking factor\\n', 'blueprint\\n', 'bomb\\n', 'boolean\\n', 'boot\\n', 'bootstrap\\n', 'boundary value\\n', 'boundary value analysis\\n', 'box diagram\\n', 'bps\\n', 'branch\\n', 'branch analysis\\n', 'branch coverage\\n', 'bubble chart\\n', 'buffer\\n', 'bug\\n', 'bus\\n', 'byte\\n', 'C\\n', 'C++\\n', 'CAD\\n', 'calibration\\n', 'call graph\\n', 'CAM\\n', 'CASE\\n', 'cathode ray tube\\n', 'cause effect graph\\n', 'cause effect graphing\\n', 'CCITT\\n', 'CD-ROM\\n', 'central processing unit\\n', 'certification\\n', 'change control\\n', 'change tracker\\n', 'check summation\\n', 'checksum\\n', 'chip\\n', 'CISC\\n', 'client-server\\n', 'clock\\n', 'CMOS\\n', 'CO-AX\\n', 'coaxial cable\\n', 'COBOL\\n', 'code\\n', 'code audit\\n', 'code auditor\\n', 'code inspection\\n', 'code review\\n', 'code walkthrough\\n', 'coding\\n', 'coding standards\\n', 'comment\\n', 'compact disc - read only memory\\n', 'comparator\\n', 'compatibility\\n', 'compilation\\n', 'compile\\n', 'compiler\\n', 'compiling\\n', 'complementary metal-oxide semiconductor\\n', 'completeness\\n', 'complex instruction set computer\\n', 'complexity\\n', 'component\\n', 'computer\\n', 'computer aided design\\n', 'computer aided manufacturing\\n', 'computer aided software engineering\\n', 'computer instruction set\\n', 'computer language\\n', 'computer program\\n', 'computer science\\n', 'computer system\\n', 'computer system audit\\n', 'computer system security\\n', 'computer word\\n', 'computerized system\\n', 'concept phase\\n', 'condition coverage\\n', 'configurable\\n', 'configuration\\n', 'configuration audit\\n', 'configuration control\\n', 'configuration identification\\n', 'configuration item\\n', 'configuration management\\n', 'consistency\\n', 'consistency checker\\n', 'constant\\n', 'constraint analysis\\n', 'Consultive Committee for International Telephony and Telegraphy\\n', 'Contrast with software item\\n', 'control bus\\n', 'control flow\\n', 'control flow analysis\\n', 'control flow diagram\\n', 'Control Program for Microcomputers\\n', 'controller\\n', 'conversational\\n', 'coroutine\\n', 'corrective maintenance\\n', 'correctness\\n', 'COTS\\n', 'coverage analysis\\n', 'CP/M\\n', 'CPU\\n', 'crash\\n', 'CRC\\n', 'critical control point\\n', 'critical design review\\n', 'criticality\\n', 'criticality analysis\\n', 'cross-assembler\\n', 'cross-compiler\\n', 'CRT\\n', 'cursor\\n', 'cyclic redundancy [check] code\\n', 'cyclomatic complexity\\n', 'DAC\\n', 'data\\n', 'data analysis\\n', 'data bus\\n', 'data corruption\\n', 'data dictionary\\n', 'data element\\n', 'data exception\\n', 'data flow analysis\\n', 'data flow diagram\\n', 'data integrity\\n', 'data item\\n', 'data set\\n', 'data sink\\n', 'data structure\\n', 'data structure centered design\\n', 'data structure diagram\\n', 'data validation\\n', 'database\\n', 'database analysis\\n', 'database security\\n', 'dead code\\n', 'debugging\\n', 'decision coverage\\n', 'decision table\\n', 'default\\n', 'default value\\n', 'defect\\n', 'defect analysis\\n', 'delimiter\\n', 'demodulate\\n', 'demodulation\\n', 'dependability\\n', 'design\\n', 'design description\\n', 'design level\\n', 'design of experiments\\n', 'design phase\\n', 'design requirement\\n', 'design review\\n', 'design specification\\n', 'design standards\\n', 'desk checking\\n', 'detailed design\\n', 'developer\\n', 'development methodology\\n', 'development standards\\n', 'DFD\\n', 'diagnostic\\n', 'different software system analysis\\n', 'digital\\n', 'digital-to-analog converter\\n', 'direct memory access\\n', 'directed graph\\n', 'disk\\n', 'disk drive\\n', 'disk operating system\\n', 'diskette\\n', 'DMA\\n', 'documentation\\n', 'documentation plan\\n', 'documentation\\n', 'DOS\\n', 'drift\\n', 'driver\\n', 'duplex transmission\\n', 'dynamic analysis\\n', 'EBCDIC\\n', 'editing\\n', 'EEPROM\\n', 'electrically erasable programmable read only memory\\n', 'electromagnetic interference\\n', 'electronic media\\n', 'electrostatic discharge\\n', 'embedded computer\\n', 'embedded software\\n', 'EMI\\n', 'emulation\\n', 'emulator\\n', 'encapsulation\\n', 'end user\\n', 'enhanced small device interface\\n', 'entity relationship diagram\\n', 'environment\\n', 'EPROM\\n', 'equivalence class partitioning\\n', 'erasable programmable read only memory\\n', 'error\\n', 'error analysis\\n', 'error detection\\n', 'error guessing\\n', 'error seeding\\n', 'ESD\\n', 'ESDI\\n', 'event table\\n', 'evolutionary development\\n', 'exception\\n', 'exception\\n', 'exception conditions/responses table\\n', 'execution trace\\n', 'extended ASCII\\n', 'extended binary coded decimal interchange code\\n', 'extremal test data\\n', 'Fagan inspection\\n', 'fail-safe\\n', 'failure\\n', 'failure analysis\\n', 'Failure Modes and Effects Analysis\\n', 'Failure Modes and Effects Criticality Analysis\\n', 'fault\\n', 'fault seeding\\n', 'Fault Tree Analysis\\n', 'FDD\\n', 'feasibility study\\n', 'Federal Information Processing Standards\\n', 'fiber optics\\n', 'field\\n', 'file\\n', 'file maintenance\\n', 'file transfer protocol\\n', 'FIPS\\n', 'firmware\\n', 'flag\\n', 'flat file\\n', 'floppy disk\\n', 'floppy disk drive\\n', 'flowchart or flow diagram\\n', 'FMEA\\n', 'FMECA\\n', 'formal qualification review\\n', 'FORTRAN\\n', 'FTA\\n', 'FTP\\n', 'full duplex\\n', 'function\\n', 'functional analysis\\n', 'functional configuration audit\\n', 'functional decomposition\\n', 'functional design\\n', 'functional requirement\\n', 'GB\\n', 'gigabyte\\n', 'graph\\n', 'graphic software specifications\\n', 'half duplex\\n', 'handshake\\n', 'hard copy\\n', 'hard disk drive\\n', 'hard drive\\n', 'hardware\\n', 'hazard\\n', 'hazard analysis\\n', 'hazard probability\\n', 'hazard severity\\n', 'HDD\\n', 'hertz\\n', 'hexadecimal\\n', 'hierarchical decomposition\\n', 'hierarchy of input-processing-output\\n', 'hierarchy of input-processing-output chart\\n', 'high-level language\\n', 'HIPO\\n', 'Hz\\n', 'I/0\\n', 'I/O port\\n', 'IC\\n', 'IDE\\n', 'IEC\\n', 'IEEE\\n', 'implementation\\n', 'implementation phase\\n', 'implementation requirement\\n', 'incremental development\\n', 'incremental integration\\n', 'industry standard\\n', 'infeasible path\\n', 'information hiding\\n', 'input-process-output chart\\n', 'input-processing-output\\n', 'input/output\\n', 'inspection\\n', 'installation\\n', 'installation and checkout phase\\n', 'installation qualification\\n', 'Institute of Electrical and Electronic Engineers\\n', 'instruction\\n', 'instruction set\\n', 'instrumentation\\n', 'integrated circuit\\n', 'integrated drive electronics\\n', 'interactive\\n', 'interface\\n', 'interface analysis\\n', 'interface requirement\\n', 'International Electrotechnical Commission\\n', 'International Organization for Standardization\\n', 'International Standards Organization\\n', 'International Telecommunications Union - Telecommunications Standards Section\\n', 'interpret\\n', 'interpreter\\n', 'interrupt\\n', 'interrupt analyzer\\n', 'invalid inputs\\n', 'ISO\\n', 'ITU-TSS\\n', 'JCL\\n', 'job\\n', 'job control language\\n', 'KB\\n', 'Kermit\\n', 'key\\n', 'key element\\n', 'kilobyte\\n', 'KLOC\\n', 'ladder logic\\n', 'LAN\\n', 'language\\n', 'large scale integration\\n', 'latency\\n', 'latent defect\\n', 'life cycle\\n', 'life cycle methodology\\n', 'linkage editor\\n', 'loader\\n', 'local area network\\n', 'logic analysis\\n', 'longitudinal redundancy check\\n', 'low-level language\\n', 'LSI\\n', 'machine code\\n', 'machine language\\n', 'macro\\n', 'macroinstruction\\n', 'main memory\\n', 'main program\\n', 'mainframe\\n', 'maintainability\\n', 'maintenance\\n', 'MAN\\n', 'MB\\n', 'Mb\\n', 'mean time between failures\\n', 'mean time to failure\\n', 'mean time to repair\\n', 'measurable\\n', 'measure\\n', 'measurement\\n', 'medium scale integration\\n', 'megabit\\n', 'megabyte\\n', 'megahertz\\n', 'memory\\n', 'menu\\n', 'metal-oxide semiconductor\\n', 'metal-oxide semiconductor field effect transistor\\n', 'metric based test data generation\\n', 'metric\\n', 'metropolitan area network\\n', 'MHz\\n', 'microcode\\n', 'microcomputer\\n', 'microprocessor\\n', 'million instructions per second\\n', 'minicomputer\\n', 'MIPS\\n', 'mishap\\n', 'mnemonic\\n', 'modeling\\n', 'modem\\n', 'modem access\\n', 'modifiability\\n', 'modular decomposition\\n', 'modular software\\n', 'modularity\\n', 'modulate\\n', 'modulation\\n', 'module\\n', 'module interface table\\n', 'MOS\\n', 'MOSFET\\n', 'MSI\\n', 'MTBF\\n', 'MTTF\\n', 'MTTR\\n', 'multi-processing\\n', 'multi-programming\\n', 'multi-tasking\\n', 'multiple condition coverage\\n', 'multiplexer\\n', 'multipurpose systems\\n', 'mutation analysis\\n', 'n-channel MOS\\n', 'National Bureau of Standards\\n', 'National Institute for Standards and Technology\\n', 'NBS\\n', 'network\\n', 'network database\\n', 'nibble\\n', 'NIST\\n', 'NMI\\n', 'NMOS\\n', 'node\\n', 'non-maskable interrupt\\n', 'noncritical code analysis\\n', 'nonincremental integration\\n', 'null\\n', 'null data\\n', 'null string\\n', 'object\\n', 'object code\\n', 'object oriented design\\n', 'object oriented language\\n', 'object oriented programming\\n', 'object program\\n', 'OCR\\n', 'octal\\n', 'OEM\\n', 'on-line\\n', 'OOP\\n', 'operating system\\n', 'operation and maintenance phase\\n', 'operation exception\\n', 'operator\\n', 'optical character recognition\\n', 'optical fiber\\n', 'optimization\\n', 'Oracle\\n', 'original equipment manufacturer\\n', 'overflow\\n', 'overflow exception\\n', 'paging\\n', 'PAL\\n', 'parallel\\n', 'parallel processing\\n', 'parameter\\n', 'parity\\n', 'parity bit\\n', 'parity check\\n', 'Pascal\\n', 'password\\n', 'patch\\n', 'path\\n', 'path analysis\\n', 'path coverage\\n', 'PC\\n', 'PCB\\n', 'PDL\\n', 'perfective maintenance\\n', 'performance requirement\\n', 'peripheral device\\n', 'peripheral equipment\\n', 'personal computer\\n', 'physical configuration audit\\n', 'physical requirement\\n', 'pixel\\n', 'PLA\\n', 'platform\\n', 'PLD\\n', 'PMOS\\n', 'polling\\n', 'positive channel MOS\\n', 'precision\\n', 'preliminary design\\n', 'preliminary design review\\n', 'printed circuit board\\n', 'production database\\n', 'program\\n', 'program design language\\n', 'program mutation\\n', 'programmable array logic\\n', 'programmable logic array\\n', 'programmable logic device\\n', 'programmable read only memory\\n', 'programming language\\n', 'programming standards\\n', 'programming style analysis\\n', 'project plan\\n', 'PROM\\n', 'PROM programmer\\n', 'proof of correctness\\n', 'protection exception\\n', 'protocol\\n', 'prototyping\\n', 'pseudocode\\n', 'QA\\n', 'QC\\n', 'qualification\\n', 'quality assurance\\n', 'quality control\\n', 'radiofrequency interference\\n', 'RAM\\n', 'random access memory\\n', 'range check\\n', 'rapid prototyping\\n', 'read only memory\\n', 'real time\\n', 'real time processing\\n', 'record\\n', 'record of change\\n', 'recursion\\n', 'reduced instruction set computer\\n', 'region\\n', 'register\\n', 'regression analysis and testing\\n', 'relational database\\n', 'release\\n', 'reliability\\n', 'reliability assessment\\n', 'requirement\\n', 'requirements analysis\\n', 'requirements phase\\n', 'requirements review\\n', 'retention period\\n', 'retrospective trace\\n', 'revalidation\\n', 'review\\n', 'revision number\\n', 'RFI\\n', 'RISC\\n', 'risk\\n', 'risk assessment\\n', 'robustness\\n', 'ROM\\n', 'routine\\n', 'RS-232-C\\n', 'safety\\n', 'safety critical\\n', 'safety critical computer software components\\n', 'SCSI\\n', 'security\\n', 'sensor\\n', 'serial\\n', 'server\\n', 'service program\\n', 'servomechanism\\n', 'severity\\n', 'side effect\\n', 'simulation\\n', 'simulation analysis\\n', 'simulator\\n', 'sizing\\n', 'sizing and timing analysis\\n', 'small computer systems interface\\n', 'small scale integration\\n', 'software\\n', 'software audit\\n', 'software characteristic\\n', 'software configuration item\\n', 'software design description\\n', 'software developer\\n', 'software development notebook\\n', 'software development plan\\n', 'software development process\\n', 'software diversity\\n', 'software documentation\\n', 'software element\\n', 'software element analysis\\n', 'software engineering\\n', 'software engineering environment\\n', 'software hazard analysis\\n', 'software item\\n', 'software life cycle\\n', 'software reliability\\n', 'software requirements specification\\n', 'software review\\n', 'software safety change analysis\\n', 'software safety code analysis\\n', 'software safety design analysis\\n', 'software safety requirements analysis\\n', 'software safety test analysis\\n', 'SOPs\\n', 'source code\\n', 'source program\\n', 'spaghetti code\\n', 'special test data\\n', 'specification\\n', 'specification analysis\\n', 'specification tree\\n', 'specification\\n', 'spiral model\\n', 'SQL\\n', 'SSI\\n', 'ST-506\\n', 'standard operating procedures\\n', 'state\\n', 'state diagram\\n', 'state-transition table\\n', 'statement coverage\\n', 'static analysis\\n', 'static analyzer\\n', 'stepwise refinement\\n', 'storage device\\n', 'string\\n', 'structure chart\\n', 'structured design\\n', 'structured programming\\n', 'structured query language\\n', 'stub\\n', 'subprogram\\n', 'subroutine\\n', 'subroutine trace\\n', 'support software\\n', 'symbolic execution\\n', 'symbolic trace\\n', 'synchronous\\n', 'synchronous transmission\\n', 'syntax\\n', 'system\\n', 'system administrator\\n', 'system analysis\\n', 'system design\\n', 'system design review\\n', 'system documentation\\n', 'system integration\\n', 'system life cycle\\n', 'system manager\\n', 'system safety\\n', 'system software\\n', 'tape\\n', 'TB\\n', 'TCP/IP\\n', 'telecommunication system\\n', 'terabyte\\n', 'terminal\\n', 'test\\n', 'test case\\n', 'test case generator\\n', 'test design\\n', 'test documentation\\n', 'test driver\\n', 'test harness\\n', 'test incident report\\n', 'test item\\n', 'test log\\n', 'test phase\\n', 'test plan\\n', 'test procedure\\n', 'test readiness review\\n', 'test report\\n', 'test result analyzer\\n', 'testability\\n', 'testing\\n', 'time sharing\\n', 'timing\\n', 'timing analyzer\\n', 'timing and sizing analysis\\n', 'top-down design\\n', 'touch screen\\n', 'touch sensitive\\n', 'trace\\n', 'traceability\\n', 'traceability analysis\\n', 'traceability matrix\\n', 'transaction\\n', 'transaction analysis\\n', 'transaction flowgraph\\n', 'transaction matrix\\n', 'transform analysis\\n', 'translation\\n', 'transmission control protocol\\n', 'Internet protocol\\n', 'trojan horse\\n', 'truth table\\n', 'tuning\\n', 'twisted pair\\n', 'unambiguous\\n', 'underflow\\n', 'underflow exception\\n', 'unit\\n', 'UNIX\\n', 'usability\\n', 'user\\n', \"user's guide\\n\", 'utility program\\n', 'utility software\\n', 'V&V\\n', 'valid\\n', 'valid input\\n', 'validate\\n', 'validation\\n', 'validation protocol\\n', 'variable\\n', 'variable trace\\n', 'VAX\\n', 'vendor\\n', 'verifiable\\n', 'verification\\n', 'verify\\n', 'version\\n', 'version number\\n', 'very large scale integration\\n', 'virtual address extension\\n', 'virtual memory system\\n', 'virus\\n', 'VLSI\\n', 'VMS\\n', 'volume\\n', 'VV&T\\n', 'walkthrough\\n', 'WAN\\n', 'watchdog timer\\n', 'waterfall model\\n', 'white-box testing\\n', 'wide area network\\n', 'word\\n', 'workaround\\n', 'workstation\\n', 'worm\\n', 'Xmodem\\n', 'Ymodem\\n', 'Zmodem\\n', 'A/B testing\\n', 'abnormal end\\n', 'abuse case\\n', 'acceptance  criteria\\n', 'acceptance  testing\\n', 'acceptance test-driven  development\\n', 'accessibility\\n', 'account harvesting\\n', 'accountability\\n', 'acting\\n', 'actual result\\n', 'adaptability\\n', 'adversarial  example\\n', 'adversarial testing\\n', 'Agile Manifesto\\n', 'Agile software development\\n', 'Agile testing\\n', 'agile testing quadrants\\n', 'alpha testing\\n', 'analytical test strategy\\n', 'analyzability\\n', 'anomaly\\n', 'anti-malware\\n', 'anti-pattern\\n', 'API testing\\n', 'appropriateness recognizability\\n', 'assessment  report\\n', 'assessor\\n', 'atomic  condition\\n', 'attack vector\\n', 'attacker\\n', 'audio testing\\n', 'audit\\n', 'authentication\\n', 'authorization\\n', 'automation code defect density\\n', 'automotive  safety integrity level\\n', 'automotive SPICE\\n', 'availability\\n', 'back-to-back  testing\\n', 'balanced scorecard\\n', 'behavior-driven development\\n', 'beta testing\\n', 'black-box test technique\\n', 'botnet\\n', 'boundary  value\\n', 'boundary  value analysis\\n', 'branch\\n', 'bug hunting\\n', 'build verification  test\\n', 'call graph\\n', 'Capability  Maturity Model Integration\\n', 'capacity\\n', 'capacity testing\\n', 'capture/playback\\n', 'cause-effect  diagram\\n', 'cause-effect  graph\\n', 'certification\\n', 'change management\\n', 'change-related testing\\n', 'checklist-based review\\n', 'checklist-based testing\\n', 'classification tree\\n', 'classification tree technique\\n', 'CLI testing\\n', 'closed-loop-system\\n', 'code injection\\n', 'codependent  behavior\\n', 'coding standard\\n', 'combinatorial testing\\n', 'command-line interface\\n', 'commercial off-the-shelf\\n', 'compatibility\\n', 'complexity\\n', 'compliance\\n', 'compliance testing\\n', 'component integration testing\\n', 'computer  forensics\\n', 'concurrency\\n', 'concurrency  testing\\n', 'condition coverage\\n', 'condition testing\\n', 'confidence interval\\n', 'confidentiality\\n', 'configuration  management\\n', 'configuration item\\n', 'confirmation  testing\\n', 'connectivity\\n', 'consultative  test strategy\\n', 'content-based  model\\n', 'context  of use\\n', 'continuous  integration\\n', 'continuous  representation\\n', 'continuous testing\\n', 'contractual  acceptance testing\\n', 'control chart\\n', 'control flow\\n', 'control flow analysis\\n', 'control flow testing\\n', 'convergence  metric\\n', 'corporate  dashboard\\n', 'cost of quality\\n', 'coverage\\n', 'coverage  item\\n', 'coverage criteria\\n', 'critical success factor\\n', 'Critical Testing Processes\\n', 'cross-browser  compatibility\\n', 'cross-site  scripting\\n', 'crowd testing\\n', 'custom  tool\\n', 'cyclomatic  complexity\\n', 'dashboard\\n', 'data  privacy\\n', 'data flow analysis\\n', 'data obfuscation\\n', 'data-driven testing\\n', 'debugging\\n', 'debugging  tool\\n', 'decision\\n', 'decision coverage\\n', 'decision table testing\\n', 'decision testing\\n', 'defect\\n', 'defect  density\\n', 'Defect Detection Percentage\\n', 'defect management\\n', 'defect management committee\\n', 'defect report\\n', 'defect taxonomy\\n', 'defect-based  test technique\\n', 'definition-use pair\\n', 'demilitarized  zone\\n', 'Deming cycle\\n', 'denial of service\\n', 'device-based testing\\n', 'diagnosing\\n', 'driver\\n', 'dynamic  analysis\\n', 'dynamic testing\\n', 'Effect Analysis\\n', 'effectiveness\\n', 'efficiency\\n', 'egon at\\n', 'egon at\\n', 'emotional intelligence\\n', 'emulator\\n', 'encryption\\n', 'end-to-end testing\\n', 'endurance testing\\n', 'entry criteria\\n', 'environment  model\\n', 'epic\\n', 'equivalence  partition\\n', 'equivalence  partitioning\\n', 'equivalent manual test effort\\n', 'error\\n', 'error guessing\\n', 'escaped defect\\n', 'establishing\\n', 'ethical hacker\\n', 'European Foundation for Quality Management  excellence  model\\n', 'exit criteria\\n', 'expected  result\\n', 'experience-based test technique\\n', 'experience-based testing\\n', 'expert usability  review\\n', 'exploratory testing\\n', 'Extreme Programming\\n', 'failed\\n', 'failover\\n', 'failure\\n', 'Failure blade and Effect Analysis\\n', 'failure mode\\n', 'failure rate\\n', 'false-negative result\\n', 'false-positive result\\n', 'fault injection\\n', 'fault seeding\\n', 'fault seeding tool\\n', 'fault tolerance\\n', 'Fault Tree  Analysis\\n', 'feature-driven development\\n', 'field testing\\n', 'finding\\n', 'firewall\\n', 'follow-up test case\\n', 'formal review\\n', 'formative evaluation\\n', 'functional  testing\\n', 'functional appropriateness\\n', 'functional completeness\\n', 'functional correctness\\n', 'functional safety\\n', 'functional suitability\\n', 'fuzz testing\\n', 'generic test automation architecture\\n', 'Goal Question  Metric\\n', 'graphical user interface\\n', 'GUI  testing\\n', 'hacker\\n', 'hardware in the  loop\\n', 'hashing\\n', 'heuristic\\n', 'heuristic  evaluation\\n', 'high-level test case\\n', 'human-centered design\\n', 'hyperlink\\n', 'hyperlink test tool\\n', 'IDEAL\\n', 'impact analysis\\n', 'incremental development  model\\n', 'independence  of testing\\n', 'independent  test lab\\n', 'indicator\\n', 'informal review\\n', 'information assurance\\n', 'initiating\\n', 'input  data testing\\n', 'insider threat\\n', 'insourced  testing\\n', 'inspection\\n', 'installability\\n', 'integration  testing\\n', 'integrity\\n', 'interface testing\\n', 'interoperability\\n', 'intrusion detection  system\\n', 'iterative development  model\\n', 'keyword-driven testing\\n', 'lead assessor\\n', 'learnability\\n', 'learning\\n', 'level of intrusion\\n', 'level test plan\\n', 'linear scripting\\n', 'load generation\\n', 'load generator\\n', 'load management\\n', 'load profile\\n', 'load testing\\n', 'low-level test case\\n', 'maintenance\\n', 'maintenance testing\\n', 'malware\\n', 'malware scanning\\n', 'management  review\\n', 'manufacturing-based quality\\n', 'master test plan\\n', 'math testing\\n', 'maturity\\n', 'maturity level\\n', 'maturity model\\n', 'MBT model\\n', 'mean time between failures\\n', 'mean time to failure\\n', 'mean time to repair\\n', 'measure\\n', 'measurement\\n', 'memory leak\\n', 'metamorphic  relation\\n', 'metamorphic  testing\\n', 'method table\\n', 'methodical  test strategy\\n', 'metric\\n', 'mind map\\n', 'ML functional performance\\n', 'ML functional performance criteria\\n', 'ML functional performance metrics\\n', 'ML model\\n', 'ML model testing\\n', 'model coverage\\n', 'model in the  loop\\n', 'model-based test strategy\\n', 'model-based testing\\n', 'moderator\\n', 'modifiability\\n', 'modified condition/decision coverage\\n', 'modified condition/decision testing\\n', 'modularity\\n', 'monitoring  tool\\n', 'multiplayer testing\\n', 'multiple condition coverage\\n', 'multiple condition testing\\n', 'Myers-Briggs  Type Indicator\\n', 'N-switch coverage\\n', 'negative testing\\n', 'neighborhood  integration testing\\n', 'network zone\\n', 'neuron coverage\\n', 'non-functional testing\\n', 'non-repudiation\\n', 'offline MBT\\n', 'online MBT\\n', 'open-loop-system\\n', 'operability\\n', 'operational  profile\\n', 'operational  profiling\\n', 'operational acceptance  testing\\n', 'outsourced  testing\\n', 'pair testing\\n', 'pairwise  integration  testing\\n', 'par  sheet testing\\n', 'Pareto analysis\\n', 'pass/fail criteria\\n', 'passed\\n', 'password  cracking\\n', 'path\\n', 'path testing\\n', 'peer review\\n', 'penetration testing\\n', 'performance  efficiency\\n', 'performance  indicator\\n', 'performance  testing\\n', 'performance  testing tool\\n', 'perspective-based reading\\n', 'pharming\\n', 'phase containment\\n', 'phishing\\n', 'planning poker\\n', 'player perspective testing\\n', 'pointer\\n', 'portability\\n', 'post-release  testing\\n', 'postcondition\\n', 'precondition\\n', 'priority\\n', 'PRISMA\\n', 'probe effect\\n', 'process assessment\\n', 'process model\\n', 'process-compliant test strategy\\n', 'process-driven scripting\\n', 'product risk\\n', 'product-based  quality\\n', 'project risk\\n', 'proximity-based testing\\n', 'pseudo-oracle\\n', 'quality\\n', 'quality  risk\\n', 'quality assurance\\n', 'quality characteristic\\n', 'quality control\\n', 'quality function  deployment\\n', 'quality management\\n', 'RACI matrix\\n', 'ramp-down\\n', 'ramp-up\\n', 'random testing\\n', 'Rational Unified Process\\n', 'reactive test  strategy\\n', 'reactive testing\\n', 'reconnaissance\\n', 'recoverability\\n', 'regression testing\\n', 'regression-averse test strategy\\n', 'regulatory acceptance testing\\n', 'reliability\\n', 'reliability growth model\\n', 'remote test lab\\n', 'replaceability\\n', 'requirement\\n', 'requirements-based testing\\n', 'resource  utilization\\n', 'retrospective  meeting\\n', 'reusability\\n', 'review\\n', 'review plan\\n', 'reviewer\\n', 'risk\\n', 'risk analysis\\n', 'risk assessment\\n', 'risk identification\\n', 'risk impact\\n', 'risk level\\n', 'risk likelihood\\n', 'risk management\\n', 'risk mitigation\\n', 'risk-based testing\\n', 'robustness\\n', 'role-based  review\\n', 'root cause\\n', 'root cause analysis\\n', 'safety integrity level\\n', 'salting\\n', 'scalability\\n', 'scalability testing\\n', 'scenario-based review\\n', 'scribe\\n', 'script kiddie\\n', 'scripted testing\\n', 'scrum\\n', 'security\\n', 'security  testing\\n', 'security attack\\n', 'security audit\\n', 'security policy\\n', 'security procedure\\n', 'security risk\\n', 'security vulnerability\\n', 'sequential development  model\\n', 'service virtualization\\n', 'session-based  test  management\\n', 'session-based  testing\\n', 'severity\\n', 'short-circuiting\\n', 'sign change coverage\\n', 'sign-sign coverage\\n', 'simulator\\n', 'smoke test\\n', 'social engineering\\n', 'softwa  e development  lifecycle\\n', 'software  in the  loop\\n', 'software  lifecycle\\n', 'software  process  improvement\\n', 'software qualification  test\\n', 'Software Usability Measurement  Inventory\\n', 'source test case\\n', 'specification  by  example\\n', 'spike testing\\n', 'SQL injection\\n', 'staged representation\\n', 'standard\\n', 'standard-compliant test strategy\\n', 'state transition testing\\n', 'statement\\n', 'statement coverage\\n', 'statement testing\\n', 'static  analysis\\n', 'static testing\\n', 'stress testing\\n', 'structural coverage\\n', 'structured  scripting\\n', 'stub\\n', 'summative  evaluation\\n', 'System  Usability  Scale\\n', 'system hardening\\n', 'system integration testing\\n', 'system of  systems\\n', 'system qualification test\\n', 'system testing\\n', 'system under test\\n', 'Systematic  Test  and Evaluation  Process\\n', 'technical review\\n', 'test\\n', 'test adaptation layer\\n', 'test analysis\\n', 'test approach\\n', 'test architect\\n', 'test automation\\n', 'test automation  architecture\\n', 'test automation  engineer\\n', 'test automation  framework\\n', 'test automation  manager\\n', 'test automation  solution\\n', 'test automation  strategy\\n', 'test basis\\n', 'test case\\n', 'test case explosion\\n', 'test charter\\n', 'test closure\\n', 'test completion\\n', 'test completion report\\n', 'test condition\\n', 'test control\\n', 'test cycle\\n', 'test data\\n', 'test data preparation\\n', 'test data preparation  tool\\n', 'test definition layer\\n', 'test design\\n', 'test design specification\\n', 'test director\\n', 'test environment\\n', 'test estimation\\n', 'test execution\\n', 'test execution  schedule\\n', 'test execution automation\\n', 'test execution layer\\n', 'test execution tool\\n', 'test generation  layer\\n', 'test harness\\n', 'test hook\\n', 'test implementation\\n', 'test improvement  plan\\n', 'test infrastructure\\n', 'test item\\n', 'test leader\\n', 'test level\\n', 'test log\\n', 'test logging\\n', 'test management\\n', 'test management tool\\n', 'test manager\\n', 'Test Maturity Model integration\\n', 'test mission\\n', 'test model\\n', 'test monitoring\\n', 'test object\\n', 'test objective\\n', 'test plan\\n', 'test planning\\n', 'Test Point Analysis\\n', 'test policy\\n', 'test procedure\\n', 'test process\\n', 'test process  improvement  manifesto\\n', 'test process improvement\\n', 'test process improver\\n', 'test progress report\\n', 'test pyramid\\n', 'test report\\n', 'test reporting\\n', 'test result\\n', 'test run\\n', 'test schedule\\n', 'test script\\n', 'test selection criteria\\n', 'test session\\n', 'test specification\\n', 'test strategy\\n', 'test suite\\n', 'test technique\\n', 'test tool\\n', 'test type\\n', 'test-driven development\\n', 'test-first approach\\n', 'testability\\n', 'tester\\n', 'testing\\n', 'testware\\n', 'think aloud usability testing\\n', 'think time\\n', 'threshold  coverage\\n', 'time behavior\\n', 'Total Quality  Management\\n', 'tour\\n', 'TPI  Next\\n', 'traceability\\n', 'traceability  matrix\\n', 'transactional analysis\\n', 'transcendent-based quality\\n', 'unit test framework\\n', 'usability\\n', 'usability  evaluation\\n', 'usability  lab\\n', 'usability  requirement\\n', 'usability test participant\\n', 'usability test script\\n', 'usability test session\\n', 'usability test task\\n', 'usability testing\\n', 'user  interface\\n', 'user acceptance  testing\\n', 'user error  protection\\n', 'user experience\\n', 'user interface aesthetics\\n', 'user interface guideline\\n', 'user story\\n', 'user story testing\\n', 'user survey\\n', 'user-agent based testing\\n', 'user-based  quality\\n', 'V-model\\n', 'validation\\n', 'value change coverage\\n', 'value-based  quality\\n', 'values of several parameters\\n', 'verification\\n', 'virtual test environment\\n', 'virtual user\\n', 'visual testing\\n', 'vulnerability  scanner\\n', 'walkthrough\\n', 'Web Content  Accessibility  Guidelines\\n', 'Website Analysis and Measurement  Inventory\\n', 'white-box  test technique\\n', 'white-box testing\\n', 'Wideband  Delphi\\n', 'wild pointer\\n', 'XiL  test environment\\n']\n",
            "1543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRIV_yn5Inrh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6920c209-dc41-4e3c-a88f-1ac23c71a5fd"
      },
      "source": [
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type=='train'].summary.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=512, #256\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type=='val'].summary.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=512, #256\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(df[df.data_type=='val'].label.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2393: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi0fSX43Inrk"
      },
      "source": [
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSOqSf20Inrm",
        "outputId": "127f1234-f4e5-4fcd-ccbc-3d3791f95476"
      },
      "source": [
        "len(dataset_train), len(dataset_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1352, 239)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8NRA_j2Inrr",
        "outputId": "22172437-ce6f-4edc-ce25-bbd367045d5c"
      },
      "source": [
        "#model = BertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", #\"allenai/scibert_scivocab_uncased\", #\"bert-base-uncased\",\n",
        "#                                                      num_labels=len(label_dict),\n",
        "#                                                      output_attentions=False,\n",
        "#                                                      output_hidden_states=False)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-base\", #\"allenai/scibert_scivocab_uncased\", #\"bert-base-uncased\",\n",
        "                                                            num_labels=len(label_dict),\n",
        "                                                            output_attentions=False,\n",
        "                                                            output_hidden_states=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Mfi7gVzDFAG",
        "outputId": "077fd40f-f0f8-4b66-a4ad-5ef0baf083e3"
      },
      "source": [
        "print(\"[ BEFORE ] tokenizer vocab size:\", len(tokenizer))\n",
        "added_tokens = tokenizer.add_tokens(new_tokens)\n",
        "\n",
        "print(\"[ AFTER ] tokenizer vocab size:\", len(tokenizer))\n",
        "print()\n",
        "print('added_tokens:',added_tokens)\n",
        "print()\n",
        "\n",
        "# resize the embeddings matrix of the model\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ BEFORE ] tokenizer vocab size: 30522\n",
            "[ AFTER ] tokenizer vocab size: 31948\n",
            "\n",
            "added_tokens: 1426\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(31948, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHno3bWzInrv"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 3\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train,\n",
        "                              sampler=RandomSampler(dataset_train),\n",
        "                              batch_size=batch_size)\n",
        "\n",
        "dataloader_validation = DataLoader(dataset_val,\n",
        "                                   sampler=SequentialSampler(dataset_val),\n",
        "                                   batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVxhNH0CInrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9fa203e-099c-4633-f6f1-81ddb9838c88"
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=1e-5,\n",
        "                  eps=1e-8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yyd6VE3Inrz"
      },
      "source": [
        "epochs = 5\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=len(dataloader_train)*epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xtxw9fyBInr2"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
        "\n",
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQNkQTBhInr5"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhZwaykYInr7",
        "outputId": "a3f5db7d-f7d6-4760-e4e1-4612d8e41c39"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6t4vsdjInr_"
      },
      "source": [
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "\n",
        "    for batch in dataloader_val:\n",
        "\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "\n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "\n",
        "    loss_val_avg = loss_val_total/len(dataloader_val)\n",
        "\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "\n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tAQsG84InsD"
      },
      "source": [
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    loss_train_total = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
        "    for batch in progress_bar:\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "\n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        loss_train_total += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "\n",
        "\n",
        "    torch.save(model.state_dict(), f'finetuned_BERT_epoch_{epoch}.model')\n",
        "\n",
        "    tqdm.write(f'\\nEpoch {epoch}')\n",
        "\n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "\n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score (Weighted): {val_f1}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roVPOv6zInsG",
        "scrolled": false
      },
      "source": [
        "#model = BertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\",#\"allenai/scibert_scivocab_uncased\", #\"bert-base-uncased\",\n",
        "#                                                      num_labels=len(label_dict),\n",
        "#                                                      output_attentions=False,\n",
        "#                                                      output_hidden_states=False)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-base\",#\"allenai/scibert_scivocab_uncased\", #\"bert-base-uncased\",\n",
        "                                                            num_labels=len(label_dict),\n",
        "                                                            output_attentions=False,\n",
        "                                                            output_hidden_states=False)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2YtAP_5InsI"
      },
      "source": [
        "model.load_state_dict(torch.load('finetuned_BERT_epoch_5.model', map_location=torch.device('cuda')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxuefcj2InsK"
      },
      "source": [
        "_, predictions, true_vals = evaluate(dataloader_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU80BMwEInsN",
        "outputId": "71649d92-8bbe-49d5-d55b-b87ba7eb4779"
      },
      "source": [
        "accuracy_per_class(predictions, true_vals)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class: non-feature containing\n",
            "Accuracy: 170/182\n",
            "\n",
            "Class: feature containing\n",
            "Accuracy: 39/57\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hsbj06-3_62j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dVIh5jsInsT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "be3443cd-3efb-4156-b36f-7c4b84d24d7a",
        "collapsed": true
      },
      "source": [
        "# Clasificacion de New Feature\n",
        "a = df[['summary', 'type', 'data_type']]\n",
        "#print(a)\n",
        "filter1 = a[\"data_type\"]==\"val\"\n",
        "filter2 = a[\"type\"]==\"feature containing\"\n",
        "a.where(filter1 & filter2, inplace = True)\n",
        "b = a.dropna()\n",
        "print(b)\n",
        "b.to_csv('new_feature_val.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d92e145171c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Clasificacion de New Feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'summary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(a)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfilter1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfilter2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"feature containing\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "I2EODVms_GG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvCPDRBg94r7"
      },
      "source": [
        "def verify_modal_verb(text, model=nlp):\n",
        "    # Create doc object\n",
        "    doc = model(text)\n",
        "    modal = False\n",
        "\n",
        "    # Generate list of POS tags\n",
        "    for token in doc:\n",
        "        if token.text in ('can', 'could', 'may', 'might', 'shall', 'should', 'will', 'would', 'must') :\n",
        "           modal = True\n",
        "           break\n",
        "\n",
        "    pos = [token.pos_ for token in doc]\n",
        "    #print(pos)\n",
        "\n",
        "    # Return number of proper nouns\n",
        "    if pos.count('VERB') > 0 and modal == True :\n",
        "       return 1\n",
        "    else :\n",
        "       return 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdfnIuD9-epk",
        "outputId": "bf640af0-c1ce-4f6b-ebf8-4094fe61f32c"
      },
      "source": [
        "df1 = pd.read_csv('new_feature_val.csv')\n",
        "cont_good_class_nf = 0\n",
        "cont_bad_class_nf = 0\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    print(row['summary'])\n",
        "    print(verify_modal_verb(row['summary']))\n",
        "    row['summary'] = row['summary'].lower()\n",
        "\n",
        "    if verify_modal_verb(row['summary']) == 1:\n",
        "       cont_good_class_nf = cont_good_class_nf + 1\n",
        "    else:\n",
        "       cont_bad_class_nf = cont_bad_class_nf + 1\n",
        "\n",
        "print('Nro de regs bien clasificados NF: ', cont_good_class_nf)\n",
        "print('Nro de regs mal clasificados NF: ', cont_bad_class_nf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "other properties  expose properties  expose properties in storyreporterbuilder\n",
            "0\n",
            "screencast com  click story name  \n",
            "0\n",
            "dallas geeknight  add crossreference report  \n",
            "0\n",
            "story timeout  allow configuration is via embeddercontrols allow configuration of storytimeoutinsecs\n",
            "0\n",
            "  provide extension  provide extension of embeddercontrols\n",
            "0\n",
            "composite step   executing of sub steps \n",
            "0\n",
            "generic parameter converter generic parameter converter for enum classes convert enum fields  \n",
            "0\n",
            "dependency injection support for weld context framework provide support  provide support for cdi context injection\n",
            "0\n",
            " override of embedder methods add extension  add extension of embedder\n",
            "0\n",
            "annotated embedder  run stories run with embedder goal run stories with annotated embedder\n",
            "0\n",
            "  organise stories  \n",
            "0\n",
            "afterstories xml  break plugin afterstories xml  have invalid xml on occasion\n",
            "0\n",
            "storyreporter calls m opening browsers in saucelabs need way  \n",
            "0\n",
            "  load resources  have loadfromclasspath as default resourceloader\n",
            "0\n",
            "pending annotation  provide pending annotation  \n",
            "0\n",
            "null entries  specifying meta filters  \n",
            "0\n",
            "  enqueue stories  \n",
            "0\n",
            "utility methods  using matcherassert depend on unit framework assertions \n",
            "0\n",
            " line in multiline steps require space work without space require space before new line\n",
            "0\n",
            "  have multiple scenarios  have multiple scenarios in story\n",
            "0\n",
            "  have many scenarios  see output from broken scenarios\n",
            "0\n",
            "stack issue  improve regex suffer from regex provide alternative implementation of scenario parser\n",
            "0\n",
            "custom converters custom converters as developer provide converters convert from string \n",
            "0\n",
            "file paths  viewing fails use for separator normalising paths viewing fails on windows\n",
            "0\n",
            " aliases for steps introduce aliases  introduce aliases for steps\n",
            "0\n",
            "  has narrative  \n",
            "0\n",
            "pending steps  break build  break build with pending steps\n",
            "0\n",
            "unarchived files  compress test moving to commons \n",
            "0\n",
            "natural order  support scenario templates  \n",
            "0\n",
            "story titles  has title  see title in output\n",
            "0\n",
            "utility class steps from classpath look resources keeping with dry principle look resources in scenario\n",
            "0\n",
            "  add monitoring  allow monitoring of runtime events\n",
            "0\n",
            "  generate stepdoc  generate stepdoc from annotated methods\n",
            "0\n",
            "w w z regexp in dollarsteppatternbuilder have chars allows for empty markers have chars of length\n",
            "0\n",
            "data file  need tmpdir  need tmpdir as upload directory\n",
            "0\n",
            "archive content  view actual contents viewing of unarchived file contents view actual contents of unarchived files\n",
            "0\n",
            "newline escape  has wrong order  has wrong order of line separator\n",
            "0\n",
            "based storyloader based storyloader as story developer load stories  load stories via urls\n",
            "0\n",
            "file name cellswith with neighbours find scenarios  find scenarios with numbers\n",
            "0\n",
            "jbehave code  improve javadocs  \n",
            "0\n",
            "systems e path of tmpdir using relative paths  \n",
            "0\n",
            "candidatesteps interface  candidatesteps interface  allow composition over inheritance\n",
            "0\n",
            "real parameter names real parameter names via paranamer jbehave   \n",
            "0\n",
            "multi scenario beforescenario as developer reset state  reset state after scenario\n",
            "0\n",
            "same title  title scenarios appear in output title scenarios before scenario\n",
            "0\n",
            "    \n",
            "0\n",
            "undoable steps  set context set up context \n",
            "0\n",
            "available source  find test 's in jar \n",
            "0\n",
            "consistent adopt consistent adopt with convention specify build specification  \n",
            "0\n",
            "groovy bindings groovy bindings for adriano bonat thoughtworker invoking step methods  \n",
            "0\n",
            "  allow filtering  allow filtering of stories\n",
            "0\n",
            "step creation creation concern from steps stepcreator creation concern  stepcreator creation concern from steps\n",
            "0\n",
            "webdriver api support for webdriver api add support  add support for webdriver api\n",
            "0\n",
            "givenstory finishes  execute scenarios  execute scenarios within story\n",
            "0\n",
            " newlines between rows fix rendering  fix rendering of newlines\n",
            "0\n",
            "support htmlunit support htmlunit in propertywebdriverprovider add browser enum html  support htmlunitwebdriver via value html\n",
            "0\n",
            "pluggable strategy  resolve file paths  resolve file paths for directory\n",
            "0\n",
            "different names  add selenium webdriversteps capture upon failing scenario add instances of selenium webdriversteps\n",
            "0\n",
            "usingguice pico   be via annotations \n",
            "0\n",
            "webdriver instance  extending separate method  \n",
            "0\n",
            "rename embeddedstory flag name of boolean flag supports running givenstories  avoid confusion with storyembedder\n",
            "0\n",
            "common use case  find paths add to storyfinder method find paths by url code location\n",
            "0\n",
            "story name story name in report sells stocks  \n",
            "0\n",
            "maven goals  requires explicit annotation requiresdependencyresolution  resolve dependencies in abstractembeddermojo\n",
            "0\n",
            "grammer definition  details availability is in real terms \n",
            "0\n",
            "  running givenstory behaviour  \n",
            "0\n",
            "  add configurable sorting strategies  add configurable sorting strategies for stories\n",
            "0\n",
            "confusion change terminology of report view generation rendering to stories \n",
            "0\n",
            "getter setter getter setter for filepathresolver add getter setter missing from springstoryreporterbuilder add getter setter for filepathresolver\n",
            "0\n",
            " declaration of abstract beans instantiate spring  \n",
            "0\n",
            "significant digits  makes type representation fails for numbers makes type representation like e\n",
            "0\n",
            "default json  add format json format  \n",
            "0\n",
            "  have complex scenarios  have complex scenarios with use\n",
            "0\n",
            "zh cn properties with keywords map add support  add support for simplified chinese locale\n",
            "0\n",
            "  perform manipulations  \n",
            "0\n",
            "default value  changing value separator  changing value separator of jbehave\n",
            "0\n",
            "  provide default constructor  \n",
            "0\n",
            "date formats configurable formats for value types   \n",
            "0\n",
            "html output    \n",
            "0\n",
            "  provide default values  provide default values for separators instantiation\n",
            "0\n",
            "russian keywords support for russian locale add support  add support for russian locale\n",
            "0\n",
            "specified delegate  add storynameresolver iterates through configurable number \n",
            "0\n",
            "story level  contains scenarios  \n",
            "0\n",
            "  close storydurations  \n",
            "0\n",
            "own threadlocal stuff    \n",
            "0\n",
            "custom implementations custom implementations of metamatcher setup custom  \n",
            "0\n",
            "snapshots releases  use local nexus work around https issues \n",
            "0\n",
            "cross reference  add start  see start of stories scenarios\n",
            "0\n",
            "  annotation requirement analysts  annotation requirement analysts at company\n",
            "0\n",
            "results problem  add flaky status  \n",
            "0\n",
            " map of story sauce urls  \n",
            "0\n",
            "filter code  have story elements filtering on story elements \n",
            "0\n",
            "interop saucelabs  improve saucelabs settings be by system property \n",
            "0\n",
            "web interface  manage run context submit in background multiple stories manage run context of multiple stories\n",
            "0\n",
            "scenario title  parse scenario title works on other platforms \n",
            "0\n",
            "  add saucelabs contextview  \n",
            "0\n",
            "  have separate plugins  track different versions of tools\n",
            "0\n",
            "saucelabs saucelabs   robustness around job timeout \n",
            "0\n",
            "non spring  fix typos  fix typos in archetypes\n",
            "0\n",
            "  ignoring failures  ignoring failures in stories reports\n",
            "0\n",
            "step failures  view generation  cause build failure in view generation\n",
            "0\n",
            "jbehave story cancellations  add keywords  add keywords for story cancellation\n",
            "0\n",
            "flashdriver javascript    \n",
            "0\n",
            "templateable output  provide xml similar template  \n",
            "0\n",
            "httpcommandexecutor wrapcommandexecutor httpcommandexecutor wrapping of selenium commandexecutor implement following httpcommandexecutor httpcommandexecutor  implement following httpcommandexecutor httpcommandexecutor in saucelabs provider\n",
            "0\n",
            "oo separation format as factory kill format class is as result \n",
            "0\n",
            "fatal outcome  avoid outcome runtime exceptions play with ci systems \n",
            "0\n",
            " support with annotation support e g  support e g with tag\n",
            "0\n",
            "cross reference  add standalone reference navigator  allows navigation of report output\n",
            "0\n",
            "long start calculation of stories   \n",
            "0\n",
            "  support alternative narrative syntax  \n",
            "0\n",
            "formatting table  transformer tabletransformer according to max width \n",
            "0\n",
            "story editor   work in editor spell checking \n",
            "0\n",
            "  add jirametamatcher  \n",
            "0\n",
            "org jbehave  has afterstep method  \n",
            "0\n",
            "normal scenario story in file using givenstories  running scenario with givenstories\n",
            "0\n",
            " steps by meta filter allow matching  allow matching of lifecycle\n",
            "0\n",
            "command ctlr add for selected formatting text formatting ctlr f  \n",
            "0\n",
            "failinguponpendingsteps strategy  run story jbehave exits work in version \n",
            "0\n",
            "  support custom implementations  support custom implementations of meta\n",
            "0\n",
            " support in turn upgrade selenium version  using jbehave web with selenium\n",
            "0\n",
            "other view types  support configurable multiple view types  \n",
            "0\n",
            " value for timeout  run without timeout \n",
            "0\n",
            "polish language    \n",
            "0\n",
            "text changes plugin for next version   \n",
            "0\n",
            "java doc  add documented annotation  containing annotated strings with test steps\n",
            "0\n",
            "finnish language  support finnish language translations  \n",
            "0\n",
            "upgrade story navigator upgrade story navigator to new xref storynavigator has anything  \n",
            "0\n",
            "odf unit   tests for odf fail \n",
            "0\n",
            "new wizard  create eclipse category  create eclipse category for jbehave\n",
            "0\n",
            "actual tag correct span for parameters contains few encoded html tags  \n",
            "0\n",
            "junit tests read from file results  linefeed on read line \n",
            "0\n",
            "localised story locale of given story allow specification allowing for story parsing allow specification of locale\n",
            "0\n",
            "misspelled xmltemplateouput  breaking current user code  \n",
            "0\n",
            "java u noclassdeffounderror in java  compiling with u results \n",
            "0\n",
            "eclipse plugin  installing new m e plugin  \n",
            "0\n",
            "textual stories  parsing story transformation  \n",
            "0\n",
            "running time  provide configurable timeout value  provide configurable timeout value for story\n",
            "0\n",
            "failinguponpendingstep strategy   work on case patch \n",
            "0\n",
            "template reports  contains special chars  contains special chars with html template code\n",
            "0\n",
            "class gherkinstoryparser  has sysout  has system near end\n",
            "0\n",
            "src test files in reporters reports   \n",
            "0\n",
            "jbehave website  needs facelifting need  update jbehave website from buildmaster\n",
            "0\n",
            "  add cglib support  add cglib support to jmock extension\n",
            "0\n",
            "behaviour discovery  discover behaviours  \n",
            "0\n",
            "velocity code generator velocity code generator for story generates classes  generates classes for given story\n",
            "0\n",
            "ant task   talk about specs \n",
            "0\n",
            "svn svn   url on website \n",
            "0\n",
            "cglib mock  integrate usingjmock  \n",
            "0\n",
            "  add dependencies  core declare dependencies in core pom\n",
            "0\n",
            "  needs intellij plugin  begin work on intellij\n",
            "0\n",
            "story code  add mojo  run generate code goal from given story\n",
            "0\n",
            "  calling usingmatchers  calling usingmatchers of usingmatchers\n",
            "0\n",
            "appropriate pattern  using narrateto  \n",
            "0\n",
            " method of same name stub method  stub method with arguments\n",
            "0\n",
            "jbehave core codebase for jbehave core   \n",
            "0\n",
            "document junitadapter document junitadapter on website use excellent eclipse hack  run current behaviour class under cursor\n",
            "0\n",
            "broken links broken links in website has couple  has couple of broken links\n",
            "0\n",
            "minute intro minute intro for jbehave needs work  needs good update before release\n",
            "0\n",
            "world keys  use enums think of reason allowing strings as world keys\n",
            "0\n",
            "scenario steps  throw exception  throw exception in signature\n",
            "0\n",
            "build script  running behaviours times picking up allbehaviours \n",
            "0\n",
            "good idea  visit outcome expectations  visit outcome expectations from scenario\n",
            "0\n",
            "non failure framework error like missing behaviour class return failure status use in batch environment \n",
            "0\n",
            "refactor storyloader  throw runtime class instantiation  \n",
            "0\n",
            "  throwing pending exception  throwing pending exception in story component\n",
            "0\n",
            "method invocation  specifying invocation expectations fail upon matched method expecations \n",
            "0\n",
            "unspecified call  fail unmatched calls waiting for verification \n",
            "0\n",
            "integration acceptance junit to behaviour test converter facilitate conversion  facilitate conversion of acceptance tests\n",
            "0\n",
            "website generator  using old api work with new buildmaster using old api for buildmaster\n",
            "0\n",
            "  add root package  generate code from story text file\n",
            "0\n",
            "jbehave maven plugin jbehave maven plugin as jbehave user type mvn jbehave  verify behaviours of system\n",
            "0\n",
            "multiple stories  includes patterns  \n",
            "0\n",
            "story parser    \n",
            "0\n",
            "plugin spanish language  add spanish language  \n",
            "0\n",
            "create project create project from archetype take standard sample story  \n",
            "0\n",
            "story execution  add configurable flag  add configurable flag in embeddercontrols\n",
            "0\n",
            "lifecycle story lifecycle in story syntax add support  add support for scenario\n",
            "0\n",
            "  use delegating model  \n",
            "0\n",
            "  add enum converters  \n",
            "0\n",
            "ignore annotation  ignores ignore annotation  \n",
            "0\n",
            " export via rest providing includes pattern export via rest \n",
            "0\n",
            "meta info gherkin  add meta tag support  provides support for tags\n",
            "0\n",
            "rest providers  add name defaulting to strategy resolving strategy for rest resources\n",
            "0\n",
            "running embeddables failures in view ignore failures  ignore failures in view\n",
            "0\n",
            "  match filters  \n",
            "0\n",
            "ignore comments ignore comments in meta jenkins  finding during transform xunit plugin \n",
            "0\n",
            "com tanob    \n",
            "0\n",
            "system properties  missing specification  missing specification of system properties\n",
            "0\n",
            "ignorable steps  generate methods  generate methods for ignorable steps\n",
            "0\n",
            "beforestories xml  causing xunit  \n",
            "0\n",
            "  starting scenario  \n",
            "0\n",
            "other way scenarios after example add support  add support for annotated steps\n",
            "0\n",
            "table parameters    \n",
            "0\n",
            "public void  throw new knownfailure corba failing without stack trace \n",
            "0\n",
            "story scenario poor version of jbehave accept parameters  have bq void mybeforestory at moment\n",
            "0\n",
            "  add failed step  add failed step as uuidexceptionwrapper message\n",
            "0\n",
            "swf object  supports invocation  supports invocation of object methods\n",
            "0\n",
            "annotated embedder   running in cli \n",
            "0\n",
            "field cause instances of printstreamoutput   \n",
            "0\n",
            "wrapped outcomesfailed exception    \n",
            "0\n",
            "multiline scenario  follows keyword scenario is over multiple lines \n",
            "0\n",
            "  defining step  \n",
            "0\n",
            "methods post  executing long scenarios  \n",
            "0\n",
            "  add stepfinder  avoid duplication of steps\n",
            "0\n",
            "table examplestable java  trailing whitespaces  \n",
            "0\n",
            "non html  rendering html reports  \n",
            "0\n",
            "candidate step  steps needs  \n",
            "0\n",
            "builder syntax builder syntax for story stepsconfiguration  make for reading \n",
            "0\n",
            "separate step pattern  produces stepmatcher parsing from matching \n",
            "0\n",
            "matched method  add method information  add method information to matching events\n",
            "0\n",
            "double nan  throws parseexception be into double nan \n",
            "0\n",
            "step configuration  improve documentation  improve documentation on scenario\n",
            "0\n",
            "starting words  starting words  \n",
            "0\n",
            "  scenarioreporter scenario reporter  \n",
            "0\n",
            " refactors in story configuration running stories  \n",
            "0\n",
            "maven ant maven ant execution of scenario provide exception fails with classloader \n",
            "0\n",
            "based configuration  allow based configuration annotations  \n",
            "0\n",
            "scenario level selenium under jbehave control  be at story \n",
            "0\n",
            "jbehave web selenium    \n",
            "0\n",
            "output scenario  handle parametrised scenarios reset at execution \n",
            "0\n",
            "beforestep method beforestep method in storyreporter add beforestep method  add beforestep method in storyreporter\n",
            "0\n",
            "support spring annotationconfigapplicationcontext patch for jbehave spring allows based spring configurations  allows based spring configurations for java annotation\n",
            "0\n",
            "numberformat instance numberformat instance in parameterconverters   \n",
            "0\n",
            "freemarker templateprocessor  load custom template loading in order specify different class for template loading\n",
            "0\n",
            "story level  require scenario  \n",
            "0\n",
            "Nro de regs bien clasificados NF:  0\n",
            "Nro de regs mal clasificados NF:  226\n"
          ]
        }
      ]
    }
  ]
}