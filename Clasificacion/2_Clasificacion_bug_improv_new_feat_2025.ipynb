{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ab2e099a3fd64426981889e6eb8dfdb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_903f94a48d6748448ac93a9b46d59b0e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_92873b8da76f418fa7f15aa09ae5b1ad",
              "IPY_MODEL_b03d2d163ba44acdbb6b55ebf1475949",
              "IPY_MODEL_1a173c05a20845bd8044b72d0335fffb"
            ]
          }
        },
        "903f94a48d6748448ac93a9b46d59b0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92873b8da76f418fa7f15aa09ae5b1ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e39ea7a566364189a9d8b6112cb1999c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6051d4dd18c4954beebbae5c6163338"
          }
        },
        "b03d2d163ba44acdbb6b55ebf1475949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_085adf9844874d64b0bf49389e3ef08a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7791072f30f64fa8b3aae6f3676268ad"
          }
        },
        "1a173c05a20845bd8044b72d0335fffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7311fa97239f4e6eaed1288f1bb331a5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 570B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb39ef5c9cdc415ea5e56e40f1472098"
          }
        },
        "e39ea7a566364189a9d8b6112cb1999c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6051d4dd18c4954beebbae5c6163338": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "085adf9844874d64b0bf49389e3ef08a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7791072f30f64fa8b3aae6f3676268ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7311fa97239f4e6eaed1288f1bb331a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb39ef5c9cdc415ea5e56e40f1472098": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6bef79c9b77d4807a7cb0f2a26340d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0e20a952006648219e4478b5421335bf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5843e60464db4ed8a811d3c070b5c0e3",
              "IPY_MODEL_b1bd72c4832346598abaac69da811ebf",
              "IPY_MODEL_d84bd636dfb944d8a567f747039a55fc"
            ]
          }
        },
        "0e20a952006648219e4478b5421335bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5843e60464db4ed8a811d3c070b5c0e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_154f7c3acfe34f708bae616378feae35",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_10dcb88aff394dcda50bc94532d9481d"
          }
        },
        "b1bd72c4832346598abaac69da811ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_08b61133d5704c5d917936ba46d7b297",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1f4c899c2284bb292bd78395b9c0091"
          }
        },
        "d84bd636dfb944d8a567f747039a55fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_479ff166501e4ecfb568cb6ea448ddd4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 1.21MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1fbecb3523344adbdfb959a797a9fa3"
          }
        },
        "154f7c3acfe34f708bae616378feae35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "10dcb88aff394dcda50bc94532d9481d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08b61133d5704c5d917936ba46d7b297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1f4c899c2284bb292bd78395b9c0091": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "479ff166501e4ecfb568cb6ea448ddd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1fbecb3523344adbdfb959a797a9fa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c14c8c3e07f3441fba53215616fa2fab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ec465e1695404cbaa033f7091996b456",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_878797b5eebd4db6bf1af7bd98dd254a",
              "IPY_MODEL_0affb2a5bf5247959cc147c648c0934c",
              "IPY_MODEL_8c03bd440cb547eb90d8f027f867c6b6"
            ]
          }
        },
        "ec465e1695404cbaa033f7091996b456": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "878797b5eebd4db6bf1af7bd98dd254a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4c5fad33f068408a94962dd91a3d7330",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f711bdcffa5484486fe80114a19b0e4"
          }
        },
        "0affb2a5bf5247959cc147c648c0934c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5ae08fa3cb2047329ffc680ffccbbf1a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_89a8dd3846c046c3a8ce22849d1e4f48"
          }
        },
        "8c03bd440cb547eb90d8f027f867c6b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1e030210df4740088cd3c8e97cb7f4eb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 455k/455k [00:00&lt;00:00, 1.70MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a779491eb1ee434da7e56316e66710d1"
          }
        },
        "4c5fad33f068408a94962dd91a3d7330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f711bdcffa5484486fe80114a19b0e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ae08fa3cb2047329ffc680ffccbbf1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "89a8dd3846c046c3a8ce22849d1e4f48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e030210df4740088cd3c8e97cb7f4eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a779491eb1ee434da7e56316e66710d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f282be2cdbb4f0d8d53369f545803de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ac49e5428a77425e83482073885e2652",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5cac0b6c5ff84ac38b8a70faad3c29c5",
              "IPY_MODEL_23e27f0d7ca4420b9389676f29189958",
              "IPY_MODEL_89626bda3a644c9fb87bb4f6ea537bdf"
            ]
          }
        },
        "ac49e5428a77425e83482073885e2652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cac0b6c5ff84ac38b8a70faad3c29c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_904df4cbf9d04f33b6ed3121152d3be1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cf4c1fcb0ff542f2875b61accca4af31"
          }
        },
        "23e27f0d7ca4420b9389676f29189958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a24403d9d1244447af44ddd7ba4a9ce3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 483,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 483,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d4fe851bfee40a29371697ba16243b5"
          }
        },
        "89626bda3a644c9fb87bb4f6ea537bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_85cb167213aa4bb2a1fc735b8ec93dbd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 483/483 [00:00&lt;00:00, 10.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7d779653ab64d81804b02f79aad30e5"
          }
        },
        "904df4cbf9d04f33b6ed3121152d3be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cf4c1fcb0ff542f2875b61accca4af31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a24403d9d1244447af44ddd7ba4a9ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d4fe851bfee40a29371697ba16243b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85cb167213aa4bb2a1fc735b8ec93dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e7d779653ab64d81804b02f79aad30e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81afe9d03b924f9386967bf85525a126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_082a8f8bd1ac4431b1c27fc058481a16",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c7e3e9bc35c845ddac17e5200017e5f4",
              "IPY_MODEL_ac3a788f71564cecac783e9227d4fcaa",
              "IPY_MODEL_c6ca7cc820d5440f893b09dce1f19242"
            ]
          }
        },
        "082a8f8bd1ac4431b1c27fc058481a16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c7e3e9bc35c845ddac17e5200017e5f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6a31dbed9efd4a738da740424b776e3c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8dd51dd5c0d4fdca45b5db418b30bda"
          }
        },
        "ac3a788f71564cecac783e9227d4fcaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2841c57a9e92411cbeae549d673316e1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f710842104c4864bd335a4637fa7b78"
          }
        },
        "c6ca7cc820d5440f893b09dce1f19242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9be7727650e34e3398b3f01559835410",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 256M/256M [00:09&lt;00:00, 27.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_141cadc927864bca9a80264e029ce9a1"
          }
        },
        "6a31dbed9efd4a738da740424b776e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8dd51dd5c0d4fdca45b5db418b30bda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2841c57a9e92411cbeae549d673316e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f710842104c4864bd335a4637fa7b78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9be7727650e34e3398b3f01559835410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "141cadc927864bca9a80264e029ce9a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francotejada/Automatic-Traceability/blob/main/Clasificacion/2_Clasificacion_bug_improv_new_feat_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNvs5noJlVz3",
        "outputId": "4c53dc45-dc2f-42c4-cd9a-609fe585af6d"
      },
      "source": [
        "# install the requirements\n",
        "!pip install spacy\n",
        "#!python -m spacy download es_core_news_md\n",
        "#!python -m spacy download en_core_web_md\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "!pip install torch\n",
        "!pip install transformers\n",
        "#!pip install contextualSpellCheck\n",
        "#!pip install textblob\n",
        "!pip install wordninja"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.10.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.16.1-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 63.3 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 43.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 73.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.16.1\n",
            "Collecting wordninja\n",
            "  Downloading wordninja-2.0.0.tar.gz (541 kB)\n",
            "\u001b[K     |████████████████████████████████| 541 kB 5.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: wordninja\n",
            "  Building wheel for wordninja (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wordninja: filename=wordninja-2.0.0-py3-none-any.whl size=541551 sha256=097fd270a764251ec385574e9bc2f3225b610cb449cb218394662a7a69b09cf0\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/3f/eb/a2692e3d2b9deb1487b09ba4967dd6920bd5032bfd9ff7acfc\n",
            "Successfully built wordninja\n",
            "Installing collected packages: wordninja\n",
            "Successfully installed wordninja-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j7U-l1alwCV"
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from transformers import AutoTokenizer #DistilBertTokenizer # BertTokenizer\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification # DistilBertForSequenceClassification #BertForSequenceClassification\n",
        "\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrLGKfVUupfP",
        "outputId": "3f2c4b04-5f58-42ac-836d-b96602e15081"
      },
      "source": [
        "# TEST\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "# Function checks if the string\n",
        "# contains any special character\n",
        "def check_token_accepted(string):\n",
        "\n",
        "    special_characters = \"!@#$%^&*()-+?_=,<>\\/\"\n",
        "    s=string\n",
        "    # Example: $tackoverflow\n",
        "\n",
        "    if any(c in special_characters for c in s):\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "def clean_tokens_special_char(string):\n",
        "    out = ''\n",
        "    for word in string.split():\n",
        "        if check_token_accepted(word) == 1:\n",
        "           out = out + word + ' '\n",
        "    return(out)\n",
        "\n",
        "sen = 'Newline escape has the wrong order of \\n\\r CandidateStep value.replaceAll(\"\"(\\n)|(\\r\\n)\"\", System.getProperty(\"\"line.separator\"\")); must be: value.replaceAll(\"\"(\\n)|(\\n\\r)\"\", System.getProperty(\"\"line.separator\"\"));'\n",
        "sen1 = \"that don't need to be in a stack\"\n",
        "print(clean_tokens_special_char(sen))\n",
        "\n",
        "for t in sen1.split(\" \"):\n",
        "  print(t)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Newline escape has the wrong order of CandidateStep must be: \n",
            "that\n",
            "don't\n",
            "need\n",
            "to\n",
            "be\n",
            "in\n",
            "a\n",
            "stack\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnG6qmikmxgk"
      },
      "source": [
        "import re\n",
        "from typing import List\n",
        "import wordninja\n",
        "import pandas as pd\n",
        "\n",
        "import spacy\n",
        "from spacy.tokens import Doc\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "class SpacyPreprocessor:\n",
        "    def __init__(\n",
        "        self,\n",
        "        spacy_model=None,\n",
        "        #remove_numbers=False,\n",
        "        remove_numbers=True,\n",
        "        remove_special=True,\n",
        "        pos_to_remove=None,\n",
        "        #remove_stopwords=False,\n",
        "        remove_stopwords=True,\n",
        "        lemmatize=False,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Preprocesses text using spaCy\n",
        "        :param remove_numbers: Whether to remove numbers from text\n",
        "        :param remove_stopwords: Whether to remove stopwords from text\n",
        "        :param remove_special: Whether to remove special characters (including numbers)\n",
        "        :param pos_to_remove: list of PoS tags to remove\n",
        "        :param lemmatize:  Whether to apply lemmatization\n",
        "        \"\"\"\n",
        "\n",
        "        self._remove_numbers = remove_numbers\n",
        "        self._pos_to_remove = pos_to_remove\n",
        "        self._remove_stopwords = remove_stopwords\n",
        "        self._remove_special = remove_special\n",
        "        self._lemmatize = lemmatize\n",
        "\n",
        "        if not spacy_model:\n",
        "            self.model = spacy.load(\"en_core_web_sm\")\n",
        "        else:\n",
        "            self.model = spacy_model\n",
        "\n",
        "    @staticmethod\n",
        "    def download_spacy_model(model=\"en_core_web_sm\"):\n",
        "        print(f\"Downloading spaCy model {model}\")\n",
        "        spacy.cli.download(model)\n",
        "        print(f\"Finished downloading model\")\n",
        "\n",
        "    @staticmethod\n",
        "    def load_model(model=\"en_core_web_sm\"):\n",
        "        return spacy.load(model, disable=[\"ner\", \"parser\"])\n",
        "\n",
        "    def tokenize(self, text) -> List[str]:\n",
        "        \"\"\"\n",
        "        Tokenize text using a spaCy pipeline\n",
        "        :param text: Text to tokenize\n",
        "        :return: list of str\n",
        "        \"\"\"\n",
        "        doc = self.model(text)\n",
        "        return [token.text for token in doc]\n",
        "\n",
        "    def preprocess_text(self, text) -> str:\n",
        "        \"\"\"\n",
        "        Runs a spaCy pipeline and removes unwanted parts from text\n",
        "        :param text: text string to clean\n",
        "        :return: str, clean text\n",
        "        \"\"\"\n",
        "        doc = self.model(text)\n",
        "        return self.__clean(doc)\n",
        "\n",
        "    def preprocess_text2(self, text) -> str:\n",
        "        \"\"\"\n",
        "        Runs a spaCy pipeline and removes unwanted parts from text\n",
        "        :param text: text string to clean\n",
        "        :return: str, clean text\n",
        "        \"\"\"\n",
        "        doc = self.model(text)\n",
        "        return self.__clean2(doc)\n",
        "\n",
        "    def preprocess_text_list(self, texts=List[str]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Runs a spaCy pipeline and removes unwantes parts from a list of text.\n",
        "        Leverages spaCy's `pipe` for faster batch processing.\n",
        "        :param texts: List of texts to clean\n",
        "        :return: List of clean texts\n",
        "        \"\"\"\n",
        "        clean_texts = []\n",
        "        for doc in tqdm(self.model.pipe(texts)):\n",
        "            clean_texts.append(self.__clean(doc))\n",
        "\n",
        "        return clean_texts\n",
        "\n",
        "    def __clean(self, doc: Doc) -> str:\n",
        "\n",
        "        tokens = []\n",
        "        # POS Tags removal\n",
        "        if self._pos_to_remove:\n",
        "            for token in doc:\n",
        "                if token.pos_ not in self._pos_to_remove:\n",
        "                    tokens.append(token)\n",
        "        else:\n",
        "            tokens = doc\n",
        "\n",
        "        # Remove Numbers\n",
        "        if self._remove_numbers:\n",
        "            tokens = [\n",
        "                token for token in tokens if not (token.like_num or token.is_currency)\n",
        "            ]\n",
        "\n",
        "        # Remove Stopwords\n",
        "        if self._remove_stopwords:\n",
        "            tokens = [token for token in tokens if not token.is_stop]\n",
        "        # remove unwanted tokens\n",
        "        tokens = [\n",
        "            token\n",
        "            for token in tokens\n",
        "            if not (\n",
        "                token.is_punct or token.is_space or token.is_quote or token.is_bracket #or len(token) > 30\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        # Remove empty tokens\n",
        "        tokens = [token for token in tokens if token.text.strip() != \"\"]\n",
        "\n",
        "        # Lemmatize\n",
        "        if self._lemmatize:\n",
        "            text = \" \".join([token.lemma_ for token in tokens])\n",
        "        else:\n",
        "            text = \" \".join([token.text for token in tokens])\n",
        "\n",
        "        if self._remove_special:\n",
        "            # Remove non alphabetic characters\n",
        "            text = re.sub(r\"[^a-zA-Z\\']\", \" \", text)\n",
        "        # remove non-Unicode characters\n",
        "        text = re.sub(r\"[^\\x00-\\x7F]+\", \"\", text)\n",
        "\n",
        "        text = text.lower()\n",
        "\n",
        "        return text\n",
        "\n",
        "    def __clean2(self, doc: Doc) -> str:\n",
        "\n",
        "        tokens = []\n",
        "\n",
        "        tokens = doc\n",
        "\n",
        "        tokens = [\n",
        "                token for token in tokens if not (token.like_num or token.is_currency)\n",
        "        ]\n",
        "\n",
        "        # Remove empty tokens\n",
        "        tokens = [token for token in tokens if token.text.strip() != \"\" or len(token) > 30]\n",
        "\n",
        "        text = \" \".join([token.text for token in tokens])\n",
        "\n",
        "        # Remove non alphabetic characters\n",
        "        text = re.sub(r\"[^a-zA-Z\\']\", \" \", text)\n",
        "\n",
        "        # remove non-Unicode characters\n",
        "        text = re.sub(r\"[^\\x00-\\x7F]+\", \"\", text)\n",
        "\n",
        "        text = text.lower()\n",
        "\n",
        "        return doc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nS87Z4AwbUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9e5cbfe-f743-4d67-d9b9-e19f8d159e06"
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "from spacy import displacy\n",
        "import re\n",
        "#from textblob import TextBlob\n",
        "#import wordninja\n",
        "#import contextualSpellCheck\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    spacy_model = SpacyPreprocessor.load_model()\n",
        "    preprocessor = SpacyPreprocessor(spacy_model=spacy_model, lemmatize=True, remove_numbers=True, remove_stopwords=True)\n",
        "\n",
        "    #clean_text = preprocessor.preprocess_text(\"spaCy is awesome! 123\")\n",
        "    #print(clean_text)\n",
        "\n",
        "    #df = pd.read_csv('jbehave_all.csv')\n",
        "    df = pd.read_csv('axis2.sqlite3.csv')\n",
        "    df.head()\n",
        "    #print(df['summary'])\n",
        "\n",
        "    texto = df.loc[:,\"summary\"]\n",
        "    tipo = df.loc[:,\"type\"]\n",
        "\n",
        "    cols = np.array(texto)\n",
        "    cols2 = np.array(tipo)\n",
        "\n",
        "    file =\"jbehave_cleaned.csv\"\n",
        "\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    #nlp = spacy.load(\"en_core_web_md\")\n",
        "    #en_core_web_sm\n",
        "\n",
        "    #contextualSpellCheck.add_to_pipe(nlp)\n",
        "\n",
        "    #doc = nlp(\"This is a sentence.\")\n",
        "    #displacy.serve(doc, style=\"dep\")\n",
        "\n",
        "    with open(file,\"w\", newline='', encoding='utf8') as rf:\n",
        "        fieldnames=['summary','type']\n",
        "\n",
        "        writer= csv.DictWriter(rf,fieldnames=fieldnames)\n",
        "        writer.writerow({'summary':'summary','type':'type'})\n",
        "\n",
        "        for i in range(0,len(cols)):\n",
        "            #texto_col = cols[i].split(\" \")\n",
        "            # 06.09.2021 print(cols[i], ' ')\n",
        "            #clean_text = preprocessor.preprocess_text(cols[i])\n",
        "            clean_text = re.sub(r'{code}.*$', \"\", cols[i])\n",
        "\n",
        "            clean_text = re.sub(r'{noformat}.*$', \"\", cols[i])\n",
        "\n",
        "            # Remove URLs\n",
        "            clean_text = re.sub(\"(?P<url>https?://[^\\s]+)0123456789\", '', clean_text, flags=re.MULTILINE)\n",
        "\n",
        "            # Elimina tokens con caracteres especiales\n",
        "            clean_text = clean_tokens_special_char(clean_text)\n",
        "\n",
        "            clean_text = preprocessor.preprocess_text2(clean_text)\n",
        "            print(clean_text)\n",
        "\n",
        "            # FT 21.10.2021\n",
        "            #clean_text = re.sub(' +', ' ',clean_text)\n",
        "\n",
        "            #doc = nlp(clean_text)\n",
        "            #print(doc._.outcome_spellCheck)\n",
        "            #writer.writerow({'summary':doc._.outcome_spellCheck,'type':cols2[i]})\n",
        "\n",
        "            # 06 09 2021 #\n",
        "            #text = wordninja.split(clean_text)\n",
        "            #text = TextBlob(str(text))\n",
        "\n",
        "            # FT 21.10.2021\n",
        "            #clean_text = clean_text.replace(',', '')\n",
        "\n",
        "            #print(i, ' ')\n",
        "            #print(i, ' ')\n",
        "            writer.writerow({'summary':clean_text,'type':cols2[i] })  #cols[i]})\n",
        "\n",
        "            #writer.writerow({'summary':str(text.correct()),'type':cols2[i]})\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding CORS Support User agents commonly apply restrictions to network requests. These restrictions prevent a Web application running from one origin from obtaining data retrieved from another and also limit unsafe HTTP requests that can be automatically launched toward destinations that differ from the running application's origin. To overcome this issue need to implement CORS Spec. [1] \n",
            "JMX support Adding JMX support for AXIS2. See \n",
            "Provide new plugpoint in code This work will provide a new plugpoint in the code. One can register InvocationListener implementations so that when a request is received on the their listener is called. when a response is ready to be sent back to the before it is actually sent through the the listener instance will be called again. \n",
            "2.1: Add support for AddressingFeature and SubmissionAddressingFeature Complete support for the AddressingFeature and and related annotations. \n",
            "Add support for and Complete support for the new annotations. \n",
            "Pinging capability to services deployed in axis2 The pinging capability is implemented as a which can be engaged by services to enable pinging. Pinging is an useful feature to to check the status of the web services deployed in axis2. Basically information provided by the ping module can be in one of the 4 levels. 0 Ping failed 1 Ping successful in the ping module of the requested operation has not implemented the Pingable 2 Ping successful in the MR of the requested operation class has not implemented the Pingable 3 ping successful class has implemented the pingable interface and returns 3 or This introduces a new interface called \"Pingable\" which has the method \"int Message Receivers and service classes can implement this interface to provide more accurate information about the status of the service. Engaging the ping module will result in introducing a new operation to the service called \"ping\" and it is dispatched using a unique SOAPAction. PingMessageReceiver is the MR which gets ping requests dispatched to the method \"ping\". If the ping request is service level no operations are specified in the ping this PingMR invoke the \"ping\" method of the individual MR's of all the operations available in the service. \n",
            "Support Axis2 services implemented with script langauges invoked by Apache BSF This patch adds support for Axis2 services implemented with script langauges. It uses Apache BSF so all script languages supported by BSF may be used. Its based on the same function used in Synapse and Tuscany. It supports two was of being either using the usual services.xml file with a script or as a script Module which monitors a script services directory and hot deploys hot updates any script put in that directory. When using the script MessageReceiver there are two ways of defining the script in the either with the script source defined in a seperate file or with the script source defined inline as a parameter value. See the javadoc comment in org.apache.axis2.scripting.ScriptReceiver for more details. When using the script module scripts currently need to have an associated WSDL file to define the service. The script and wsdl need to have the same name so the two can be linked together. For you have and in the Axis2 repository directory then an Axis2 service would be deployed at The script language is determined from the file extension of the script source file. Currently a single script function is called for all service the Axis2 MessageContext is passed into that function decorated with helper methods to access the payload XML in a way appropriate for the script for example E4X for JavaScript or ReXML for Ruby. I'd like to continue working on hopefully with input from you guys. There's a few things that could be and it needs things like samples and doc. Be really good to get it working with the wso2 axiom e4x impl. I'd also like to extend it to make it easy to implement handlers in script languages. \n",
            "Sample to illustrate the pinging capability This patch contains a ping sample. It is developed to illustrate the pinging capability. \n",
            "support in metadata layer routing For routing of an incoming message to an the input AxisMessage element QName must be set to the part name and then the operation needs to be added to the AxisService MessageElementQNameToOperationMapping. This is not being done by the metadata layer for AxisOperations it created based on annotations. \n",
            "Adding Function to support RespectBinding changes in on Client and Server I am adding code that will Add support for RespectBinding changes in on Client and Server side. I will make modifications to RespectBindingConfiguration on client and server and also add Unit test cases to verify the functionality. I will provide patch for this change. \n",
            "2.2: Add new Provider.createW3CEndpointReference method Override the implementation of the following Provider method that was added to section 6.2.4 of the specification for 2.2: QName QName QName String Creates W3CEndpointReference using the specified parameters. This method adds support for extension extension and porttype name. \n",
            "Integration among axis2 and osgi using xmlbeans databinding Hi i´m trying to develop web services with axis2 and osgi integration. At the begining all went ok. The problem appears when I try to return a data type that it build using xmlbeans databinding. In trying to do it in several ways but always obtains the same mistake: org.eclipse.osgi 4 0 17:25:15.062 An unexpected runtime error has occurred. 0 java.lang.NoClassDefFoundError: at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at I tried to provided the required class by addind it to the meta inf or including the next dependency: I don´t know if it is possible to do it in some ways or it is a feature that will be developed. Thanks in advance. Alberto. \n",
            "soap12:binding in dynamic wsdl Axis2 deployed services can respond to both soap11 and soap12 but there is no information in the dynamic generated wsdl about the soap12 binding. dims \n",
            "SOAPMonitor ported to axis2 The soap monitor is really three components: An applet which displays responses a servlet which binds to a default port of 5001 and connects to the and a handler used to intercept the soap messages. Therefore it requires three diferent pieces to be installed: applet classes a servlet config in web.xml and the servlet classes in and a module with the handlers under The module also requires phases defined and placed in axis2.xml . I tried to fit these classes into a structure that matches axis2. The source files are under the directory . I did some guess work here as a starting point. Not needed but perhaps helpful is my build.xml along with my web.xml and under the dir 'resources'in the zip file. The only needed change in the port besides package name changes was the SOAPMonitorHandler. A module was created with phase and the handler determines whether the soap message is a request or a response by The axis 1.x soap handler depended on . is never invoked in the axis2 code base. Attachment comming in comments. \n",
            "Add ability to have service .aar files inside a .mar file Module author may need to add services to the system in order to work perfectly . Therefore module archive file can contain services archive file inside that. So if there are any service archive inside module then it is require to deploy those services in the system. \n",
            "Java2WSDL Ant Task Can we please add an Ant Task for dims \n",
            "An option to specify the soapAction of an operation in the services.xml Can we have an option to specify the soapAction in the services.xml when defining the operation. Otherwise always generates the soapAction value as the operation name. Proposed solution: Allow an optional 'soapAction' attribute in the 'operation' element. \n",
            "update for annotation. 2.2 specification adds new properties to annotations. I am adding a change in metadata module that will consume these new property changes in runtime. The new properties are \"PartName\" in annotation and \"MessageName\" in annotation. \n",
            "Implicit SEI restiction on Static and Final Method exposure as webservice 2.2 specification restricts exposure of static and Final method on Implicit SEI as a webservice. I am making a change that will allow us to be compliant with this I am also adding new test cases to prove restriction on Static and Final operations. \n",
            "Support serialization of java.util.Map when using POJO service with RPCMessageReceiver. At one point serialization of java.util.Map was on Axis' TODO list but has since fallen through the cracks. When using POJO Map is not supported. Would be nice to add that support. \n",
            "add an option not to generate xmlbeans classes and instead get them from classpath With when generating the java code from the XFire looks on the classpath for the xmlbeans and if they're XFire does not generate them. This would be very useful with Axis2. At the I do not believe there is any way to avoid having Axis2 generate the xmlbeans classes. In my particular case I found a bug with this generation and the workaround is to empty out all my elements and complex types and use wsdl2java and then generate the classes from the real schemas with xmlbeans. Kind of cumbersome. I prefer to have xmlbeans generate my classes and axis2 generate the web service related files. That way I keep the two separate. \n",
            "Extend Spring support to accept proxies ServiceBuilder presently requires service class's byte code to obtain method parameter names. This won't work with thus making Spring support really feeble. I propose introducing additional service.xml namely to enumerate service methods and parameter names. \n",
            "Add option to enable a wsa:MessageId in repsonse message At the the wsa:MessageID on the response message is omitted as a performance optimisation. It's not really possible to force Axis2 to include it at the moment. \n",
            "Allow Customizable WSDL generation error messages When setting the value useOriginalwsdl to true in a services.xml and not providing a wsdl file in your directory the following message occurs: Unable to generate WSDL 1.1 for this serviceIf you wish Axis2 to automatically generate the WSDL then please useOriginalwsdl as false in your services.xml it would be better if a customizable error message a blank could be returned or even better allow the behavior to return different http error codes like 404 where the wsdl is effectively hidden without giving a clue that it exists. A work around for this is to create a filter that will check to see if someone is try to access the wsdl file directly and then return a 404 or what ever type of message they chose. Here is an example filter class: import import import import public class WebServiceSecurityFilter implements Filter { private static org.apache.log4j.Logger log public void ServletResponse FilterChain throws ServletException { HttpServletRequest httpRequest { } else { Unauthorized WSDL Access remote ip: \" HttpServletResponse httpResponse RequestDispatcher dispatcher } } public void { } public void { } } Thank you for your time. \n",
            "Provide support for org.w3c.dom.Document in web service. Provide support for org.w3c.dom.Document as a parameter for a web service. \n",
            "Support HashMap type in the web service. Support HashMap type in the web service. \n",
            "Provide compatibility to Axis 1.x for generated code. The generated code with WSDL2Java in axis 1.x has followed a different convention than the Axis2. Therefore it is one to test the existing service implementation class axis with Axis2. There are mainly two reasons for this. 1. Class names are different both in serverside and client side. Axis 1.1 has used the as the interface class name and the \"Impl\" as the Skelton class name. In client side stub name has taken as the \"Stub\". See the user guide 2. Method singatures are different. Axis 1.x remove the wrapper of the request objects at the method signature. \n",
            "Need to get client IP address on server side hi all In my application i need to get client IP address on server side. It is need to possible this in both of SimpleHttpServer and Axis2 distributions. Please can someone do Thanks Lots Regards Indika \n",
            "Unwrap Top Elements like in Axis 1.x when backwordcompatibility mode on Unwrap Top Elements like in Axis 1.x when backwordcompatibility mode on \n",
            "Adding WebServiceContext Resource Injection and EnpointLifecycle functionality I am adding new function to support and invoking Lifecycle messages. I will be adding unit test cases for these function and I will update the existing Endpointcontroller code to integrate this functionality. \n",
            "Session Management Support Adding support for Session Management per JAXWS Specification section 10.4.1.4 \n",
            "Need to save and restore the AXIS2 MessageContext There is an AXIS2 requirement to save the message context at some point in the handler store it and restore it later. This requirement also includes the need to let handlers manage data when the message context is saved and restored. In this feature can be used by a implementation to persist and messages and to recover from a server restart. The idea being to save a message then later restore the message context and pick up the message processing at the point at which the message context was saved without having to completely restart the message from the Refer to the wiki page for a description of a proposal on how to accomplish this feature. \n",
            "does not have a maven 1.x build script does not have a maven 1.x build script \n",
            "Axis2 auto generated wsdl dose not set nilable to true In the current code base if I generate wsdl for a java class it generate wsdl w.o putting its element to be nillable. In the real time scenario java class can return null values or it may take null as argument. So I think we need to generate wsdl allowing element to be null. \n",
            "Maven to run Axis2 simple HTTP server. Original proposal available here \n",
            "Provide an for setting parameters for Java2WSDL generation. In current axis2 user's ability to control the generated for a generated service. A comprehensive mechanism is needed to fulfill this. For eg: setting custom port port wsdl binding etc One idea would be to introduce new parameters for services.xml to set these. \n",
            "Maven archetype to create a simple Axis2 service as a webapp Maven archetype to create a simple Axis2 service as a webapp \n",
            "[GSOC 2012] Improve Json support in Axis2 with There are two ways that xml string can be converted into JSON Badgerfish and Mapped . Current Axis2 with JSON module completely supports Badgerfish convention[1] while partialy supports Mapped convention[1] as Mapped formatted JSON with namespaces are not supported in Axis2. Therefore if the client side code needs to talk with java service which is deployed in it should be sent as Badgerfish convention. It is cumbersome to generate Badgerfish convention of JSON string again and again to call services if there is no xml representation string in client side. If java script client can send JSON object to relevant java service in defining service and operation in request without doing any modifications to JSON then it would be very helpful for users at client side. According to the thread in the mailing which discussed we have two approaches. i have summarized those two approaches as below. 1. Store json inputstream in message context at the message builder while putting dummy SOAPEnvelop to the message and using process it inside the message receiver 2. Preserve the requirement that a message must have a well defined SOAP infoset and use a trivial representation similar to what we use for plain text. This has the advantage that it is more in line with the rest of the Axis2 or another option is to write an xmlstream implementation to parse the json stream. And provide that xml stream implementation to Axiom. \n",
            "Directory deployment for Axis2 deployment engine. At present Axis2 deployers are only associated with a file extension. but if we need to call an Axis2 deployer when a directory is dropped to the deployment it is not possible with the current deployment engine logic. I made few minor fixes to DeploymentEngine and RepositoryListener in order to achieve this. Now if the extension parameter is not present in the deployer Directories will be picked up and the registered deployer will be called. with this feature we can make the Axis2 Deployment engine more usable for wider deployment scenarios. \n",
            "Maven archetype to create a simple Axis2 service Maven archetype to create a simple Axis2 service \n",
            "WS Policy Attachments for services.xml Axis2 does not recognize policy references in services.xml. Implementation should alow usage such: \n",
            "Adding a small feature to send JSON messages through HTTP GET method Until now the JSON module in Axis2 did not support JSON messages which are sent through HTTP GET method. This patch adds that feature. This was implemented according to a request made by some user. This patch contains... Changes to JSONMessageFormatter to support GET Changes to JSONOMBuilder to support GET Changes to the yahoo JSON search sample Test cases to test this new feature in JSONIntegrationTest \n",
            "Maven filter labels added Maven filter labels added to files in xdocs. \n",
            "Document for JSON support in Axis2 This document explains the JSON support implementation in Axis2. It includes an introduction to why it is useful for how to use JSON support in Axis2 and details about the test cases and samples. \n",
            "Adding a Deployment Life cycle listner to Axis2 Deployment life cycle listener is very useful when restarting some actions after a server crash. This is specially use full in starting the persisted RM sequences when a server starts up or at the client side when the client restarts. \n",
            "Produce Axis2 documentation in a form suitable for printing and offline reading I'm sure the people who work with Axis2 either as users or developers of the believe that the state of the project documentation is perfectly fine. What the documentation is the ability to ingest the documentation in a printable and readable form. The Wiki is perfectly fine as a but it's not very useful for many people who want something more. I'm sure the new Axis2 book will sell because it's probably the only form of Axis2 documentation in that form that anyone can get a hold of. If you examine the model of the Spring and Hibernate they produce a very readable offline documentation set that someone can use to read about the details of the project in a form that is convenient for them. I also believe that even if you agree with that the Axis2 project needs a good printable up to documentation you would likely agree that this would take a lot of work to produce. I would also agree with that. It's a task that may never be completed. as I didn't see an issue reported that addresses this I felt I should at least file to get this on the record. \n",
            "JDk5 Enum Support in AXIS2 Our Organizaton want to use Java level enumeration support or WSDL level enumeration support for implementing it in the WSDL \n",
            "To be able to create Web services out of EJB 3 a new package with new classes to handle EJB 3 \n",
            "Client side exception handling In the client if the recd SOAP message contains a SOAP we throw an exception to the application with the information extracted from the Fault message. But due to security reasons sending fault information to the application is not desirable. And some times it may be required to get the recd SOAP with the as it is. So better to have a flag in the either to get the java exception or the soap message. \n",
            "Java2WSDL for WSDL 2.0 Please see request from dims \n",
            "validate request and response with Schema Currently the content is not validated against the Schema definition in the WSDL. I propose to add a Handler that can be added to the request the response handling on the server even on the I think this would simplify many problems when developing a client. The request validation might even be switched on in production environments to reduce the risk af malicious requests or to reduce the load on the backend in case of DoS attacks that Axis is used as a sort of that forwards the request to another \n",
            "Module based on WSS4J Similar to could we please add a module as X509 using dims \n",
            "JMS Transport for Axis2 Do we have a JMS Transport for Should we have one for dims \n",
            "Axis2 deployer for Geronimo We need an Axis2 deployer for Geronimo. This will enable the standard Geronimo deployer can to automatically detect a Axis2 deployment unit jar which includes inside and then a the web service. dims \n",
            "Support for in security module In addition to supporting the old wss4j style of specifying the handler We need to be able to drop in a assertion service.xml or in a separate to specify the security parameters for a web service. dims \n",
            "Provide a way to Configure Axis2 storge class In AxisEngine there are methods to store and retrieve data public Object Object public Object Object And the underline implementations is based on an interface so there should be a way to specify the implementation class in axis2.xml \n",
            "Support for 2.0 Eventually we'll need to support 2.0 We should decide on hooks for how to inject infromation from annotations into the service description. though we may not implement JSR 181 in the 1.0 time there should be enough room in the implementation to drop in support for JSR 181 say via the beehive project IF they decide to do it dims \n",
            "WSIF Provider for Axis2 Should we create a provider for dims \n",
            "Extend the schema generation providing ability to generate wrapped array types Currently the schema generator will create unwrapped array schema e.g. for a String[]: It would be valuable if it could also generate array types in wrapped format which is the default behaviour in .NET and e.g. The wrapped format has certain benefits over the unwrapped more on this can be found in this article: . This option can possibly be configured with a parameter in the axis2 configuration per service The parameter could be named \"generateWrappedArrayTypes\" or something like this. The default should be not to generate wrapped array types as it is right now providing backward compatibility. \n",
            "New AXIS2 Packaging Structure New AXIS2 Packaging structure for standard minimal source and binary docs releas and WAR release \n",
            "Added new doc to dir. Ammended userguide. Review Apply Added new doc to dir. Ammended userguide.html in same dir. Kindly review and apply patch \n",
            "Global Outflow information should be available for handlers in the InFlow Currently global inflow information can be obtained using the method 'getInPhasesUptoAndIncludingPostDispatch' of the Axisconfiguration. But there is not way to obtain global outFlow information. We got this requirement in Sandesha2. we sometimes need to send acknowledgement messages from a global handler. But there is no way to get outFlow information. so handlers like AddressingOutHandler does not get called. \n",
            "Supporting multiple cookies Implement Axis2 cookie support as described in following mail \n",
            "add SOAP Response SOAP MEP support SOAP 1.2 defines a called SOAP Response. See: NOTE: SOAP MEPs are different from WSDL MEPs .. and Axis2's concept of MEP is a WSDL 2.0 not a SOAP SOAP Response is basically a way to do be able to do a regular HTTP GET and have the response be a SOAP envelope yet for the whole exchange to appear as a SOAP exchange as far as the client is concered. Glen should be able to give us more info on the subtleties .. this was a particularly sensitive topic in the SOAP 1.2 group as it was viewed as a way to bridge between the WS world and the REST world. With the recently committed HTTP capability for operations WSDL 2.0 for this we should be able to do this quite trivially. \n",
            "Rename InOnlyMEPClient to RobustInOnlyMEPClient and implement Fire 'n Forget I think we need to implement RobustInOnlyMEPClient and FireAndForgetMEPClient properly. I think the current InOnlyMEPClient is more Robust In scenario. \n",
            "UDP transport for Axis2 I think its better to have UDP transport for Axis2. \n",
            "Use IOR supplied in SOAP request to get Corba object Currently the corba module is always looking up the Corba object using the name service when executing a Corba method. It would be very nice when you can also supply the IOR of the Corba object in the SOAP request. When this IOR is the Corba service is not using the name service to get a Corba but will use the Corba object identified by the IOR. Pseudo code: if { } else { } \n",
            "Running in a machine with multiple with its own ip address In environment where we run multiple tomcat instances using and if each instance is bounded to its own ip address running soapmonitor results in an error as the socket connection uses localhost when creating the server socket. \n",
            "Unable to use the java.net.URL connection to run om Appengine I'm unable to make use Axis2 as a client on Appengine to call other webservices From the looks of ProtocolSocketFactory it needs to create a which is not allowed on Is there any way around this problem. \n",
            "When instantiating the ExceptionException add AxisFault to it proper reason codegen produces the below piece of code. valuable information such as is lost with this. Suggestion: add AxisFault to the generated ExceptionException class if an AxisFault is available add it to the ExceptionException org.apache.axiom.om.OMElement faultElt if if the fault by reflection try{ java.lang.String exceptionClassName java.lang.Class exceptionClass java.lang.Exception class java.lang.String messageClassName java.lang.Class messageClass java.lang.Object messageObject java.lang.reflect.Method m new if instanceof throw } So the new piece of code would look like org.apache.axiom.om.OMElement faultElt if if the fault by reflection try{ java.lang.String exceptionClassName java.lang.Class exceptionClass java.lang.Exception class java.lang.String messageClassName java.lang.Class messageClass java.lang.Object messageObject java.lang.reflect.Method m new if instanceof ExceptionException ee throw ee; } ... \n",
            "Enable ServiceGroupID to be customized The approach uses a SOAP header for identifying its sessions. This might look as follows: ... When I develop an application I want to map this id to my application namespace so that it is clear that this Id belongs to my application. Please enable it to be changed in a configurative so that it might look like this: myns:sessionID ... Thanks. \n",
            "Termination of the soapsession I want to do some tidying up at the termination of the soapsession. The session is terminated when the specified in is reached. It would be of great help if you could have something like a SessionLifeCycle interface. It may contain two methods and which are called whenever the session is started or terminated. Like the the implementing class of the SessionLifeCycle could be specified via the where you also have to declare that the service uses the soapsession approach. To clarify my request: In a servicegroup with a single service I could do all the session specific in the method of the Service implementation class. But when there are multiple services in a there is no way to init or destroy resources used by the whole serviceGroup. \n",
            "Client side support for and MustUnderstand Check on Handler Injected headers. This JIRA is to add missing function in JAXWS implementation to invoke on JAXWS client. The function needs to perform MustUnderstand check after the invocation on This function is very similar to what we did on server side and we will be able to leverage some of the code that we wrote on server side. JAXWS TCK does not check for this function on client side. So I beleive this is a low priority I will provide implementation for this function. \n",
            "Add Fault processing to JAXWS Fault processing is now working with this patch under JAXWS. Server endpoints may throw custom which will be received as such on the client side. Attached patch file is for Axis2 SVN rev 464492 from \n",
            "Codegen for one WSDL with multiple services Need more See we need to be able to generate a client. dims \n",
            "Integrating ParameterDescription into MethodMarshaller. I am Integrating ParameterDescription annotation meta data layer into MethodMarshaller code. The code replaced all the parameter annotation MetaData from MethodParameter Class and replaces that with the new ParameterDescription. I have also made changes to BlockImpl to now read BlockContext that stores the declaredType of the jaxbClass that can be used to unmarshall JAXB using declaredTypes. I will attach patch for these new features. \n",
            "OMElement support for JAXWS supports a few all of which require multiple transforms. If we expose OMElement as a supported several transforms can be which greatly improves performance. \n",
            "Remove SOAP Version Restriction from Provider Endpoint This JIRA is for removing SOAP Version Restriction from Provider Endpoints. Currently a Provider Endpoint can support a SOAP11 or SOAP 12 call based on the soap version defined in the binding type annotation. With this JIRA I am introducing a new constant that can be used in when this new constant is used the javax.xml.ws.Provider java endpoints will cater to SOAP11 and SOAP12 messages. This JIRA will also add proper validation checks to support the new for example it will ensure that a SOAP Fault will be thrown when a response of soap12 is sent on a soap11 request etc. This JIRA also adds code to update various validation checks for new constant during web services deployment. This JIRA also adds test cases in module to test various scenarios for this new constants and validations. \n",
            "Axis2 configuration to support transactions Need to add following JTA transaction related configuration to axis2.xml \n",
            "jsr311 implementation for axis2 I implemented some of the features specified jsr311 specification in Axis2. By this feature users will able to use rest support available in axis2 using annotations inserted in the service source. current implementation support both .class .aar type deployment. Earlier users had to manually edit the WSDL in order to use REST support in axis2. with this users will able to consume RESTFUL web services in axis2 by adding some annotations in the source. currently i have implemented support for : Path HttpMethod Produces Consumes \n",
            "Clover Code coverage for Axis2 I have attached a patch file to get colver test coverage analysis as a optional maven goal in Axis2 trunk. If we run \"mvn clean install\" the clover goal will not execute. if we want to run builds with clover test coverage we have to give the profile name during the run mvn clean install I tested this with a temporary clover license. The permanent open source license will be granted when the poms are updated with Clover plugin and committed. please commit the attached patch. \n",
            "Creating Eclipse Features and a p2 Repository for Axis2 Eclipse IDE plugins This jira will be used to track the progress of creating Eclipse Features and a p2 repository for Axis2 Eclipse IDE plugins. \n",
            "ant task for deploying aar file to running axis2 web application Background email: The axis2 is nice when you deploy an aar file rarely. during development is becomes a bit cumbersome since I have to deploy for testing quite often. The imaginable ways of deploying my web services application would be: 1. Uploading the aar file to the axis2 web application through the web interface. 2. using Tomcat manager application for deployment of complete axis2.war containing my aar file. 3. Copy the aar file to the deployed axis2 app in tomcat and hope for file system access to 4. Copying the complete axis2.war containing my aar file to the tomcat webapps file system access to 5. Missing: for uploading the aar file to the running axis2 application. Are there any plans of making a for deployment of aar files to \n",
            "Automatically warn users who try to use or that it is unsupported. There are frequent conversations on the mailing list of the sort: Q: \"I tried the following WSDL that used to work fine on Axis 1.4 on but the output files are missing classes\" A: Your WSDL uses format. Axis2 doesn't support that. You'll have to rewrite it to use I dont' see why this issue should ever have made it to the mailing list. It seems to me that if Axis2 doesn't support \"encoded\" forms of that any attempt to use them should produce no but should instead automatically trigger an error message explaining that the encoded forms are not supported by this version of Axis2. what happens now is that WSDL2Java SEEMS to but produces wrong \n",
            "Java 2 Security We need a feature which can provide us access control to grant privileges when the codes and to have code operate with the minimum necessray privileges. \n",
            "Dispatcher support for annotation The Dispatcher currently assumes the Body of the MESSAGE mode support for types of and String needs to be added. I am working on a patch which I will submit shortly \n",
            "Add Maven 2 Plugins Attached you find a first implementation of Maven 2 plugins for Axis 2: Creates an aar file Runs the wsdl2code generator Runs the java2wsdl generator I'd like to contribute this to the Axis 2 project. Maintaining them would work best as soon as Axis 2 is itself built with Maven. The project needs more work. In it lacks documentation. \n",
            "Adding support to handle NULL object in Proxy JAXWS Proxy case did not handle null object being passed to the method parameter. I will be adding support to handle I will also add a test case for JAVA Bean endpoint with Proxy. \n",
            "Adding support to handle bare wsdl in a Java Bean Endpoint I am adding support to java bean endpoint so it can handle a non wrap or bare wsdl. I am also adding test cases created from a wrapped wsdl and using binding file with enableWrapperStyle false. \n",
            "Initial pass at a standardized interface for collecting and processing Web Service annotations there are different ways of parsing for and collecting annotations. We are proposing a standard interface for the collection of Web Service class reflective information and annotations. Once all the information is it will then be verified against the relevant specs. This issue is intended to present an initial pass at such an interface. \n",
            "java2wsdl functionality to the Axis2 IntelliJ Idea Plugin currently axi2 eclipse plugin have the java2wsdl functionality. Attaching the patch to the Idea plugin java2wsdl functionality. \n",
            "Fast Infoset support for Axis2 I would like add fast infoset support for Axis2. I will submit a patch with this feature soon. \n",
            "Add metadata layer annotation processing Within the metadata we added processing of the This consists of adding a new method EndpointDescriptionImp.getHandlerChain that ultimately reads the xml file from the annotation and converts it into a JAXB object \n",
            "Optional \"Ignore Unexpected Elements\" mode allows for clients Problem: Service provider adds an optional element to the responses it assuming client can while client is unaware and has not retrieve updated WSDL and regenerate client. Axis2 client generated with cannot handle and throws an exception. Solution: Optional \"Ignore Unexpected Elements\" mode for wsdl2java using adb allows for clients that can recover from unxpected elements in service responses. Based on the work in Issue 3037 This patch is more up to is for both trunk and handles more and will correctly parse the portion of the response after the unexpected element. To pass the parameter to wsdl2java Handles the following scenarios: unexpected element in a xsd:all appended unexpected element in a xsd:sequence. For the unexpected and subsequent elements within that sequence are not captured. If a service adds a new element within a it should be as the generated client is strict with and can't differentiate an sequence from an additional inserted element. \n",
            "Support for service classes having a Java 5 parameterized type as a super type. When a class implements an interface extends a which is a parameterized compiler creates a synthetic method which behaves as a bridge method in order to support sub classing. Axis2 detects this bridge method as an overloaded method and hence does not properly support service classes having parameterized super types. For axis2 does not support EchoClass below as a service class. public interface { public T } public class EchoClass implements { public String { return value; } } \n",
            "Allow the ability to handle bad client requests We are getting a lot of parsing exceptions from clients rouge than hitting our axis2 soap services incorrectly. For example: ERROR org.apache.axis2.engine.AxisEngine : javax.xml.stream.XMLStreamException: :3:247 expected at 0xffffffff We have no control over the processing since the AxisEngine logs the error directly Axis2 should provide a way to override the error handling either by using an interceptor or having a delegating method that can be overwritten. It can default to logging the error but allow developers to overwrite this behavior easily. Not sure the easiest approach but look for guidance from the Axis2 dev team to provide a solution. \n",
            "Add an option to control whether to throw or suppress exceptions on invocations Add a configuration option to control whether to throw or suppress exceptions on invocations in HandlerChainProcessor. \n",
            "Support for Threshold. I am adding function to support MTOM attachment Threshold. The implementation will involve reading the MTOM attachment threshold size and setting it on Messagecontext. During the attachment marshalling process this threshold value will be read and used to determine if the attachment needs to be send as inlined or optimized. \n",
            "Deploying a Javascript service in Axis2 It is now possible to deploy a web service written entirely in javascript on Axis2. When implementing the javascript the user will have the option of using E4X which extends the semantics of familiar Javascript operators and manipulate the XML data with ease. This feature needs 2 classes and and the js.jar library from Mozilla Rhino in addition to the Axis2 libraries. The JavaScriptReceiver processes the incoming message and extracts the javascrtipt function name[1] the arguments payload to be sent to the javascript service and the javascript source stream[2]. It then calls the JavaScriptEngine which uses the Mozilla Rhino API to process the javascript file. The JavaScriptEngine returns an xml string object to the JavaScriptReceiver and the latter encodes the result and sends the outMessage. [1] The operation the client requests. [2] This is similar to the ServiceClass in a Java service. \n",
            "Support for basic authentication There is no support for basic authentication when making webservice calls via ServiceClient class. I see there is basic authentication support for proxy server but not for direct connection. It would be nice to have something following: ServiceClient client new Axis 1.3 have these in class org.apache.axis.client.Stub. \n",
            "Support RI databinding for WSDL2Java I've added support for using the RI with WSDL2Java. This patch just includes the initial support to get the appropriate databinding extension and calling the RI's XJC compiler. Code gen is working for basic cases I have not yet started on runtime support. I've followed the pattern for loading the per the recent changes in the XMLBeans and JiBX binding extensions. deps on the RI are limited to the new jaxbri and at runtime if the RI JARs are not available on the WSDL2Java will throw an appropriate exception msg. A sample command line: wsdl2java foo.wsdl jaxbri \n",
            "Service removal within OSGi environments is not handled by WSTracker Service removal of services registered with the property {{org.apache.axis2.osgi.ws}} is currently not handled by WSTracker. The result is that an Axis service is still available even when the underlying OSGi service has been unregistered. \n",
            "spring mvc axis integration I want to implement axis2 with spring mvc using maven. Can you share the configuration. spring implementation code. \n",
            "Adding Attachment Image Compare Utility I am adding a small utility to compare java.awt.image objects. The Utility will be mostly used to verify test cases that send and receive MTOM attachments as Image the idea is to have ability to compare two images to see the validity of Image Objects. \n",
            "Control what wsdl bindings returned via services.xml I believe that it would be a very useful feature if we controlled the generation of what WSDL bindings is returned in a WSDL document by AXIS 2 one does not from within the services.xml file. One can indicate through a parameter whether etc. binding are to be returned. Keith Chapman responded with the following that may be help in showing how this could be done: I guess the better solution might be to use the AxisBinding hierarchy introduced while integrating WSDL 2.0 changes. Currently the services.xml does not populate the Binding hierarchy but keeps all the details in the AxisService. It might be a better solution to populate 3 bindings by default SOAP SOAP 1.2 and and customize it based on properties in the services.xml. When or is called we look for binding and if its present we serialize them. If its not present we generate 3 default bindings. So if the above is incorporated we would automatically get a WSDL that the user desires. Using the binding hierarchy has other such as been able to customize a particular binding without affecting the others. I certainly think that we should be using the Binding hierarchy when building services from the services.xml. \n",
            "Ability to override the overwrite capabilities of wsdl2java In the following code will not overwrite what is already even if you want it to. It would be nice to have a switch to turn on overwriting behavior. public void String throws Exception { outputFile the existing flag fileExists if { this.stream new } else { } } \n",
            "WSDL2Java should generate some kind of infrastructure on the server side for soap:headers defined in WSDL Right now we generate extra parameters on Stubs for on the client side. We do not do any equivalent for the server side skeletons. This is potentially a problem in that if one of the headers is sent at runtime with we'll get a fault even though we should understand the header. Proposal is to define an \"ApplicationHeaderHandler\" which reads metadata from AxisService describing which headers the service understands. It checks to see that those headers are present in the message if marks them as processed so MU test and supplies the OMElements in convenient properties of the MessageContext. \n",
            "Support for 2.1 Add support for the 2.1 MR which was recently released by Sun. \n",
            "Raw SOAP XML Logging It would be outstanding if there was a way to log the raw SOAP XML for each request and response on a server. Currently if a user of Axis2 wants to log the raw SOAP XML they must follow and implement the 'Writing Your Own Axis2 Module' tutorial. The tutorial is found at: It would be nice if a default module was made to make the logging easier. I could see the need to keep the current module explaining how to do logging if more logging is required. Finally it would be nice to also point out that this module works for both requests made to the server and requests made from the server. Here is the current handler we're using for our logging. It isn't great but it is a starting point for different ideas. package com.xxx.axis2.handlers; import import import import import public class LogHandler extends AbstractHandler { private static org.apache.log4j.Logger log private static ThreadLocal aSessionId new private String aName null; public InvocationResponse throws AxisFault { Map map HttpServletRequest request start { id: \" } operation: \" service: \" direction: \" { remote ip: \" } binding name: \" Envelope \" Envelope { } return InvocationResponse.CONTINUE; } public void { Map map HttpServletRequest request start { id: \" } operation: \" service: \" direction: \" { remote ip: \" } binding name: \" Envelope \" Envelope { } } public void { aName name; } public String { return aName; } } \n",
            "Plugin in JAXWS RI's wsgen to generate the dynamic When one deploys a jaxws annotated service using the the dynamic wsdl and xsd generated don't use all the annotations present in the Quick way is to plugin the wsgen tool from JAXWS. if the JAXWS RI jar's are in the classpath then we pick them up and use them to generate the wsdl. This tactic is already used quite successfully by the Geronimo folks. dims \n",
            "Deploy goal for Axis2 Web Admin Console for A a new deploy goal for the Maven2 plugin that allows users to upload AAR files to the Axis2 Web Admin Console. Source code attached in patch. \n",
            "2.1: Support and MTOMFeature 2.1 adds some new config options for enabling along with adding some new capabilities to the MTOM function. This will mostly leverage existing but will also require some additional functionality and coordination with the message model. A quick summary of the work to be done: 1. [DONE] Update the metadata APIs to reflect whether or not the MTOM configuration was found on the endpoint. 2. [DONE] Update the annotation processing code to pick off the annotation when included on an endpoint. 3. [DONE] Update the client creation code off of the ServiceDelegate to set the appropriate values when the MTOMFeature is configured for client instances. 4. Change the marshalling code to read the threshold and toggle MTOM when appropriate. Here are some examples of the new ways that MTOM can be configured. Before: public class MyServiceImpl { ... } After: public class MyServiceImpl { ... } the threshold is configured as such. public class MyServiceImpl { ... } On the client the configuration changes a little bit as well. Here are a few examples of how this will be done. MTOMFeature mtom new Service service MyProxy proxy \n",
            "2.1: Support and RespectBindingFeature RespectBinding is a feature added in 2.1 that allows an endpoint to ignore the binding defined in a wsdl:binding element. In other an endpoint could support both SOAP 1.1 and SOAP 1.2 even though the WSDL may indicate only SOAP 1.1 support for the endpoint. Here's a quick summary of the work to be done: 1. Update the metadata APIs to expose the RespectBinding data available 2. Update the annotation processing code in the DescriptionBuilder to process the annotation. 3. Update the WebServiceFeature processing code to account for the RespectBindingFeature. 4. Change the EndpointController to have a toggle point that checks against a RespectBinding property. 5. Update Provider processing code to handle the scenario where the return type is invalid according to the input. This is described in the check that exists in the EndpointController. \n",
            "Support and Metadata sparse composite to override certain annotation members Add support for a client to use a sparse DescriptionBuilderComposite to override certain annotation values specified in the client artifacts on a basis. This support is the basis for supporting additional such a deployment descriptor information. Added additional tests to verify the new functionality. \n",
            "Provide enabling support in JAXWS for when validating the description we throw a WebServiceException if we encounter a transport other than 'HTTP'. This feature will allow as well \n",
            "Modify BlockImpl to avoid double unmarshalling creates an buisiness object from AXIOM. I am trying to create buisiness object before JAXWSReceiver and set the buisiness object into OMSoucedElement. But current can not aware that. The BlockImpl wraps the OMSourcedElement by OMStaXWrapper and create same buisiness object again. This patch modifies BlockImpl to be able to aware such OMSoucedElement which has buisiness object and set the buisiness object into BlockImpl. \n",
            "Support for xs:union inside xs:simpleType Please see: and also the WSDL in bug dims \n",
            "StAX Filter [ Data or do something between XMLStreamReader and StAXBuilder] To use this Filter in we have to change AXIS2 alittle. See \n",
            "Java2Wsdl needs \"extra classes\" support In Axis Java2Wsdl has support for which allows the wsdl to generate complex types for subclasses that are possible return types for methods that return abstract classes or interfaces. For example: One might have an abstract class \"com.myCo.fruit.Fruit.java\" that has the subclasses \"com.myCo.fruit.FruitApple.java\" and \"com.myCo.fruit.FruitOrange.java\". If there is a method in our service interface: public Fruit return } I want my WSDL to have definitions of not just but also FruitOrange and FruitApple so my client will be able to handle those types. In Axis you could add something to you ant task like: com.myCo.fruit.FruitOrange.java\" Is there the possibility of getting this feature in Matt \n",
            "Add metadata support for WebServiceProvider and related annotations on service implementation class Add support in the metadata layer and refactor the EndpointController and JavaBeanDispatcher and ProviderDispather classes for annotations: BindingType. I am working on a patch which I will submit shortly. \n",
            "Support for xs:list inside an xs:simpleType Please see examples in the following wsdl's. dims \n",
            "Asyc Feature for JAXWS proxy non Wrap. I am adding support for proxy non Wrap Async callback. I will also included test case for Async Callback. The test case uses wrapped wsdl and uses a binding file with enableAsyncMapping to true and enableWrapperStyle to false. \n",
            "initial support for Proxy I am dropping code to provide initail support for unwrap support for Proxy. I am attaching the test case where a Wrapped WSDL with a binding file where enableWrappedStyle is set to false is used to generate SEI using RI tooling. Next I will attemp to support multi part wsdl. \n",
            "Message Driven Bean as JMS listener I've been walking around mdb implementation for Axis2 for a while. And at I've successfully served my services through it. But there are many concerns that need to be taken into account when it comes to J2EE environment. My purpose for creating this issue is sharing my mdb code and starting a discussion around: Application server agnostic packaging and deployment model Necessity of listener manager integration Supporting JMS 1.0.2b as well TODO comments I've put into the mdb file Let me list my way I've come through: Chose \"njms\" as base implementation. Used to be able to compile MDB code Mixed some code from JMSConnectionFactory and put them into AxisMdb. Used WL8.1 which support JMS 1.0.2b API. But \"njms\" requires JMS 1.1. Used Sonic 7.0's client jars as JMS API 1.1 implementation and overrided WL's client by putting them in system classpath Put all the jars come with Axis2 under folder found in ear file. Please note that is WL solution. I needed to add all the jars into system classpath. in that I got operating system error that complained about size of the CLASSPATH variable. Created an ear as following structure: lib Instead of giving absolute path for repository in the I only used directory name and created the directory under \". This is the folder WL's starting and stopping scripts reside. When Axis2 is this folder found successfully. Since I don't know all the details of need to be directed towards a better code. I hope someone will look into the file I'll attach and give feedback. \n",
            "A mechanism to specify password to access the We should have a mechanism to specify password for authentication like proxy https to access \n",
            "CORBA module for Axis2 I have developed a CORBA module for Axis2. It is based on pluggable deployer architecture. This module can act as a bridge between a CORBA server and a web service client. The patch against the latest trunk and a user guide is attached. This module uses Apache Yoko as the default CORBA implementation in RUNTIME. be Since Yoko is not yet available in maven2 remote repositories I have commented them from pom.xml file. Yoko requires JDK 1.5. This module depends on Antlr also. The classes in org.apache.axis2.corba.idl.parser were generated by Antlr using idl.g. Please refer the attached guide for more information. \n",
            "Need a hook point in MessageReceiver where we can register a callback when the business logic has been invoked In we need to understand when a message has been \"delivered\". This is the point at which the operation has been executed by the MR. At the moment we get round this by invoking all messages from our own Invoker thread. we need to optimize this as its costing us a lot of performance. We simply need a way of hooking in a call that the MR will make Ideally we ought to be passed some information about whether the call succeeded or if an exception was thrown. \n",
            "2.0 support for Apache Axis2 WSDL2Java Code Generator Hi Herewith I have attached a patch which will enable WSDL2Java to generate code based on 2.0 standard. I would like to mark this as experimental because there are several thins to be completed.. 1. Improve the usage of annotations. 2. Support for wrapper style mapping of method parameters. Once these things are completed this feature can be put into the actual usage. I would like to make a humble request to you all to use this feature and let me know your comments. Sameera jayasoma. \n",
            "Allow https connection without a keystore Normally when we connect over if the server sends us a certificate that is not well we have to specify a keystore using system properties: to keystore\" We should allow clients to either provide a certificate by some other such as the or allow the client to disregard the certificate and trust the server. This is because clients are sometimes deployed on systems where the developers have no access to the file system and therefore cannot configure the keystores. \n",
            "Please support methods returning in java2wsdl The java2wsdl tool doesn't generate useful WSDL for methods that return It would be much more useful to generate WSDL like for T[]: Using manually created WSDL like the latter with a method that returns seems to so it would be nice if java2wsdl supported this also. \n",
            "Support HttpState object association with a client and use it when invoking Hi I am opening a new JIRA related to the HttpState association with a given Axis client. The use case I want to point out a concrete use case I have. I want to reuse a HttpClient among different instances of a clients which are executed in different threads. Every client can make several invocations. The clients can call different Web Services deployed at different As a consequence every client may need to provide different authentication Credentials and may need to support transport sessions using Cookies. Both Credentials and Cookies are part of the HttpState. As a result the HttpState associated with the HttpClient that is reused cannot be reused that easily in the scenario described above. Credentials are associated with a given realm and authentication schema the AuthScope object used as a key for the credentials Map part of the Following is an excerpt from the creds new Credentials are kept into a Map and could be identified uniquely from client to client to but this Map is exposed to all clients which reuse the HttpClient which is not a good idea. The situation with the other member of the HttpState is similar. When we have client instances to use cookies calling one and the same WS's operation then the effect is that both are sharing one JSESSIONID. The proposal The proposal is based on my question posted at [2] The idea is to provide the capability to a separate HttpState with every client and still reuse one and the same HttpClient. What you just need is to pass it as a parameter to the I decided that the HttpState should be kept into the ServiceContext. I did all changes needed in Axis2 kernel fact they are really and added the possibility to use a separate HttpState and invoke passing it as a parameter. The changes keep the kernel backward compatible. I did and several tests and it looks good. give me your comments. Do you like this If so I can provide you with the changes and finally we can agree on committing them into the kernel. I have the patches but we are using a little bit older version of axis2 .I need some time to apply the changes to the trunk version. Then I will provide them. Although I am a WS committer I can not commit anything since I am still waiting my company's lawyers to check all aspects of this. Thank Dobri [1] [2] \n",
            "WSDL2 support in dynamic service client As i know dynamic service client only supports WSDL11. It would be better if we can add support for WSDL2 as well. \n",
            "Support for version of I'm using with axis2 under the hood. I'm trying to create a proxy of a soap 1.1 web service. A proxy needs to have soap 1.1 with interface. The problem is axis doesn't support version of It support the last submission version The link below contains more details about my use case. We are not able to switch to a newer version. I would be happy to see the feature in axis. \n",
            "Initial Implementation This is the JIRA isse mentioned in an earlier note. This is an initial pass at some of the APIs. We'd like to submit this for inclusion within the existing Axis2 module. Please see the attached README.txt for more info. \n",
            "JAXWS: MetaDataQuery Tool for merging and checking annotation information with other deployment descriptors The MetaDataQuery functionality will deal with annotation data with respect to checking it for merging it with and constructing valid representations of web services based on the data collected. The MDQ will check the annotation information working on a standard data structure produced by the annotation information that has been gathered. This should allow users to collect annotation data in an independent manner as long as they can produce a data structure that agrees with the input to the MDQ. The annotation validity will be determined via the appropriate Java specifications. The MetaDataQuery will modify the annotation data structure depending on any inheritance that needs to be observed. The MDQ will also accept the validated annotation data along with a wsdl definition and produce a merged data structure that can then be used by different components. The idea will be to create the MDQ with the eye toward accepting other deployment descriptors in the and to be able to merge these other descriptors with the annotations and wsdl. \n",
            "JAXWS: Refactoring invocation APIs I've started work on refactoring the invocation APIs for Right the Dispatch and dynamic proxy implementations use the AxisController API to perform the invocation. I'd like to maintain the same general but clean the APIs up a bit and moving some of the function around to more apporpriate places. Also included in this will be the first pass at the defined in the spec. This will delegate down to the Axis2 MessageContext wherever possible. This includes the SoapMessageContext and the LogicalMessageContext as well. \n",
            "JAXWS: handler framework HandlerResolver HandlerProcessor I am working on the HandlerResolver and a HandlerProcessor. This will get about of Chapter 9 of the 2.0 spec done. I'll submit tests as well probably July 10 or 11. \n",
            "New JMS Implementation ConnectionFactory cache for client I'm creating this issue regarding discussion found at Following is the related excerpt from the mentioned discussion: [Ali Sadik Kumlali] In if ConnectionFactory is retrieved from the JNDI for each very high memory usage which prevents access to admin console occurs during high message traffic. And sometimes the server crashes. old JMS implementation uses connectors to achive this. [Asankha] The JMS listener focuses on listening for JMS messages and I believe that the optimization that one could perform on outgoing JMS is limited as different messages may be destined for different JMS destinations. I also think that we could use the \"default\" connection factory one is for outgoing messages with a minor patch.. Will this be \n",
            "JAXWS: Message Subsystem I am currently architecting a data model representing the Message. A Message is an abstraction for the XML and Attachment information. The layer needs to render the message in different forms: OM : To communicate with the core Axis2 engine SAAJ : To communicate with Application Handlers Business Objects: To communicate with dispatch and receivers. The Message subsystem is a convenient abstraction that hides the transformation between these forms. I am planning to add the initial code early next week. Follow on issues will be opened to use the proposed OMObjectWrapperElement to gain more performance. \n",
            "JAXWS: Proxy Implementation for JAXWS This will be a new Feature for JAXWS Proxy is a low level JAXWS client api that provides access to service endpoint interfaces at runtime without static generation of stub class. The java.lang.reflect.Proxy api from JDK will be used to implement the dynamic proxy functionality. A Proxy is created using getPort method of Service instance. The getPort returns a proxy implementation for specific Service Endpoint Interface to the client. Proxy Creation will fail if the SEI provided by the client does not conform to the WSDL to java mapping rules of jaxws specification. \n",
            "JAXWS: Wrap and unWrap JAXB Objects using JAXBWrapperTool This is a new Feature for JAXWS JAXBWrapperTool's primary purpose is to Wrap and UnWrap JAXBClasses. Architecturally the wrapper tool will be a separate pluggable component that will be used by JAXWS client api's like Dispatch and Proxy to handle wrap and wsdl's. For Wrap case JAXBWrapper tool implementation will read Wrapper propertyNames and propertyObjects as input parameter and product a wrapped JAXB Object with property and their object values set. For unWrap case JAXBWrapper tool implementation will read JAXB Object and property names as input and product separate objects for each property. \n",
            "JSR 181 support Attached is the scratch code from my sandbox. Note this was done as a proof of concept. More work needs to be but I need to see if the initial direction is community approved before I spend more time on it The patch contains WSMToAxisServiceBuilder.java and other related files. Also attached are the WSM jars from my local repo them under a very simple POJO with 2 public methods and only one marked with just bug me if anything is missing \n",
            "unwrapping support in codegen Please see the discussion here: \n",
            "JAXWS: Metadata Abstraction Layer This layer abstracts the various metadata used by JAXWS. That metadata currently consists of and annotations. 1.2 Deployment Descriptors will be another source of metadata. This layer will shield the rest of from this metadata and the complexities involved in merging the various sources into the final effective metadata to be used. The layer will contain a hierachy of description artifacts corresponding to the port and parameters. These Description classes will delegate to the etc to access WSDL metadata and annotation information. The Description classes will contain the annotation information other information as DD I am currently working on the initial implementation of this layer and the associated tests. \n",
            "Endpoint Controller framework Started work on cleaning up the JAXWSMessageReciever and the addition of an Endpoint Controller framework for easy service endpoints maintainability and to provide a reliable framework base for future service enhancements per JAXWS specification. \n",
            "Deploying services on the client side Purpose of the modification Axis2 provides a nice way of deploying services on the server side but no good way of doing the same on the client side. All the service deployment features provided by Axis2 on the server side can be very easily extended to client side. Currently on the server side you can package a service as a .aar file and deploy it. On the client you need to pass the wsdl url to the ServiceClient to send a message to a service. The proposed modification uses the same deployment features that are available on the server side for application on the client side. So with the proposed modification you can deploy a .aar file for use on the client side. Infact you can take the same .aar file from your server and put it on your client. This is very useful in the case where you are writing intermediaries and you are not using ServiceClient but instead calling the AxisEngine directly. The change is very minimal and has no impact on existing code. Details of the Modification When a service is loaded by Axis2 it makes an assumption that it needs to be loaded as server side. The idea is to not make that assumption and let the user specify via a parameter in the axis config file how the Engine should use the service. Deployment Engine will look for this config and set server side to true or false based on that. Here's the config parameter.. Added by Sandeep Trailside Systems. isclientside is used to indicate whether the deployed are to be used on the client side. If client side is set to true then a wsdl that declares a service of type will be interpreted as because that's how the client will have to treat it. The core axis Engine supports both client and server message flows. The Engine only needs to know whether the service is to be treated as client side or server side. Here's the code snippet that demonstrates the change that can be made to DeploymentEngine code.. ... ... AxisService axisService null; InputStream wsdlStream if { wsdlStream serviceName } if { WSDL11ToAxisServiceBuilder wsdl2AxisServiceBuilder new TODO: Added by Sandeep Trailside Systems. check if service is to be loaded for use on client side or server side axisService ... ... The big difference in treating a service on the client as opposed to server is in the Exchange A wsdl with an service when loaded on the server will create an Operation whereas on the client side it will create a operation. A rversal of MEP. IN becomes OUT and OUT becomes IN. I have all the required modifications to 1.1 in a zip file. \n",
            "Client API needs a method to access Current Message Context The generated client stub doesn't have a way to access MessageContext or SOAPHeader. Client would like to access the header upon returned from the service. It's ideal to add a getter method in the client stub or Service Client class. \n",
            "Cannot deploy multiple versions of the same service I am trying to deploy multiple versions of the same web service without changing the name of the service and wsdl. I want to be able to do that by changing namespace of the service in the wsdl file and location of the service. For example : MyService version 1 ServiceName MyService Location Wsdl namespace MyService version 2 ServiceName MyService Location Wsdl namespace Currently Axis2 doesn't have a mechanism to deploy multiple versions of the same service by chaging its location and wsdl namespace. The services repository has not been designed to accomadate multiple versions of the same service can have only one service It can probably be done providing support for deploying multiple versions of the same service similar to the mechansim provided for deploying multiple versions of the same \"module\". Gul \n",
            "Enable 2D Array Encoding When creating services that manage 2D array parameter type example there's need to enable 2D array encoding... On axis1 it's possible adding the following parameter on global configuration: There's no parameter or similar setting to allow the same on axis2. Please examine if it's possible to manage this parameter on axis2.xml or find a solution that allow to manage 2D Array... \n",
            "Polymorphic Schema Support by WSDL Schema Parsin. As a part of Polymorphic Schema support in JAXWS implementation Rich has added code to gather polymorphic package names using annotation walking on ServiceEndpointInterface. I am expanding this solution to add support where we now read WSDL Schema and imports to gather package names. I have also added support to read packages from JAXB SchemaBinding Customization. Finally have also made changes to ensure that we do not attemt to load packages using Runtime Class instead we read packages as String and then before creating jaxb context we use ThreadContext Class Loader and load all the classes in each package. This should give us full support to handle polymorphic schema. \n",
            "java2wsdl ant task would be handy resolution of issue it was but for older java2wsdl ant task would be handy in resolution of issue it was but for older version the classes required in the java file attached to that issue the required classes cannot be found.. \n",
            "SOAP Encoding support This has two parts .. first to provide SOAP encoding support without support for hrefs which shouls be relativley and the second to provide href support. \n",
            "Turn off web services through Axis2 web admin module Throgh the Axis2 web addmin interfce provide a way to remove off web provide a way to change service specfic parameters \n",
            "Binary Serialization support for SOAP Message \n",
            "Management support via JMX \n",
            "Use case for REST Yahoo Search Step Need an example for a well known REST service. for Example: Step Update to consume WSDL2.0 and generate code for REST web services. Dave Orchard has a wsdl for yahoo: \n",
            "Generating WSDL in the runtime when request for Implementation for at least HTTP request via \n",
            "Chuncking support for the simple HTTP Server and Axis2 default http transport Idea is to implement chuncking for the HTTP server and the deafult HTTP tranport. \n",
            "JMS transport for Axis2 JMS transport for the Axis1.x implementation will give good insight in to how to do this. \n",
            "Message Context Serialization Support Support to store and restore the Message context .. this involve the Axis storage and context serialization \n",
            "E4XProvider for Axis2 E4XProvider allows users to deploy java script code that provides web services businuss logic \n",
            "XPath support for AXIOM Adding XPath support can be easily done using Jaxen. Involves implementing org.jaxen.Navigator. More details in their FAQ I'd highly recommend adding this to our 1.0 list. dims \n",
            "Commons transport sender for Axis2 This is expected to provide the chuncking support and help providing the keep alive in HTTP transport \n",
            "implementing DOM on AXIOM this needed for the SAAJ and support. we need the samples and docs \n",
            "chuncking support for the Simple HTTP server This can be fixed using the Chuncked input stream \n",
            "Support for registering custom MessageReceiver for an operation There can be cases where a few service implementation classes would demand special style of invocation is the case with me that my services if they are implementing ServiceLifeCycle interface I'd like to call special methods on them apart from the method that matches with the client requested operationName And in such cases if developers do code their custom MessageReceivers there should be a way to specify the same in the service or operation element of service.xml . And also our deployment should be embedded the intelligence to setMessageReceiver with that specified class rather than the default one. Thanks and Regards Jayachandra \n",
            "Service Groups Axis2'ers: I've been thinking recently about a couple of things with respect to Axis2. First of the idea that we might want to support some concept of \"service groups\" a bunch of individual services which are related somehow implemented with the same Second of I'm thinking of building a JBI implementation on top of and JBI's notion of \"components\" are deployable units which can each provide multiple services. What about changing our model slightly to enable \"components\" to implement more than one Web This would I believe: Change to for Add a \"ComponentContext\" level to the context stack between ServiceContext and ConfigurationContext Components would be just like services looking at the code I don't see this for services yet... need to dig around component.xml for would contain 1..N elements each of which looks like the current so the minimal file would be We could allow optimizing this to just at the top level \n",
            "Add system level hooks Axis2 should provide a mechanism to execute system level where resources available across services can be initialized outside of a service request. The classic use of this is to create and initialize a database in order to remove the connection creation from any single service as well as to limit the number of database connections that can be open at a given time. The mechanism should have access at least to the ConfigurationContext. It would be nice if it could also access a but I'm not sure if this will work. As an in a this can be done using a servlet which gets a message when the servlet is created and another when it's destroyed. \n",
            "Add TargetResolver configuration and loading mechanism. Issue to add the pluggable target resolution discussed in thread at: Attachments: core.patch.txt changes to the core module including the new funtion integration.patch.txt new test for this function an an example as \n",
            "Adding OneWay and Asynchronous Callback functionality for Dynamic Proxy This is a new feature for Dynamic Proxy. I have now extended the proxy wrapped support to make Async method calls. The BaseProxyHandler now looks at the signature and return type of the method to determine if its a Asynchronous call. It also check for method name to end with Async if the return type is Future or Response. I have also modified proxy to implemented new features in InvocationController to get JAXB Block directly rather than reading MessageAsOM. Next I will be adding Holder functionality to Proxy. \n",
            "Plugpoint to allow for migration between context and TLS We have an issue with some APIs requiring that data be present on Thread Local Storage I believe that we can work around least for needing to migrate information between and can simply get away with storing it in one of the contexts and then moving it to TLS before we get into user space up through the service programming and then back again if need be. \n",
            "JAXWS Dynamic Proxy new Updates and test cases Updates to dynamic added new functionality and refactored ProxyHandler code. Also created ProxyDescriptorFacotory and ProxyHandlerFactory. I have added test case for Proxy invocation and updated maven.xml so jaxb schemas are generated at build time. More functionality in Proxy to come..... \n",
            "MMS transport support for Apache Axis2 Developed MMS transport for Axis2. This is part of my project for Google Summer of Code 2006 first part was to build a MMS transport for Apache Mirae and after I finished that I made the MMS transport functionality for Apache Axis2. More information about my project can be seen here . Patch coming up .. \n",
            "Initial scaffolding for Metadata renamed from MDQ Some refactoring of the JAXWS Metadata Abstraction Layer Description for initial factory to create Description objects. This factory was previously refered to as the MDQ Query but has been renamed from MDQ to be the DescrpitionFactory. The associated MDQ packages have been deleted. \n",
            "JAXWS Dynamic Proxy This is the first set of classes for Dynamic I have also created some test cases that I will be checking in. For feature details of proxy see the following jira JIRA \n",
            "Add support for disengagement of modules to administration web frontend It would be great if modules could be disengaged using the admin \n",
            "Add the feature to add comments in WSDL file by having a parameter in services.xml file in axis2 In Axis if I need to add a I can set it using the API. created by There is no similar way to create in AXIS2 \n",
            "Metadata Exchange support on Axis2 New features to support specification on Axis. to support incoming Get Metadata request message from SOAP protocol Axis2 SOAP processing is extended with new metadataExchange and allows of Data Locators. Data Locator is responsible to perform data retrieval. The support allows other Web Services engines that build on top of Axis2 to support different data retrieval implementation. \n",
            "JAXWS support in codegen We need to be able to generate service and client code based on the specification. dims \n",
            "Add \"Service Object Supplier\" Support EndpointLifecycleManagerImpl does not use ServiceObjectSupplier service parameter and always creates new instance of service object by So we can not use JAXWS with other service object suppliers like Spring. Ali Ebrahimi Mehdi Bahribayli \n",
            "Implement W3C WSDL 2.0 CR I am opening a JIRA for this work to give us a place to track it. Glen took an action in the WSDL 2.0 Working Group Implementors call a few weeks ago to do this but he must be too busy. See for a discussion. The requirement is to support WSDL 2.0 alongside WSDL 1.1. This means to upgrade the WSDL2Java and Java2WSDL tools and to generate WSDL at runtime there is no WSDL deployed with a Web Work is underway already. Chathura is looking at replacing the Axis2 WOM with the Woden Component Model. That would achieve WSDL 2.0 support. For backward support of WSDL some new extensions would have to be defined for WSDL i.e. the WSDL 2.0 Component Model could be extended to express the features of WSDL 1.1 not supported by the core WSDL 2.0 spec and its adjuncts. I asked Matthew to look into this. It would greatly help the current W3C WSDL 2.0 Candidate Recommendation advance to the Proposed Recommendation stage if Axis2 could provide an implementation and participate in an interop event within the next few months. \n",
            "CLONE request and response with Schema Currently the content is not validated against the Schema definition in the WSDL. I propose to add a Handler that can be added to the request the response handling on the server even on the I think this would simplify many problems when developing a client. The request validation might even be switched on in production environments to reduce the risk af malicious requests or to reduce the load on the backend in case of DoS attacks that Axis is used as a sort of that forwards the request to another \n",
            "[Axis2] Documentation for Session Mgt Attached is the documentation for session mgt. Please apply the from xdocs folder. \n",
            "Session Management Session Management This patch containes transport independent session mgt using EPRs Interfaces All interfaces are located in the core module Main interfaces useful for users org.apache.axis2.session.Session org.apache.axis2.session.SessionManager org.apache.axis2.session.SessionIdFactory There is a Null impl for these interfaces within core Implementation All implementation specific classes are located in the session module Clustering impl Clustering impl is located within the clustering module empty classes so Examples in the samples ATM example Echo example \n",
            "CLONE request and response with Schema Currently the content is not validated against the Schema definition in the WSDL. I propose to add a Handler that can be added to the request the response handling on the server even on the I think this would simplify many problems when developing a client. The request validation might even be switched on in production environments to reduce the risk af malicious requests or to reduce the load on the backend in case of DoS attacks that Axis is used as a sort of that forwards the request to another \n",
            "A default TransportInProtocol it would be nice if: new if line was the default and didn't need to be set. there doesn't seem to be a reply tranport in the so the default protocol would likely be the same as the targetEPR. \n",
            "ServicesDirectory parameter should support http access for external services repository I'm trying to configure an external WebDAV repository for the services. I am using After axis2 is it cannot load the services from the repository and displays an empty list. This is the parameter in axis2.xml which I am modifying: override you need to uncomment following parameter and value SHOULD be absolute file Has anyone tried this Using Internet I can open the webdav folder above with no problem. Angel \n",
            "Sandesha2 with Axis2 We need to make Sandesha2 work with Axis2. \n",
            "Add Spring Support Add SpringReceivers to invoke Spring Beans as the implementations of Services. Scratch code is here: We really should refactor the MessageReceivers as there is plenty of common code between Java Object and Spring. \n",
            "Adding service scope control There should be a parameter in services.xml which let you control the service scope of the impl class on a per application In Axis1 there is such a parameter you can set in \n",
            "Generate stubs using correct OperationDescription We have multiple OperationDescriptions and depending on the MEP code generation should create correct OperationDescritions in stubs. In current codeganeration generate stubs only with OutInOperationDecrition it has to be improved to do the right thing. \n",
            "Add Spring Support Add SpringReceivers to invoke Spring Beans as the implementations of Services. Scratch code is here: We really should refactor the MessageReceivers as there is plenty of common code between Java Object and Spring. \n",
            "A cloning mechanism for SOAPEnvelopes and OMElements We got a requirement for cloning SOAPEnvelopes in the Sandesha2 implementation. It seems that this has not been implemented yet. The scenarios is this. In WSRM we have to at times messages. Currently we make a copy of a message context and send it every time. But since the SOAP envelope cannot be cloned we have to share it between resends. Unfortunately this causes the handlers after RM to add their headers again and again. For example messages have multiple ReplyTo headers. \n",
            "A module should be able to add a response message within the InFlow Suppose the user has deployed a Ping Service a ping and RM module is deployed. Only the RMHandlers of the in path get called the user has set an InOnly message The RM module may want to send an acknowledgement message as response instead of simply sending 202. So the RMHandlers of the InFlow should be able to set this message beforehand. One way to do this is making AbstractInMessageReceiver more flexible. If a response message has been set in the OperationContext a handler in the the AbstractInMessageReceiver has to work as an InOut message receiver and it should send this message. Or is there a better \n",
            "Support for This is especially useful for REST support where typically a deployer provides a link to the schema to the users of the web service. \n",
            "ServiceBuilderExtension for Axis2 Deployers Refer the following discussion[1] to find objectives of this idea. ServiceBuilderExtension can take following API. public interface ServiceBuilderExtension { public void ConfigurationContext public throws DeploymentException;; } and possible to register them with deployers as follows. name One deployer can have number of ServiceBuilderExtensions and will invoke them in the order they defined in the axis2.xml file. For a given if all ServiceBuilderExtensions fail to create AxisService then base deployer will take care about the deployment of that particular deploymentFile. For a given if a ServiceBuilderExtension could create a AxisService then stop execution of other ServiceBuilderExtensions registered and return the AxisService immediately to the base deployer for the further processing. Axis2 AbstractDeployer implement necessary helping methods for this idea so that extended Deployer from AbstractDeployer can easily utilise ServiceBuilderExtension concept. Immediate goal is to support artefacts through ServiceDeployer . [1] [2] \n",
            "A JSON sample using yahoo search API This patch contains a JSON sample which uses the Yahoo search API gives the response in JSON when the parameter is set using GET Here the request is sent in using GET method and the response is received as a Mapped formatted JSON string. This Yahoo search API gives the response with the content type and this content type is mapped with the Mapped JSON builder in the axis2.xml. \n",
            "Introduce Reflection based DBC Tool to MDQ This will introduce the ability to create a set of DescriptionBuilderComposite objects by reflecting on a web service implementation or SEI class. This will eventually remove the need for MDQ to have separate code paths for DBC and Class related objects. \n",
            "ClusterManager based abstraction to replicate the state of the Context hierarachy To capture the changes we do regarding the ClusterManager based abstraction. \n",
            "A method in HTTPSender to send GET messages With the new message formatter concept in SOAPOverHTTPSender name will be changed to something has become the common sender for all formats including REST. So the RESTSender will be removed soon and there will be a message formatter for REST too. Other than there are some situations where JSON responses are sent using GET method. Because of these there should be a method in HTTPSender to send messages using GET method. So I have implemented this and the patch is attached.... \n",
            "Management module persistent configuration Management module provides functionalities to monitor and configur remote Axis2 engines. Currently it provides configuring API using web services and jmx. It also monitors statistics of remote engines like incoming and outgoing messages at service and operation levels. Code is located at the url: Currently the configurations made for Axis2 by using the above management API or by the admin webapp are not persistent after system restarts. The management module is improved to provide such persistent support by saving the entire configuration to an xml file and loading it back to the remote engines after system restarts. \n",
            "Support for specifications There doesn't seem to be much support for Axis2 in this space. I am working on an implementation. Will add the code through this JIRA page soon. \n",
            "Add SPI to allow naviation to ServiceDelegate and associated EndpointDescription from BindingProvider Add the abilility to navigate from a BindingProvider to the ServiceDelegate and the EndpointDescription. The BindingProvider is implemented by the Proxy handler and the Dispatch that are returned to the client. Middleware this new can cast the Dispatch or the proxy handler returned from Proxy.getInvocationHandler to the spi BindingProvider inteface and then retrieve the ServiceDelegate or the EndpointDescription. See the test for an example. Also refactor PortInfoData into the EndpointDescription and added protocol to return a PortInfo object from the EndpointDescription. \n",
            "org.apache.axis2.wsdl.util.CUtils for C realted keyword checking This class is introduced to add methods to check C language specific key words. package org.apache.axis2.wsdl.util; import java.util.Arrays; import java.util.Locale; import java.text.Collator; public class CUtils { static final String keywords[] { \"while\" }; Collator for comparing the strings static final Collator englishCollator Use this character as suffix static final char keywordPrefix Checks if the input string is a valid C keyword. Returns boolean. public static boolean { return } Turns a C keyword string into a keyword string. now this simply means appending an public static String { return keywordPrefix keyword; } } \n",
            "Codegen and runtime changes for supporting \"full\" WSDL 2.0 HTTP binding Enhance REST support and codegen to handle WSDL 2.0 Primer Travel Reservations PUT GET and the weather service by Hugo [1] [2] dims \n",
            "Provide a \"unload\" or \"remove\" link on the Axis2 admin page The Axis2 admin page does not offer an \"undeploy\" or \"remove\" link. If one develops a service using axis2 and from time to time has to a new version of the .aar one gets a friendly message \"The file successfully but the service that then gets called remains the old i.e. the previous service does NOT get replaced by the just uploaded That IMHO is a bug the message should that the newly uploaded service will NOT be until the server or axis2 is restarted. Querying in the newsgroup I that there is a \"hotupdate\" flag and that works fine. having the capability to remove a service might still be worthwhile. Occasionally one may want to remove or withdraw some service without having to restart the server or axis2 thereby potentially disrupt concurrent Michael \n",
            "There should be an option when we are doing a wsdl2java for different packages for stubs and skeletons As the stubs and skeletons are two different entities corrosponding to client side and server side so when doing a wsdl2java we should have an option to specify different packages for stubs and skeletons \n",
            "for Corba Module It should be possible to protect Corba services exposed with Axis2 Corba module with Corba module should map to CSIV2. \n",
            "wsdl2java issues log4j warnings every run Annoyance: The wsdl2java is emitting log4j config warnings on every invocation on Windows. do this on Mac OS X 10.9 for Using Using log4j:WARN No appenders could be found for logger log4j:WARN Please initialize the log4j system properly. Usage: WSDL2Java [options] or : A url or path to a WSDL Looks like the same issue as in item 1. But the workaround it mentions doesn't probably because paths have changed since whatever release it was using. In I can get rid of the warnings with a similar workaround: add this to wsdl2java.bat at line after \"set set Can wsdl2java be fixed to not emit the log4j warnings by \n",
            "ZooKeeper based clustering implementation Currently the clustering implementation in Axis2 is based on Apache The purpose of this feature is to provide an clustering implementation based on Apache ZooKeeper[1] as an alternative. [1] \n",
            "Spring integration for Axis2 In present two 3rd party projects targeted to provide Axis2 spring integration are not active anymore. Also I noticed that there were few discussions happened on Axis2 developer mailing list time to time but didn't make continuous progress. For the moment I found following points as objectives of this projects. Use Spring application context file to configure Axis2 framework without using axis2.xml file. Use Spring application context file to add Axis2 web services and Axis2 modules. Use Spring application context file to access Axis2 web service from client side. \n",
            "ZooKeeper based clustering implementation Currently the clustering implementation in Axis2 is based on Apache The purpose of this feature is to provide an clustering implementation based on Apache ZooKeeper[1] as an alternative. [1] \n",
            "I can not send Map object as parameter. I would like to send Map object as SOAP message. I try to create OMElement by send Map object in array like this... OMElement payload new Object[] But I got... the arg1 should has content like this... but it empty. Because I would like to migrate from Axis to Axis2. In Axis I use .. result It work fine. Please any one tell me how should I Thank you... \n",
            "Modules should have an easy way to specify Axis2 version compatibility I don't think this is already but correct me if I'm wrong. We could use the capability to express Axis2 version compatibility in the module.xml file. Something like: ... Where you could specify \"version\" for an exact or for any version including or after the specified one. This would prevent people from deploying modules that rely on later Axis2 features on earlier versions. \n",
            "Implementing MTOMPolicy OptimizedMimeSerialization Implemting \n",
            "Reading class array from Jar file for creating JAXBContext I am adding code to update JAXBUtils to read classes from jar file in order to collect list of classes to create a JAXBContext. So as per current logic we will read context path if anvObjectFactory is defined in a given package. if we will read all the classes from the file system directory and jar files for a given package. \n",
            "JSON support for Axis2 I've implemented the JSON support for Axis2 and i'm attaching the patch with this. I used the following JSON StAX parser implementation Apache which contains a StAX reader and writer for JSON. Jettison current version works only with jdk 1.5. So I have already sent the patch to make it working with jdk 1.4 too. Hope they will apply it soon.I have uploaded the jettison jar which works with jdk under an OMSourcedElementImpl object is used with a JSONDataSource in the receiving side. It can be used to build the OM element in case of a java service or it can be used to get the JSON string directly without building the OM in case of a java script service. I've implemented a JSONOMBuilder which gives the OMSourcedElementImpl when the method is called. This patch also contains an JSON integration test. \n",
            "JavaScript services deployed in Axis2 I've written a message receiver which enables JavaScript services to be deployed in Axis2. I've bundled a deployable .aar within the .zip archive as well \n",
            "EJB provider is not available for Axis2 Axis 1 comes with an EJB provider. But there is no EJB provider in Axis2. \n",
            "Optimizations for Axis2 POJO web services I did some optimizations for the Axis2 POJO web services as an intern project in last two months. It was a research type project and its idea was to handle POJO web services without using Java Reflection to improve the response time. The method I followed to accomplish it when a POJO service is Axis2 generates a code which contains the logic to invoke that service. To generate this code Java reflection is used. In the run time service is invoked through the generated code for that service. The generated code is like the code is like the code generated by wsdl2java tool using ADB. So the idea was to achieve the performance of ADB services for POJO services by this. In wsdl2java tool code is generated as .java files. But in this case those had to be generated as .class files because those have to be invoked at runtime. To do this I used a Java bytecode library called JavaAssist. Currently this new michanisam support most of the Java types Java beans and data handlers. But its not mature enough like the existing mechanism and therefor i integrated it with the existing mechanism instead of replacing it. To use this new method a parameter can be added to the service descriptor like below. true If this is included service invocation will done using the new mechanism and other wise usual procedure will be followed. Attached patch contains the changes done by me. To test the new method one can apply this patch to a downloaded trunk in a local build the trunk and create a new war file and deploy it. Then create a POJO service and add to service descriptor and deploy it. Here the code will be generated as class files in the temp directory. If someone want to look in to them as Java code those can be written as text files in addition to .class files by uncommenting the statements in code generating classes classes are included in the \n",
            "Extend Spring support to accept beans Now AXIS2 offers only ContextLoaderListener as Listener for Spring It's initialized during deploy of war For using spring beans axis2 must support also add suport or provide workaround for this issue \n",
            "adb codegen WSDL2C emits incorrect code for xsd:time and xsd:date Class org.apache.axis2.schema.typemap.CTypeMap assigns the native datatype to represent and xsd:time in the generated code. The code generation template in file chooses the serializer and deserializer routines to call based on the native datatype. As a result the generated code contains calls to for xsd:date and xsd:time where and are appropriate. Same applies for the calls. Potential fixes: Add typedef names for and as aliases for struct and change the CTypeMap to use them. Modify the template to consider the schema type names when generating for elements. I don't know enough to know whether this information is available to the template. \n",
            "There is no way to communicate between the CallbackHandler and the runtime context The CallbackHandler has a \"handle\" method to be executed in order to authentificate a but if it needs the message context for example to set cannot access it. Solution should be to be provided a meaningfull some reference to communicate between the callback handler and axis2 runtime e.g to be more interactive. \n",
            "Basic Authentication support Working on providing HTTP Basic Authentication support per JAXWS Section 10.4.1.3 Security. \n",
            "Enabling modules to AxisMessage In order to support policies that are attached at message it is necessary to enabling module disengagement on AxisMessage \n",
            "Enable SOAP session support for both Axis 1.X clients and those not using WSA We should be able to provide as much functionality as possible to peers that do NOT use As such it would be nice to implement support for a simple SOAP session mechanism such as the one from Axis1.X. This would give us a dual benefit supporting scenarios and also with Axis1.X services and clients. \n",
            "Additional Holder Functionality I am adding following functionality to holder Adding Asyc support and test case. Adding Support for Headers and Holders in Headers. Adding Support to use target name space. I will submit patch for these listed functions. \n",
            "Adding Initial Holder Support and Refactoring Client and Server Message Marshalling. I am adding Holder support to JAXWS Proxy code. I will add test cases for Wrap and Bare methods that use Holders. Seconldy I am adding the common Method Marshaller code that will be used on client and server to marshall message and demarshal Message. I have discussed the architecure with Rich and Nick on this so they are aware of the changes. As a result of refactoring the abstract ProxyHandler model and Proxy Descriptor on client and Mappler code on server side will be deleted I will submit patch for this JIRA. \n",
            "Review \"WSDL 1.1 Binding Extension for SOAP 1.2\" and \"SOAP 1.1 Binding for MTOM 1.0\" \n",
            "Need to enhance code generation from WSDL to support JMS extensions there is no support for JMS WSDL extensions in Axis 2.0. Code generation for a WSDL service with JMS bindings but the client stub is missing a default JMS endpoint and transport elements and appropriate properties from should be placed into the generated services.xml file. To do the appropriate extension elements for JMS in the WSDL must be recognized. This requires adding them to WSDL4J's extensibility mechanism. The appropriate implementations already exist in the Apache WSIF project: \n",
            "Fault Handler not reached when soap envelope contains empty namespace A customer has a requirement that our application be secure. One of the issues brought up was component names being leaked in error messages which may assist hackers by providing info they may use in future attacks. To resolve this issue we attempted to use a simple custom handler that checks for a fault and replaces the message with something more generic. The axis2.xml file was then modified to include the handler within the InFaultFlow and OutFaultFlows in the appropriate section as defined by the axis2.xml. However when a namespace is empty in the soap message or there is an issue in the envelope at the root element example: ...otherwise well constructed soap message the AxisServlet throws an AxisFault exception bypassing the handlers and leaking info example result: ... Illegal character unicode encountered: not valid in any content at .. \n",
            "Error when displaying web service WSDL Web service deployed to WebLogic Server 12 runs fine however when trying to display the WSDL results in the error below. We use utilities to create client code to consume the web services which requires the WSDL. This error is preventing us from doing that. Note this did not occur in version 1.3 but with the new wsdl utility classes as the one referenced in the error. java.lang.ClassCastException: org.apache.axis2.wsdl.util.WSDLDefinitionWrapper cannot be cast to oracle.j2ee.ws.wsdl.DefinitionImpl at at at at at at at at at at at at at at at at at at at at at at at at at \n",
            "upgrading from axis2 1.4 to 1.6.4 Hi This is related to existing JIRA We are upgrading from axis2 1.4 to 1.6.4. We upgraded successfully and got response from provider with method. After 4 to 8 request the service is throwing below error intemittently. Error: at at at at So we added few logging to Kernel 1.6.4 and found that after few request method in the serviceclient is cleaning the the following request getting failed with Null error. Also we see changes in AxisCOnfiguration in 1.4 and 1.6.4 in Cleanup Is this the normal behaviour in axis2 \n",
            "Axis2 1.7.0 eclipse plugin doesn't work on a fresh install of Mars.1 release I've dropped the 2 jar files into the \"dropins\" folder but it still this doesn't work. Both wizards don't show up in New Other... I've seen a similar issue for 1.6.3 that has been marked as \"solved\" in 1.6.4 and 1.7.0. Thank you \n",
            "ClassCastException from org.apache.axis2.saaj.SOAPElementImpl We have have which worked fine with Axis 1.6.2 Axis 1.6.2 . The moment I try to upgrade to the Axis 1.7.1 or to Axis 1.7.2 the following exception is thrown from SOAPElementImpl java.lang.ClassCastException: org.apache.axis2.saaj.SOAPElementImpl cannot be cast to org.apache.axiom.om.OMElement at at at at at at at at \n",
            "AxisConfiguration is NULL Am using the axis2 1.7.2 I have deployed the axis2.war in the tomcat and started the service. The StockQuoteService can be listened via the below url I have created a client to request that service the complete project To trigger multiple I have invoked the client call method in the For loop from main method To avoid creating the multiple am caching the http client and reusing it. When I run the program with this around 46 requests are executed successfully and returning the response. After that NPE in thrown. After investigating about found that the JVM is expelling the ServiceClient object ServiceClient.java protected void throws Throwable { try { } finally { } } public void throws AxisFault { if a configuration context was created for this client there'll also be a service so discard that if { String serviceGroupName AxisConfiguration axisConfiguration AxisServiceGroup asg if { } } else { } } When the finalize method is it is invoking the cleaup method which again calls the terminate method of ConfigurationContext. Because of this AxisConfiguration in the ConfigurationContext is becoming NULL. Once this cleanup is the subsequent requests are not able to process due to empty AxisConfiguration returned from ConfigurationContext. This whole issue is due to reusing the HttpClient. When the HttpClient is not this error is not thrown. But as per our project we will be getting multiple requests from the end user and we need to reuse the HttpClient. Kindly advice at the as we are facing this issue in the production \n",
            "Upgrade HTTPCore and HTTPClient into latest versions Axis2 1.7.0 and 1.7.1 ship with vulnerable versions of and products include Apache HttpClient products include Apache HttpClient 4.2.1 and Apache HttpClient Additional information on these vulnerabilities can be found at this link: and should be upgraded to the newer GA versions available and should be removed if possible. \n",
            "bad link for axis2 intellij plugin this link loops back to when attempting to download the intellij plugin. \n",
            "WSDL11ToAxisServiceBuilder fails to determine the MEP when wsdl bindings are defined in an imported document When deploying a web service archive with and a wsdl which imports the bindings from another the WSDL11ToAxisServiceBuilder fails with \"Cannot Determine the MEP\" exception. The issue seems to be caused by wsdl4j which does not properly populate binding's port type this is reported in wsdl4j jira: since Axis2 will do a search in imported wsdls to find the port it will not use the port type in the parent but the port type in the bindings' wsdl. I'm providing an 'EchoService.aar' that demonstrates the issue please raise Axis2 log level to DEBUG to see the exception. \n",
            "Axis2 web service not working on Weblogic12c We have created 2 web one we deployed from Eclipse and one from Weblogic12c console as a war. Observation : Eclipse deployed webservice application is getting hosted properly and we are able to see our webservice getting hosted. we exported WAR from eclipse and tried to deploy the same from weblogic12c console. we codnt see webservice we are trying to host. \n",
            "WSDL2Java converts marshalls non charecters to another non charecter In our we have many java web services built using axis2 1.3 version and are deployed on Websphere server. Now we have to add new operations to exisitng web service. so new schama contain non charecter ö. We use WSDL2Java utility to generate proxy classes from WSDL and xsd. For the given another non charecter got generated in the generated class i.e. Ã¶. This causing compile time error. Could you please help me to resolve this Thanks \n",
            "Invalid wrapper tag name in request when using wrapped pattern in WSDL When using wrapped pattern in sent by the generated using can have invalid letter case in the request's wrapper tag name. We have a WSDL file containing an opertaion with style. This opertaion uses \"wrapped\" as described here: The name of the operation has first capital letter. We generate client code from this using WSDL2Java or When we try to use generated code to call the we get invalid soap having wrapper tag name starting from the lowercase letter if an operation name is we get a wrapper tag named We have dived into the source code of and have found the cause of that bug. InterfaceImplementationTemplate.xsl the org.apache.axis2.wsdl.template.java in several places uses operation name instead of original operation name from WSDL \n",
            "AxisService.wsdl for any imported wsdl always resolves to root contains: BUT wsdl:import EchoBindings.wsdl resolves to root instead of \n",
            "Issue with web service call HttpClient java.net.SocketException: Socket Closed due to stale SSL java 8 We are in the process of upgrading an axis2 application from java 6 to java 8 and have been running tests against existing axis2 services. We have a web running on that is placing a client also via to an external web service via an SSL connection. After switching from java 6 to java 8 we have found that the client call is still working. when placing a second call to the same web service the call fails with a \"java.net.SocketException: Socket Closed\" exception. This issue is occurring i.e. if we restart the tomcat server and then execute the web service which places the client via the same exception is logged. On further analysis of the log file it seems on the second the http connection is being returned from the cache via the httpclient MultiThreadedHttpConnectionManager class. The exception is as below: DEBUG org.apache.commons.httpclient.HttpConnection An error occurred while reading from the is appears to be stale java.net.SocketException: Socket Closed at at at at at at at at at at at at at at at at at It therefore seems that the remote to which we are placing the client is closing the connection immediately after sending the response but that the client is not detecting this. When the next web service call is placed via the client the connection is retrieved from the connection the check is the connection is not correctly detected as being stale and then the method is called to reset the socket java net then detects that the connection is no longer active and raises the socket exception. Note that when this issue occurs it is no longer possible to run this web i.e. the socket exception is then output on every invocation of the service until the tomcat server is restarted. note that this issue only occurs with java 8. The socket exception is not output with java 6. I have performed tests with different versions of axis2 and found with version the same socket exception is output but that a new connection is then opened and the web service then executes and returns a response without issue. I read the Apache Axis2 1.7.0 release note which states that Axis2 1.7.0 and above supports Apache HttpClient 4.x in addition to the no longer maintained Commons HttpClient 3.x. I have attempted to follow the instructions for upgrading the HttpClient to release 4.x but in the log file I'm still seeing output for org.apache.commons.httpclient.HttpConnection. It seems that the change applied to the axis2.xml config file is not taking effect. Please could you help with the resolution for the socket exception issue and also give guidance with upgrading the HttpClient to version 4.2.5. \n",
            "Unable to deploy service classes with final modifier I am acutally not really sure if this is a Bug or wrong configuration but as wished here as an issue. Hi I currently got the problem that I am not able to access my service. I patched it from axis 1.5.1 to axis 1.7.1. The old version still works fine but if I deploy the upgraded version and try to access it via a simple testclient I get the following error that the server does not even log with logging level on debug: {code:xml} class de.fiverx.steuerberater.ws.v1.Service must have public as access {code} my Service class looks as follows: package de.fiverx.steuerberater.ws.v1; public final class Service implements SteuerberaterOnlineServiceSkeletonInterface { public { return new } } {code} and at last my services.xml {code:xml} This file was from WSDL by the Apache Axis2 version: 1.5.1 Built on : Oct 2009 {code} removing the final keyword does not help either. Any suggestions what is going wrong P.s.: I am currently updating 7 projects to this axis2 version and only 1 project does not have this error. The configuration though is pretty much the same. That's why I do not understand what the mistake might be. \n",
            "ADB java.lang.Boolean type mapping incorrect for '1' and '0' is but in version 1.6.3 SimpleTypeMapper.java still contains ... private static final String \"java.lang.Boolean\"; ... } else if { return } ... Therefore both '0' and '1' are parsed as 'false'. \n",
            "faultString: java.net.ConnectException: A remote host did not respond within the timeout period. I am using for creating a webservice in java. I created the webservice and its perfectly working in UAT environment. In production it throws the below issue. Kindly look into it and send the solution asap 10:16:06:852 EDT] 0000001c SystemErr R AxisFault faultCode: faultSubcode: faultString: java.net.ConnectException: A remote host did not respond within the timeout period. faultActor: faultNode: faultDetail: A remote host did not respond within the timeout period. at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at 10:16:06:852 EDT] 0000001c SystemErr R java.net.ConnectException: A remote host did not respond within the timeout period. 10:16:06:853 EDT] 0000001c SystemErr R at 10:16:06:853 EDT] 0000001c SystemErr R at 10:16:06:853 EDT] 0000001c SystemErr R at 10:16:06:853 EDT] 0000001c SystemErr R at 10:16:06:853 EDT] 0000001c SystemErr R at 10:16:06:853 EDT] 0000001c SystemErr R at 10:16:06:853 EDT] 0000001c SystemErr R at 10:16:06:853 EDT] 0000001c SystemErr R at 10:16:06:853 EDT] 0000001c SystemErr R at 10:16:06:853 EDT] 0000001c SystemErr R at 10:16:06:853 EDT] 0000001c SystemErr R at 10:16:06:853 EDT] 0000001c SystemErr R at 10:16:06:859 EDT] 0000001c SystemErr R at 10:16:06:859 EDT] 0000001c SystemErr R at 10:16:06:859 EDT] 0000001c SystemErr R at 10:16:06:859 EDT] 0000001c SystemErr R at 10:16:06:859 EDT] 0000001c SystemErr R at 10:16:06:859 EDT] 0000001c SystemErr R at 10:16:06:859 EDT] 0000001c SystemErr R at 10:16:06:859 EDT] 0000001c SystemErr R at 10:16:06:860 EDT] 0000001c SystemErr R at 10:16:06:860 EDT] 0000001c SystemErr R at 10:16:06:860 EDT] 0000001c SystemErr R at 10:16:06:860 EDT] 0000001c SystemErr R at 10:16:06:860 EDT] 0000001c SystemErr R at 10:16:06:860 EDT] 0000001c SystemErr R at 10:16:06:860 EDT] 0000001c SystemErr R at 10:16:06:860 EDT] 0000001c SystemErr R at 10:16:06:860 EDT] 0000001c SystemErr R at 10:16:06:860 EDT] 0000001c SystemErr R at 10:16:06:860 EDT] 0000001c SystemErr R at 10:16:06:860 EDT] 0000001c SystemErr R at 10:16:06:860 EDT] 0000001c SystemErr R at 10:16:06:860 EDT] 0000001c SystemErr R at 10:16:06:860 EDT] 0000001c SystemErr R at 10:16:06:860 EDT] 0000001c SystemErr R at 10:16:06:860 EDT] 0000001c SystemErr R at 10:16:06:860 EDT] 0000001c SystemErr R Caused by: java.net.ConnectException: A remote host did not respond within the timeout period. 10:16:06:865 EDT] 0000001c SystemErr R at 10:16:06:865 EDT] 0000001c SystemErr R at 10:16:06:865 EDT] 0000001c SystemErr R at 10:16:06:865 EDT] 0000001c SystemErr R at 10:16:06:865 EDT] 0000001c SystemErr R at 10:16:06:865 EDT] 0000001c SystemErr R at 10:16:06:865 EDT] 0000001c SystemErr R at 10:16:06:865 EDT] 0000001c SystemErr R at 10:16:06:865 EDT] 0000001c SystemErr R at 10:16:06:865 EDT] 0000001c SystemErr R at 10:16:06:865 EDT] 0000001c SystemErr R at 10:16:06:865 EDT] 0000001c SystemErr R at 10:16:06:865 EDT] 0000001c SystemErr R at 10:16:06:865 EDT] 0000001c SystemErr R at 10:16:06:865 EDT] 0000001c SystemErr R ... 35 more \n",
            "versions 1.0 1.2.2 are subject to requires 1.3 version of versions 1.0 1.2.2 are subject to requires 1.3 versions 1.0 1.2.2 are subject to \n",
            "Axis2 update from 1.6.2 to 1.7.1 missing web service operation doesn't work anymore i've update recently our axis2 from 1.6.2 to 1.7.0 and at the begining no ws was working anymore. I saw afterwards that 1.7.1 was released installed that one and worked till i've started to check ever operation in my services. The Problem: Object structure as return types. I knew that was a problem before and some types need to be exposed directly in service but now after the update some types that were before working now don't work anymore. The same thing with generic classes... a bit dissapointed i may i was positive surprised about the maps and lists as return types and now it's even worste as before. Some examples that in 1.6.2 have worked and now doesn't work anymore: {code} public { DataList ist not not present in TypesTable. } public Response { } {code} Where response looks like: {code} public class Response { private Header header; private Content content; setters section } public class Content { here can be of course some of these types will not be found in TypesTable private Object payload; } {code} Workarounds: {code} in service class expose types public DataList return null; } {code} Any ideas why axis can't do this by itself object Some other Why is after update I mean we have enum support now but stuff isn't working Thanks and Vasile \n",
            "Generated code for xsd:totalDigits throws NumberFormatException In relation to issue generated code for type: {code:xml} {code} produces a class with setter: {code:java} public void { java.lang.String totalDigitsDecimal if { param; } else { throw new \"Input values do not follow defined XSD } } {code} ConverterUtil.convertToStandardDecimalNotation produces a BigDecimal with a value but contains code: public static long String { return } {code} which parses second string parameter as a throwing a NumberFormatException \n",
            "RobustOutOnlyOperationClient does not respect Options.isExceptionToBeThrownOnSOAPFault RobustOutOnlyOperationClient extends OutInAxisOperationClient and the latter respects Options.isExceptionToBeThrownOnSOAPFault when there is a fault in the response. But RobustOutOnlyOperationClient doesnot respects is there any reason for I would like to be able to manipulate both in the same way and not have to handle Exception to treat Faults. \n",
            "Request for removal of dependency of 3.1 on Apache Axis2 Hi Request for removal of dependency of 3.1 on Apache as this version of httpclient bundled in is exposed to to the vulnerability The Vulnerability says that the class in Apache Commons HttpClient before 4.2.3\" is vulnerability. Additional information on these vulnerabilities can be found at these links: Dependency of should be upgraded to the newer GA versions available Deepak \n",
            "Invalid Configuration in Axis2 Maven POM In the Maven POM under the 1.7.3 branch the execution for the is incorrectly located within the configuration element. {code:xml} Override the execution defined in org.apache:apache so that the assembly is not built. We define our own source distribution in {code} IMHO it should be: {code:xml} Override the execution defined in org.apache:apache so that the assembly is not built. We define our own source distribution in {code} \n",
            "Should not be with SOAP 1.1 binding. It seems some codes related with are with SOAP 1.1 binding. It should be configurable with annotations. In my you should get a wsdl generated by axis2 runtime if you access Axis2 uses to generate the requested wsdl at the time. set binding as SOAP 1.1 regardless of the service classess binding annotation. wsgen arguments will set as SOAP 1.1. You must set extra arguments like wsdl:Xsoap1.2 If you want to use wsgen for SOAP 1.2. wsgen will complain about it. Martin Gainty told me some provider implementations are the same. Thanks a lot. I think they should not be with specific but conigurable with annotations. \n",
            "Some Data Binding tests fail if pathes with spaces are used There are some tests compiling Java code using Maven or ANT or such and some of them don't quote paths so the Java compilation fails. The following is one example for JAXBRI: {CODE} [DEBUG] Command line options: [DEBUG] Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java Bug Java 1.5 1.5 [INFO] Compiling 88 source files to Bug Java [INFO] [ERROR] COMPILATION ERROR : [INFO] [ERROR] Bug Java error: package com.foo.wsns.axis2.test01 does not exist {CODE} In this issue I will combine all places I found which need to be corrected. I think this is easier managable than creating one bug per pom.xml. \n",
            "JarFileClassLoader can't handle URLs with spaces When creating a JarFileClassLoader with URLs built from File with spaces so that the spaces are correctly handled up to the point we have an then will then transform these URLs back to File but will fail to transform them properly when they contains spaces. I think the proper way to convert an URL to a File is to call new and not simply new \n",
            "creates invalid sources I configured my like so {code} the result that the plugin is generating sources that do not compile. For example: {color:red}public class implements org.apache.axis2.databinding.ADBBean {color}{ ... parentQName factory org.apache.axiom.om.OMElement public org.apache.axiom.om.OMElement final javax.xml.namespace.QName final org.apache.axiom.om.OMFactory throws org.apache.axis2.databinding.ADBException { return } ... } {code} the lines \"that I unfortunately could not get red\" are invalid since org.apache.axis2.databinding.ADBDataSource is an abstract class and the generated class does not implement the abstract methods. Also is it trying to directly instantiate the abstract class. Or am I doing something really stupid here that is causing this \n",
            "Failing tests because of SNAPSHOT vs. release changes in pom.xml For the long please recognize comment else here are the steps with which I can reproduce the problem in my environment: 1. rmdir 2. svn co 3. mvn clean mvn install failure: Apache Axis2 Transport UDP ..................... FAILURE [ 2.273 s] 4. rmdir 5. svn up 1746119 6. mvn clean mvn install success 7. svn up 1746141 8. mvn clean mvn install failure: Apache Axis2 Transport UDP ..................... FAILURE [ 2.273 s] 9. change 10. mvn clean mvn install success The changes of step 9 depend on the version checked currently it's for for 1.7.2 it was a bit different. But as the root cause surely is the same and the tests run a long I'll focussed on 1.7.3. \n",
            "Various tests fail when Axis2 is built using a path with spaces DBCwithReduceWSDLMemoryParmsTests fails when Axis2 is build using a path with spaces: {CODE} null at at at at {CODE} After enabling logging using log4j the reason is easier to find: {CODE} DEBUG entry DEBUG entry DEBUG org.apache.axis2.wsdl.util.WSDLWrapperReloadImpl.isReloadable: Enter null DEBUG org.apache.axis2.wsdl.util.WSDLWrapperReloadImpl.getExplicitURI: Bug Java DEBUG org.apache.axis2.wsdl.util.WSDLWrapperReloadImpl.isReloadable: [javax.wsdl.WSDLException] error [WSDLException: : : java.net.URISyntaxException: Illegal character in path at index 48: Bug Java javax.wsdl.WSDLException: WSDLException: : : java.net.URISyntaxException: Illegal character in path at index 48: Bug Java at {CODE} The problem is in DescriptionTestUtils.getWSDLURL: {CODE} wsdlURL new {CODE} toURL is kown to fail in situations like these: {QUOTE} Deprecated. This method does not automatically escape characters that are illegal in URLs. It is recommended that new code convert an abstract pathname into a URL by first converting it into a via the toURI and then converting the URI into a URL via the URI.toURL method. {QUOTE} \n",
            "One hour difference after convertToDateTime I find a difference of one hour between the date coming from the client and the date returned by the axis2 system. Debugging inside the code i get to the method org.apache.axis2.databinding.utils.ConverterUtil.convertToDateTime which seems responsible of the conversion from string to date This is the snipped from the ws call The field was declared as dateTime This is the test program package test; import java.text.SimpleDateFormat; import java.util.Calendar; import java.util.Date; public class Axis2DateBug { public static void { String date Calendar cal Date d SimpleDateFormat itaDateFormat new result } } The output date has an hour gain from the original hour. I suspect this could be related to timezone but i can't understand how to overcome the problem. Is this an axis2 bug of there is something i could do to get out the correct Thanks in advance \n",
            "Version of httpclient bundled in is exposed to to the vulnerability Version of httpclient bundled in is exposed to to the vulnerability Hi The version of httpclient bundled with is susceptible to The Vulnerability says that the class in Apache Commons HttpClient before 4.2.3\" is vulnerability. What plans we have for Axis2 to address this Vulnerability. Will it be fixed in the upcoming 1.7.2 or 1.8 release or any other release. If when would that be. Reason for this query is our application uses Axis2 and and hence exposed to this vulnerability. Deepak \n",
            "Unable to generate webservice client when ‘wsdl:part’ defined with attribute ‘type’ instead of ‘element’ using wsdl2code plugin Using maven plugin for below mentioned ‘test.wsdl’ webservice axis2 client is generated successfully as expected. when wsdl:part has been changed from to webservice axis2 client code generation is failing with below compilation even though changes made to wsdl are schema compliant. Is this a issue with axis2 library to handle this Please suggest. Maven Plugin used for client code generation : Working Schema : Schema : when changed above schema for wsdl:part to use attribute ‘type’ instead of following compilation error is coming. Compilation Error: [INFO] [ERROR] cannot find symbol symbol : variable param2 location: class sample.ws.stub.TestServiceStub [ERROR] cannot find symbol symbol : variable param2 location: class sample.ws.stub.TestServiceStub [ERROR] cannot find symbol symbol : variable param2 location: class sample.ws.stub.TestServiceStub [ERROR] cannot find symbol symbol : variable param2 location: class sample.ws.stub.TestServiceStub \n",
            "does not refer to parent In does not call the parent options if it is not set it means nothing to say it is not set because it's an it can't be \n",
            "If environment variable not Maven module \"distribution\" fails in If the environment variable is not an error is thrown during the Maven build of module 'distribution'. {quote} ERROR: not found in your environment. Please set the variable in your environment to match the location of your Java installation {quote} This is thrown by the Maven job started by the Here from {code:xml} {code} This problem can be resolved by adding the following line to the plugin configuration: {code:xml} {code} This passes the Java installation path of the current pom.xml to the invoked maven pom.xml. \n",
            "Building with mvn install failes Just wanted to build one more time axis2 from the with That worked well for me in the past as I started to not run all the tests as they seldom where running and where too often the cause for a abort of the build. Now even with it failed. The reason is a missing file which is not generated if tests are skipped. p2n.wsdl\" The file p2n.wsdl is missing as it will be not generated if is selected. Why is that file not generated when I just intend to not have Josef \n",
            "option logs Unexpected value for enumeration every time Deployed Axis2 1.7.1 using generated client stubs using the option. Noticed in our logs the message regarding an Unexpected value for enumeration. The api hit and if you exclude the option the messages go away. But as far as I can tell they should not show up even with the option. I view this as related to the change in \n",
            "In the admin console the seiMethodHeaderParameter service parameter should not be modifiable In the admin some services are automatically tagged with the seiMethodHeaderParameter service parameter. This parameter takes an array as value instead of a String. Because it appears in the parameters in the changing any other parameter for the service will also send a value to this seiMethodHeaderParameter parameter. This issue is that the admin console sends all parameter values as String and therefore the seiMethodHeaderParameter now contains a String value instead of an array. This will result in an exception of the service at runtime with a ClassCastException cannot cast a String into an array. See such an exception below: {noformat} [ERROR] java.lang.String cannot be cast to java.util.ArrayList java.lang.ClassCastException: java.lang.String cannot be cast to java.util.ArrayList at at at at at at at at at at at at {noformat} Looking at the code of we see indeed that it tries to retrieve the value of the seiMethodHeaderParameter service parameter as in: {code:java} ArrayList seiMethodHeaders {code} And this generates the exception because we changed service parameter but the admin console updated also seiMethodHeaderParameter with a string value. \n",
            "AXIS2 webservice with HTTPS is not working on websphere 8.5.5.3 AXIS2 webservice with HTTPS is not working on websphere 8.5.5.3 Followed but getting following error 17:23:42:062 IST] 0000003d SystemOut O ERROR WarBasedAxisConfigurator org.apache.axis2.jaxws.dispatchers.GenericProviderDispatcher incompatible with org.apache.axis2.engine.Handler org.apache.axis2.deployment.DeploymentException: org.apache.axis2.jaxws.dispatchers.GenericProviderDispatcher incompatible with org.apache.axis2.engine.Handler at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at Caused by: java.lang.ClassCastException: org.apache.axis2.jaxws.dispatchers.GenericProviderDispatcher incompatible with org.apache.axis2.engine.Handler at ... 36 more 17:23:42:116 IST] 0000003d FfdcProvider W com.ibm.ws.ffdc.impl.FfdcProvider logIncident FFDC1003I: FFDC Incident emitted on com.ibm.ws.webcontainer.servlet.ServletInstance.init 172 17:23:42:117 IST] 0000003d ServletWrappe E com.ibm.ws.webcontainer.servlet.ServletWrapper init Uncaught.init.exception.thrown.by.servlet 17:23:42:120 IST] 0000003d webapp E com.ibm.ws.webcontainer.webapp.WebApp commonInitializationFinally SRVE0266E: Error occured while initializing servlets: {0} javax.servlet.ServletException: javax.servlet.ServletException: org.apache.axis2.deployment.DeploymentException: org.apache.axis2.jaxws.dispatchers.GenericProviderDispatcher incompatible with org.apache.axis2.engine.Handler at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at Caused by: javax.servlet.ServletException: org.apache.axis2.deployment.DeploymentException: org.apache.axis2.jaxws.dispatchers.GenericProviderDispatcher incompatible with org.apache.axis2.engine.Handler at at ... 29 more Caused by: org.apache.axis2.deployment.DeploymentException: org.apache.axis2.jaxws.dispatchers.GenericProviderDispatcher incompatible with org.apache.axis2.engine.Handler at at at at at at at ... 30 more Caused by: java.lang.ClassCastException: org.apache.axis2.jaxws.dispatchers.GenericProviderDispatcher incompatible with org.apache.axis2.engine.Handler at ... 36 more 17:23:42:125 IST] 0000003d webcontainer I com.ibm.ws.webcontainer.VirtualHostImpl addWebApplication SRVE0250I: Web Module MDM has been bound to 17:23:42:138 IST] 0000003e webapp I com.ibm.ws.webcontainer.webapp.WebGroupImpl WebGroup SRVE0169I: Loading Web Module: adminconsole redirector. 17:23:42:149 IST] 0000003e WASSessionCor I SessionContextRegistry getSessionContext SESN0176I: Will create a new session context for application key \n",
            "Invalid wrapper tag name in request when using wrapped pattern in WSDL When using wrapped pattern in sent by the generated using can have invalid letter case in the request's wrapper tag name. We have a WSDL file containing an opertaion with style. This opertaion uses \"wrapped\" as described here: The name of the operation has first capital letter. We generate client code from this using WSDL2Java or When we try to use generated code to call the we get invalid soap having wrapper tag name starting from the lowercase letter if an operation name is we get a wrapper tag named We have dived into the source code of and have found the cause of that bug. InterfaceImplementationTemplate.xsl the org.apache.axis2.wsdl.template.java in several places uses operation name instead of original operation name from WSDL \n",
            "Parse encoded characters HI I know this product has retired but I will put my question any way. May be someone out there will answer my Who When receiving XML document through a soap request which contains encoded why is xmlbeans decoding Is there any configuration parameter that can be used with xmlbeans to prevent encoded characters from being When testing it with encoded illegal characters coming through soap requests are not decoded. Can xmlbeans do the same in some BR Lulseged \n",
            "Changing a service name doesn't update its TypeTable struct I have an implementation of ServiceLifeCycle in which I'm overriding startUp and change the name of my service in some special way to make my deployment easier. I'm simply implementing some kind of mandator mechanism based on exploded services and their unique name in the file system. This worked pretty fine the last but today I encountered that Axis2 is handling structures internally in which the service name is used as some component of a key. Those structures were built before startUp was called and were not updated on a changed service name. My service generated an exception for some Axis2 tried to handle that and failed itself with a which made debugging pretty hard of course because the original exception was lost. The NPE was thrown in the following line 183 of RPCMessageReceiver and the not up to date structure was TypeTable for the that's why elementQName was null instead of a valid object. Gladly I was able to access that map in my ServiceLifeCycle implementation and update the generated keys and QNames with my new updated service name. I would have expected that if I'm able to change the service structs containing it would get updated automatically by Axis which at least for TypeTable currently isn't the case. {CODE} 175 Class[] exceptionTypes 176 for exceptionType : 177 if 178 this is an bussiness logic exception so handle it properly 179 String partQName 180 TypeTable typeTable 181 QName elementQName 182 SOAPFactory fac 183 OMElement exceptionElement 184 185 if 186 this is an exception class. so create a element by hand and add the message 187 OMElement innterExceptionElement 188 OMElement messageElement 189 {CODE} I'm currently unable to build Axis2 from src and am not sure where one would implement such a therefore can't provide but instead I'll simply post my implemantation of the change for TypeTable in my ServiceLifeCycle. In my TypeTable contained the following data for my old service name \"SoapAuth\": {CODE} complexTypeMap {CODE} My LifeCycle changes the name from \"SoapAuth\" to and therefore I simply rename all entries with the wrong service remove them and put new ones in. {CODE} private void String String { TypeTable tt schemaMap addSchemaMap new for it { entry String key QName value if { continue; } String newKeyRegExp String newValueRegExp String newKey String newValue } } {CODE} {CODE} private void { File configDir File svcDir String oldSvcName String newSvcName } {CODE} \n",
            "Some typos in comments found in code generated by wsdl2java Noticed a couple of typos in code generated by running wsdl2java. \n",
            "Maven: duplicate classes in versus I noticed two bothering things with the maven artefacts deployed to maven central: and contain duplicate tells me this: [WARNING] Found duplicate classes in [WARNING] org.apache.axis2.transport.http.ApplicationXMLFormatter [WARNING] org.apache.axis2.transport.http.HTTPConstants [WARNING] org.apache.axis2.transport.http.MultipartFormDataFormatter [WARNING] org.apache.axis2.transport.http.SOAPMessageFormatter [WARNING] org.apache.axis2.transport.http.XFormURLEncodedFormatter [WARNING] org.apache.axis2.transport.http.util.ComplexPart [WARNING] org.apache.axis2.transport.http.util.QueryStringParser [WARNING] org.apache.axis2.transport.http.util.URIEncoderDecoder [WARNING] org.apache.axis2.transport.http.util.URLTemplatingUtil sources artefact does not contain the sources for these so when trying to access the source from it does not look at sources but at sources. I think it would be good to not duplicate them and have the sources in the same artefact than the class. Thank \n",
            "Compilation failure: unmappable character for encoding I tried to build the current trunk and got the following errors: {CODE} [ERROR] Failed to execute goal on project Compilation failure: Compilation failure: [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding [ERROR] [ERROR] Java error: unmappable character for encoding {CODE} Looking at I can see that the generated file is language and OS in my case it contains German comments and is encoded in instead of {CODE} Diese Datei wurde mit der JavaTM Architecture for XML Reference v2.2.6 generiert Siehe Änderungen an dieser Datei gehen bei einer Neukompilierung des Quellschemas verloren. Generiert: 2016.03.14 um 11:00:38 AM CET package org.test.proxy.doclitwrapped; {CODE} Not sure what the result of the file is used but either don't assume its always encoded in or it looks like it helps to not generate any file header comments using the option \n",
            "Getting 'https is forbidden' exception for axis2 REST POJO with certificate When trying to access axis2 REST POJOs on a deploy using SSL transport and a certificate we get the following exception: javax.servlet.ServletException: https is forbidden at at Since this is a POJO deploy there is no axis2.xml so no place to con figure the transport as far as I can tell. Any workaround to the problem would be fine. \n",
            "calling ServiceClient.fireAndForget and receiving java.lang.NoSuchMethodError getMessageFormatter We are trying to upgrade to the newest version of wso2as. we are unable to send asynchronous messages based on the following errors received source will be at the TID: [] WARN {org.apache.axis2.transport.base.TransportMBeanSupport} Error registering a MBean with objectname ' ' for JMX management {org.apache.axis2.transport.base.TransportMBeanSupport} javax.management.InstanceAlreadyExistsException: at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at TID: [] ERROR {org.apache.axis2.rpc.receivers.RPCInOnlyMessageReceiver} {org.apache.axis2.rpc.receivers.RPCInOnlyMessageReceiver} java.lang.NoSuchMethodError: at at at at at at at at at at at at at at at at at at at at at at at at at at at at at Code Source: public void { ServiceClient serviceClient null; try { String namespace String endpointName serviceClient for endpoints not in PDA Properties if { endpointName } if { String queue \"ProxyCBR\"; String transportInfo endpointName queue transportInfo; } if { if { } if { } if { } } Add the operation to it. AxisOperation operation new Set the endpoint and action. Add the message to the SOAP message. OMFactory omFactory OMElement actionElement Grab the root element \"endpointName: \" \"action: \" Send the message. omFactory null; actionElement null; operation null; } catch { } finally{ Connection if necessary try { } catch { } } } The error in the logs is a java.lang.NoSuchMethodError. The MessageContext and MessageFormatter class files all exist in both the wso2v6 and wso2v14 version of the axis2 jar. Since the error is referencing I went ahead and reverse engineered both versions of that class file. The getMessageFormatter method does NOT exist in the wso2v14 version of the TransportUtils class. That being I do see where it exists now but it's the code from within axis2 that is failing. I cannot make the change. \n",
            "WebMethods from different classes with same name don't work There appears to be a problem with the axis2 bundled in IBM Websphere AS 8.5 believe the axis2 version used is We are using annotated services and observe the following problem: Two webservices have both a webmethod with the same name but different and also being from different Deployment endpoints are published. If used with one of the webmethods will the other will fail with the fault \"axis2ns1:Server Internal Error\". The log shows a hinting that for whatever reason method A with parameter X expects parameter Y belongs to method If the names of the webmethods are unique it works. \n",
            "CLONE totalDigits Facet of XSD type int incorrectly treated in databinding Note: I could not enter the release I'm using: 1.6.2. The following XSD fragment in a stub generated by wsdl2java public void java.lang.String totalDigitsDecimal if } else { throw new } } The string value of totalDigitsDecimal is rather than or some different method should have been called to convert totalDigits to a causing the error seen in this stacktrace snippet: Caused by: java.lang.NumberFormatException: For input string: \"1000.0\" at at at at at \n",
            "AntCodegenTask gens faulty code in 1.7.1 when using After upgrading Axis2 from 1.7.0 to 1.7.1 AntCodegenTask gens faulty code when using {code} {code} 1.7.1: {code} Buildfile: declare: [codegen] Retrieving document at [codegen] log4j:WARN No appenders could be found for logger [codegen] log4j:WARN Please initialize the log4j system properly. compile: [javac] warning: 'includeantruntime' was not defaulting to set to false for repeatable builds [javac] Compiling 9 source files to [javac] error: no suitable method found for [javac] [javac] [javac] method is not applicable [javac] mismatch; QName cannot be converted to [javac] method is not applicable [javac] mismatch; QName cannot be converted to [javac] method is not applicable [javac] mismatch; QName cannot be converted to [javac] method is not applicable [javac] mismatch; QName cannot be converted to [javac] method is not applicable [javac] mismatch; QName cannot be converted to [javac] method is not applicable [javac] mismatch; QName cannot be converted to [javac] method is not applicable [javac] mismatch; QName cannot be converted to [javac] error: cannot find symbol [javac] [javac] [javac] symbol: variable Factory [javac] location: interface OMElement [javac] error: incompatible types: OMElement cannot be converted to [javac] return [javac] [javac] error: incompatible types: cannot be converted to OMElement [javac] [javac] [javac] Note: uses unchecked or unsafe operations. [javac] Note: Recompile with for details. [javac] Note: Some messages have been simplified; recompile with to get full output [javac] 4 errors BUILD FAILED {code} 1.7.0: {code} Buildfile: declare: [codegen] Retrieving document at [codegen] log4j:WARN No appenders could be found for logger [codegen] log4j:WARN Please initialize the log4j system properly. compile: [javac] warning: 'includeantruntime' was not defaulting to set to false for repeatable builds [javac] Compiling 9 source files to [javac] Note: uses unchecked or unsafe operations. [javac] Note: Recompile with for details. dist: BUILD SUCCESSFUL {code} See in attachment. Please put the 1.7.0 and 1.7.1 axis2 jars in the respective folders. Use {code} {code} or {code} {code} in build.xml line 6 for switching between the \n",
            "NullPointerException in AxisServlet when no RequestResponseTransport Not sure how to describe this as it may be a configuration issue on my but I'm facing an error on Axis2 1.6.4 in the AxisServlet line 165 with a NullPointerException when the code checks for the presence of a RequestResponseTransport in the current MessageContext. It occurs at the end of the service call being when checking if the response has been written. By looking at the source file I suppose this is because the has not been set. This seems to be confirmed by the presence of the following DEBUG level logs: DEBUG org.apache.axis2.transport.TransportUtils Did not find RequestResponseTransport cannot set response written DEBUG org.apache.axis2.transport.TransportUtils Did not find RequestResponseTransport returning false from The complete stacktrace is as follows: ERROR org.apache.axis2.transport.http.AxisServlet java.lang.NullPointerException at at at at at at at at at at at at at at at at at at at at at at at One interesting thing is that it does not prevent my service from returning its response back to the client. However I do have a stacktrace at the container level when this occurs: GRAVE: for servlet [AxisServlet] in context with path threw exception [org.apache.axis2.AxisFault: No transport info in MessageContext] with root cause org.apache.axis2.AxisFault: No transport info in MessageContext at at at at at at at at at at at at at at at at at at at at at at at at at at at For what it's I think that replacing the test on line 165 to check for null should be enough as the following: if null RequestResponseTransport. { But I have no idea if this would trigger any side effect. \n",
            "throws NullPointerException Test Case 1 My service operation returns an Response having a header and content. In Header i have in CustomError code object that describes application errors and in content i have the payload. In my specific case i'm calling the service operation which returns an Response object having in header a custom error without details. This causes the operation to fail because the pull parser wants to instantiate the result of the getter method witch is a null java.lang.Object. Test code: {code:java} public class CustomError { private Error code; private Object detail; constructors getters and setters } .. new detail is null {code} in adb: Object value; if { value value is null } else { throw new '\" propertyName \"' in bean class '\" \"'is not } ...... ...... }else { if { is required to match this element prefix as element's prefix. QName qNamefortheType typeTable OMFactory fac QName elementName; OMElement element; if { elementName new } else { elementName new } element }else{ value is null XMLStreamReader xr {code} public static XMLStreamReader QName TypeTable boolean boolean { Class beanClass NullPointerException .............. {code} Testcase 2 return of the operation is also a complex structure but now inside the returned object at a deeper level there is a Array List of String arrays. Here another problem because the BeanUtil tries to get the package of the meaning the arrays of object which is NULL resulting to if null { QName qNamefortheType if { is null for class [Ljava.lang.Object; qNamefortheType } if { throw new qname not fond for the package: \" } {code} \n",
            "Axis2 1.7.0 Upgrade Classcast Exception I've upgraded from 1.6.3 to migrated our project to utilize the HttpClient 4.5.x and Axis2 to include copying the axis2.xml from the binary download into the project. Not able to get past this error and I've tried updates to axis2.xml and so on. java.lang.ClassCastException: org.apache.http.impl.client.InternalHttpClient cannot be cast to org.apache.http.impl.client.AbstractHttpClient at at at at at at at at at \n",
            "Fixed value causes Exception for non fixed values in ADB generated code I'm using Axis 1.7.1 and found an issue using fixed values in WDSL and the ADB Codegenerator. Basically when one fixed all attributes are treated as fixed attributes. This when setting the value on a it set be seen as null and causing an exception once used to send to server. I've attached a simplified WSDL. I've looked in the ADB Codegen and IMHO the issue seems to be in SchemaCompiler where the code says: register the fixed value if present if { } The setFixed seems to be too and maybe it can be changed into something following the e.g. \n",
            "totalDigits Facet of XSD type int incorrectly treated in databinding Note: I could not enter the release I'm using: 1.6.2. The following XSD fragment in a stub generated by wsdl2java public void java.lang.String totalDigitsDecimal if } else { throw new } } The string value of totalDigitsDecimal is rather than or some different method should have been called to convert totalDigits to a causing the error seen in this stacktrace snippet: Caused by: java.lang.NumberFormatException: For input string: \"1000.0\" at at at at at \n",
            "How to prevent xml from decoding Hi I am using AXIS2 1.6.3 and my XML is decoded when I receive it. As the character is not allowed in I have to encode it when I send a soap request to AXIS. Instead of sending I have to send encoded like: {noformat} {noformat} But somewhere in AXIS it is decoded back to How can I make sure that my XML in the soap request arrives intact to my Is there any configuration that I have to apply or this is not AXIS BR Lulseged Zerfu \n",
            "Exception in thread \"main\" org.apache.axis2.wsdl.codegen.CodeGenerationException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException I am getting following errors while using axis2 library tool WSDL2Code or WSDL2Java. Any help on this will be highly appreciated. Sanchit Retrieving document at Exception in thread \"main\" org.apache.axis2.wsdl.codegen.CodeGenerationException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException at at at Caused by: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException at at ... 2 more Caused by: java.lang.reflect.InvocationTargetException at at at at at ... 3 more Caused by: java.lang.NoSuchMethodError: at at at at at at at at at ... 8 more \n",
            "MessageContextBuilder createFaultEnvelope FaultCode with \"soapenv\" prefix and different namespace from envelope causes error I have encountered a problem in where the throwable is an AxisFault with the default SOAP namespace prefix but a than the envelope itself. For including a with a SOAP 1.2 namespace in a SOAP 1.1 envelope or a SOAP 1.1 namespace in a SOAP 1.2 envelope. The result in at least the first case is the following error: \"A Soap envelope with fault action has been received without a fault element in the soap body\" The precondition is that the fault code content has the same namespace prefix as the SOAP element being created. {code:xml} {code} The cause of the error is that the prefix within the fault code is used to declare a namespace on the \"soapenv:Fault\" element. This results in two different namespace URIs being declared with the same prefix: {code:xml} {code} During debugging you can clearly see the problem with the double prefix: {code:xml} error in function {code} real problem is in Axiom OMElement The OMElement declareNamespace method does not check if the given prefix is identical to that of the OMElement itself a different namespace In this it should probably discard the provided prefix and generate a new one. I created a simple example of this problem which creates an element with prefix \"foo\" and a given namespace URI and then declares a second namespace on this element with the same prefix and a different URI. The result is an OMElement with a {code:java} import javax.xml.stream.XMLStreamException; import org.apache.axiom.om.OMAbstractFactory; import org.apache.axiom.om.OMElement; import org.apache.axiom.om.OMFactory; public class NamespaceTest { final static String final static String final static String \"foo\"; public static void main { final OMFactory omFactory OMElement testElement try { } catch { to serialize the OMElement. Reason: \" } } } {code} This method generates the following output: {code:xml} {code} Our workaround at the moment is that we no longer use the default constant for our custom For example \"foo\": {code:xml} error in function {code} I wanted to file the issue here because the problem can occur on any OMElement. \n",
            "Module Deployer incorrectly invalidates MAR due to invalid filename recognition in ModuleDeployer When performing full build on the module fails build in the unit test: UDPTest:testSoapOverUdpWithEchoService It fails because it is unable to load the 'addressing.mar' Module. The module my is at: The failure seems to occur in org.apache.axis2.deployment.ModuleDeployer within the following code from method [side note: maybe fix the method name to {code:java} int index { moduleFile } else { moduleFile } {code} On Windows the File.separator is and a the separator is always The effect that on windows the index will always be and on unix it would correctly be 113 in my case. The result is that the module name on windows is not \"addressing.mar\" but the full file URL. Because my path also has the Axis version in the version recognition in throws an error and flags the module as faulty. I believe the correct implementation is: {code:java} int index String moduleFile; moduleFile } else { moduleFile } {code} I made the following changes: 1. Changed {{File.separator}} to 2. Changed to so that it returns \"{{addressing.mar}}\" instead of \n",
            "Axis2 not compatible with IntelliJ IDEA 15 Neither dropping into the plugins folder or choosing to install plugin from allows the to work both raise the message saying the is not compatible with IDEA \n",
            "clients cannot resolve service reponse We have developed an axis2 service some years ago but had some security issues with it. Therefore we now patched to version 1.7.0. We got 2 test one and an Both are working perfectly with the old version. But when sending requests to the axis2 service in version 1.7.0 the clients cannot resolve the though the service is answering correctly. What can be the reason of is returning null and is throwing an exception of unknown elemtn eventhough the mentioned element is absolutely correct. I watched the traffic via fiddler to find differences in the reponses of the old version client and the new version client. But the differences are minor and do not justify that the clients cannot resolve it. I never had this kind of problem with webservices except for this here is the from the old service version 1.5.1 that the clients accept correctly 200 OK Date: 11 Feb 2016 07:21:14 GMT Server: Apache Connection: chunked 2d4 0 And here the new service response that the clients do not accept. 200 OK Date: 11 Feb 2016 07:15:54 GMT Server: Apache Connection: chunked 2cb 22 0 EDIT: corrected the responses... accidentally put the requests here not the responses... \n",
            "HTTP errors 500 and 400 are not reported appropriately on WS call On any WS call made in ODE I think the same is expected anyway using the all HTTP errors are reported appropriately e.g. 404 Not [ERROR] Couldn't call external web service Error sending message [PID calling Status Transport error: 404 Error: Not Found org.apache.axis2.AxisFault: Transport error: 404 Error: Not Found at at at at at at at at at at at at at at at But only in case of 2 errors 500 Server and 400 the message is still parsed further which causes [WstxUnexpectedCharException: Unexpected character '\"'] of course as the message contains no message but HTTP error description: [ERROR] Couldn't call external web service Error sending message [PID calling Status com.ctc.wstx.exc.WstxUnexpectedCharException: Unexpected character '\"' in DOCTYPE declaration; expected a space between public and system identifiers at org.apache.axis2.AxisFault: com.ctc.wstx.exc.WstxUnexpectedCharException: Unexpected character '\"' in DOCTYPE declaration; expected a space between public and system identifiers at at at at at at at at at at at at at Caused by: org.apache.axiom.om.DeferredParsingException: com.ctc.wstx.exc.WstxUnexpectedCharException: Unexpected character '\"' in DOCTYPE declaration; expected a space between public and system identifiers at at at at at at at at at at at at at at at at at at ... 10 more Caused by: com.ctc.wstx.exc.WstxUnexpectedCharException: Unexpected character '\"' in DOCTYPE declaration; expected a space between public and system identifiers at at at at at at at at ... 26 more This behavior prevents user to proper analyze the cause of the problem with the WS it requires time and efforts to understand that the original problem is in e.g. commonly used error 500 means the WS server has some teporarily problems. I've found that the cause why Axis2 is doing this is the code in the org.apache.axis2.transport.http.HTTPSender.handleResponse function the 1.6.4 or corresponding HTTPSender implementations in the which derives the logic if || statusCode allowing the message to be parsed non blocking API transport flag is instead of throwing exception anyway. Is there some real reason why exception isn't just thrown anyway including errors 500 and \n",
            "NullPointerException in DeploymentFileData.getName on failed tests I tried to build 1.7.1 from src using mvn and get the following NullPointerException: {CODE} Running org.apache.axis2.transport.http.SimpleHTTPServerTest Tests run: Failures: Errors: Skipped: Time elapsed: 0.318 sec Time elapsed: 0.317 sec java.lang.NullPointerException: null at at at at at at at at at at at at at at at at at at at at at {CODE} ModuleDeployer.deoloyFromUrl is failing for some reason and instead of logging a proper error message it tries to access which throws a NPE. {CODE} public String { return No need to check for null due to constructor check } {CODE} Please recognize the which makes false claims about a {CODE} public { this.file file; } {CODE} So from my point of view getName or the CTR needs to be made null so the caller can easier log error messages when things fail for any like in my test run. Currently the NPE is hiding the root cause for the failing test. The code is still the same in but I don't know if the test fails there as because it fails in my case for other reasons already before that test. \n",
            "java.lang.NoClassDefFoundError AFTER successful build Ubuntu 14.04: {CODE} [INFO] [INFO] BUILD SUCCESS [INFO] [INFO] Total time: 29:07.033s [INFO] Finished at: Tue Jun 28 08:42:11 CEST 2016 [INFO] Final Memory: [INFO] 08:42:11.773:INFO:oejsl.ELContextCleaner:javax.el.BeanELResolver purged 08:42:11.774:INFO:oejsh.ContextHandler:stopped {CODE} Windows succeeds as but there's an additional exception: {CODE} [INFO] javax.el.BeanELResolver purged [INFO] stopped [WARNING] FAILED java.lang.NoClassDefFoundError: at at at at at at at at at Caused by: java.lang.ClassNotFoundException: at at at at ... 9 more [WARNING] FAILED java.lang.NoClassDefFoundError: java.lang.NoClassDefFoundError: at at at at at at at at at Caused by: java.lang.ClassNotFoundException: at at at at ... 9 more Exception in thread \"ShutdownMonitor\" java.lang.NoClassDefFoundError: at at at at at at at at at Caused by: java.lang.ClassNotFoundException: at at at at ... 9 more {CODE} The problem is not present in former like 1.7.3. \n",
            "always touches the id Currently it is not possibel to get a ServiceGroupContext from the ConfigurationContext without forcing a touch to the 'lastTouchedTime'. This prevents us from performing our own checks against the lastTouchedTime because it is always set to the System time Effect\" by observing the we change the I would propose a second API method which would allow retrieval of the ServiceGroupContext by id without touching the lastTouchedTime. Here my proposed code change: {code:java} Returns a ServiceGroupContext object associated with the specified ID from the internal table. If the returned ServiceGroupContext} will be touched with the current system time. serviceGroupCtxId The ID string associated with the ServiceGroupContext object The ServiceGroupContext or null} if not found public ServiceGroupContext { return } Returns a ServiceGroupContext object associated with the specified ID from the internal table. serviceGroupCtxId The ID string associated with the ServiceGroupContext object touchServiceGroupContext if true} the retrieved ServiceGroupContext} will be touched on retrieval; false}. the ServiceGroupContext or null} if not found public ServiceGroupContext boolean { if { Hashtables require pairs return null; } ServiceGroupContext serviceGroupContext null; if { serviceGroupContext if null { } else { serviceGroupContext if null { } } } return serviceGroupContext; } {code} Side note: the javadoc of getServiceGroupContextIDs is incorrect. The method returns a String[] array of ids and not a hashmap of ServiceGroupContexts. {code:java} Gets all service groups in the system. Returns hashmap of ServiceGroupContexts. public String[] { {code} \n",
            "not functioning after Ant build and Deployment I built a top down web service in Eclipse using Axis2 and XmlBeans. When I test the service in Eclipse it works but when I do an Ant build and deploy the service in Tomcat on a remote server I have problems. Basically there is a point where I create a new XmlObject based on an autogenerated schema. I then use to change it to the correct schema type. Then I cast it to the correct object type which is extending XmlObject. This works in but after full deployment I get a ClassCastException because doesn't change the XmlObject to the correct Object type. \n",
            "wsdl2java: nillable \"true\" is ignored I tried to create a java client with wsdl2java. With version 1.7.0 and older ones everything is fine. But since version 1.7.1 the attribute is ignored. Here is a small example wsdl: {code:xml} first {code} For creating the client I use the option. The problem appears in the Factory's parse method for the defined types. For example for TradePrice.java from the given wsdl above: Genereated code from version 1.7.0 from Factory parse if { java.lang.String content } else { throw away text nodes if any. } {code} Genereated code from version 1.7.1 from Factory parse if || { throw new \"The element: \" \"price\" \" cannot be } java.lang.String content {code} So as you can in 1.7.1 the {{price}} element is handled as a non nillable value although it is nillable. So if the server sends a repsonse with price null the client will throw an exception although everything is fine... \n",
            "Axis2 Client Connection Issue I have a 1.4.1 component in middleware which consumes a web service hosted in another application. Am facing some issues in it. Please find the code snippet below ConfigurationContext configContxt; MultiThreadedHttpConnectionManager connxMgr new HttpConnectionManagerParams params connxMgr HttpClient client new Please help to clarify the below 1. Whenever a new request comes a new connection is getting created. This can be confirmed by doing 'netstat When we were using axis2 1.3v client earlier there was no new connection please clarify why this is creating a new connection while using axis2 To prevent I have set property in ConfigurationContext to TRUE. So this will reuse the existing connection to the server. 2. I have set the setDefaultMaxConnectionsPerHost and setMaxTotalConnections as 50. When I do the load test from SoapUI by triggering 50 only 3 connections were created. Later I increased to 200 but still the connections count didnt exceed 3. Am not sure why it is not able to serve with only one connection reuse property is and also why the number of connections did not gradually increase with the number of requests connx for 50 requests and again same 3 connx for 200 How will the reuse propery behave 3. How many transactions can be done per connection concurrently while using \" property\" in the 4. Another Issue is: I have set the closeIdleConnections with the timeout of 30 secs. Even this is not working. The unused connections are closed only after 5 mins. I just want to know If there could be some property set at server side which overriding this 30 seconds which am setting at client side As per your previous reply axis 1.4.1 is not supported anymore. So we upgraded to axis 1.7.1. With reference to the below it says that reusing Http client is handled internally and need not be explicitly handled in the user program. [\" in earlier versions of Axis2 the configuration property was necessary to enable this but as of 1.5 this is no longer necessary\"] But when we triggered 100 we found that 100 connections were created and as mentioned in the the connections were not reused. THE TICKET FOR Ver 1.7.2 As per your previous reply axis 1.4.1 is not supported anymore. So we upgraded to axis 1.7.1. With reference to the below it says that reusing Http client is handled internally and need not be explicitly handled in the user program. [\" in earlier versions of Axis2 the configuration property was necessary to enable this but as of 1.5 this is no longer necessary\"] But when we triggered 100 we found that 100 connections were created and as mentioned in the the connections were not reused. Attached the screenshot for your reference \n",
            "Maven Build fails: \"reference to Parameter is ambiguous\" 1. Download and extract 2. cd 3. mvn package [INFO] [INFO] BUILD FAILURE [INFO] [INFO] Total time: 2.951 s [INFO] Finished at: [INFO] Final Memory: [INFO] [ERROR] Failed to execute goal on project Compilation failure: Compilation failure: [ERROR] error: reference to Parameter is ambiguous [ERROR] [ERROR] error: reference to Parameter is ambiguous [ERROR] [ERROR] error: reference to Parameter is ambiguous \n",
            "Unable to retrieve Axis2 MEX artifact from central Maven repository I'm encountering a \"Class not found\" exception involving the class. I added the Apache Axis2 MEX 1.6.3 dependency to my pom.xml file and the Eclipse Maven indicates that it cannot locate the dependency: The Maven indicates \"Missing artifact org.apache.axis2:mex:jar:1.6.3\". None of the other Axis2 dependencies in my pom.xml have this issue. These are the other Axis2 dependencies in my pom.xml file: \n",
            "Maven Build Module: kernel generates modifies file under should build in output directory Maven Build for In the Maven Module at in at least the module as test and run against the directory instead of the directory. In the interest of Maven \"compliance\" the build process should not touch or otherwise \"dirty\" files. Examples: 1. The creates temporary generates and removes these temporary directories directly within the source directory. 2. The utility method 'readWSDLFromFile' in XMLSchemaTest creates a File reference to a file in and performs the following: This updates the input on my windows build it changes the from Unix to Windows. The current Maven POMs already take care of copying the directory to so all of the required input files and are available there. the POM ANT \"dir\" properties and the JUnit tests just need to be updated to use these instead of the originals. \n",
            "Handling of Http 202 in Axis 2 Rest. In HTTP Sender if a 202 is the code ignores any response body. The particular web service I am accessing I post a JSON body and the service returns a JSON response that contains an ID so that I can check back later for the result of my request. It seems to me that and should be handled the same way. Note : 10.2.3 202 Accepted The request has been accepted for but the processing has not been completed. The request might or might not eventually be acted as it might be disallowed when processing actually takes place. There is no facility for a status code from an asynchronous operation such as this. The 202 response is intentionally Its purpose is to allow a server to accept a request for some other process a process that is only run once per without requiring that the user agent's connection to the server persist until the process is completed. The entity returned with this response SHOULD include an indication of the request's current status and either a pointer to a status monitor or some estimate of when the user can expect the request to be fulfilled. \n",
            "EnableChildFirstClassLoading not working on Windows I have a web service based on Axis2 1.6.3 currently and Axis2 provides In my service I want to use HttpCore 4.4.5 and HttpClient 4.5.2 and both core packages provide the class but some classes new in HttpCore 4.4.5 need a newer version of that class than HttpCore 4.0 can provide. This leads to exceptions like the following: {CODE} Caused by: java.lang.NoSuchFieldError: INSTANCE at at at at at at at at at at at at at {CODE} {CODE} Caused by: java.lang.NoClassDefFoundError: Could not initialize class org.apache.http.impl.conn.ManagedHttpClientConnectionFactory at at at at at at {CODE} The problem is that when my service is about to be Axis2 used the BasicLineFormatter on its own loaded it and DeploymentClassLoader.loadClass finds that class in its own cache afterwards. This way the newer version of that class bundled with my service will never be used by default. Because the class is in the using \"EnableChildFirstClassLoading\" doesn't change a thing here because the cache is always queried first. I could work around that problem by changing the class loader of my service in ServiceLifeCycle.startUp: The new class loader is just another instance of DeploymentClassLoader which I put all the URLs needed for Jars and classes and such use \"EnableChildFirstClassLoading\" by default and provide the already available class loader as the new parent: {CODE} class WsAxis2SvcCl extends DeploymentClassLoader [...] private static boolean { String paramValue paramValue if { return false; } return true; } [...] protected ClassLoader { } [...] static void { if { return; } ClassLoader origCl Path svcDir clUrls ClassLoader newCl new } {CODE} This way the classes and jars of my service are always considered first and only things not found in there are forwarded to the default Axis2 class loader used before. In the my classes using HttpCore 4.4.5 get their BasicLineFormatter and Axis2 keeps using its own. The \"trick\" is that DeploymentClassLoader.findLoadedClass only searches the current no parent or and by providing a new instance I get a clean start for loading the service classes without interfering with the former already present Axis2 loader. As I understand such problems can't be addressed without another classloader like so I woudl like to suggest exactly such an approach like I implemented now to be added. As I did one could configure the use of that class loader on a per service level and would therefore don't introduce any problems with backwards compatibility. If I could provide more of my implementation. Or is there any other approach I have missed to deal with same classes in incompatible versions like in my \n",
            "Can import axis2 1.7 eclipse plugins into eclipse mars 4.5 I drop axis 2 eclipse content inside eclipse installation dropins but they are not loaded. Reviewing eclipse errors log I can find: Error 1: Message: Invalid input Stack Trace: java.io.IOException: Unable to resolve at at at at at at ..... Error 2: Message: Unable to resolve Stack Trace: java.io.IOException: Unable to resolve at at at at at ... \n",
            "NPE at at I tried to re get response and it throw thís exception: {code} 200 11:32:16.244|DEBUG| 200 11:32:16.245|DEBUG| \"Server: 11:32:16.246|DEBUG| 11:32:16.246|DEBUG| 11:32:16.246|DEBUG| \"Date: 19 May 2016 04:32:21 11:32:16.246|DEBUG| 04:32:36 11:32:16.246|DEBUG| 11:32:16.254|DEBUG| org.apache.commons.httpclient.HttpMethodBase|Cookie accepted: 11:32:16.258|DEBUG| 11:32:16.258|DEBUG| org.apache.commons.httpclient.HttpMethodBase|Resorting to protocol version default close connection policy 11:32:16.258|DEBUG| org.apache.commons.httpclient.HttpMethodBase|Should NOT close using 11:32:16.259|DEBUG| org.apache.commons.httpclient.HttpConnection|Releasing connection back to connection manager. 11:32:16.259|DEBUG|mons.httpclient.MultiThreadedHttpConnectionManager|Freeing 11:32:16.259|DEBUG|ache.commons.httpclient.util.IdleConnectionHandler|Adding connection at: 1463632336259 11:32:16.259|DEBUG|mons.httpclient.MultiThreadedHttpConnectionManager|Notifying there are no waiting threads 11:32:16.260|ERROR| contract info] got Connection Exception. java.lang.NullPointerException at at at at at at at at at at at at {code} \n",
            "Module engaged at the service level is used globally Maybe I misunderstood how Axis2 was meant to but I have addressing and rampart present in my modules they are made available in the AxisConfiguration then addressing is globally engaged because it is present in the axis2.xml file. Later I engage rampart manually on a specific service calling on the AxisService and then the rampart handlers are executed for every even not those of the aforementioned service. I looked at the code and goes down to call on all the operations of the gather all the phases from the global AxisConfiguration object and then add the Handler to the needed phases in this within the method being in an modifying the Phase without cloning it first will impact also the global AxisConfiguration that have references to them as well as all the other PhaseHolder for all the operations that have references to them… Is that meant to I don't think so but I may be mistaken Thank you \n",
            "client recieves empty SOAP response message when used as a client of gsoap server some responses from server are considered by axis2 as empty. tcpdump shoes that there is actually a response. This problem seems to occurs when sending lot of SOAP requests in a short amount of time. This problem doesn't occurs in version I roll back to traces are as follows : grep DEBUG httpclient.wire.header 200 DEBUG httpclient.wire.header \"Server: DEBUG httpclient.wire.header DEBUG httpclient.wire.header DEBUG httpclient.wire.header \"Connection: DEBUG httpclient.wire.header ERROR obao.ssm.communication.protocol.ProtocolOutPollerV114 Connection error for suppressEquipments at endpoint : null \n",
            "Upgrading from axis2 1.4 to 1.6.4 Hi All We are in the process of upgrading Axis2 from1.4 to 1.6.4. Imported all 1.6.4 library and migrated successfully in design time. When i do testing i am getting below error. We are using HTTPClient 3.1 with axis2 1.6.4. Seems that some incompatible issue with common HTTP client. Please let us know if any resolution. org.apache.commons.httpclient.HttpState incompatible with org.apache.commons.httpclient.HttpState Thanks. \n",
            "Axis2 xsd2java namespace prefix added to inherited attributes We have recently migrated from Axis2 1.6.2 to 1.7.3. We have multiple XSDs that extend elements from a common parent XSD. After the we now have different namespace prefixes on our attributes. For example: 1.6.2 1.7.3 According to the namespace spec \"Default namespace declarations do not apply directly to attribute names; the interpretation of unprefixed attributes is determined by the element on which they appear.\" In the generated Java for example the parse methods now have fully qualified attribute names: {code:java} if } ... if } {code} Previously I the given attribute namespace was null. The serialized XML generated with this approach does not validate in AltovaXML editor. attribute 'core:name' is not permitted in the element I will attach an example with two XSDs and the Axis 1.7.3 generated \n",
            "Generated code is not complete if ns2p is specfied and JAXRBI databinding is used When I generate the code using JAXBRI I am able to get the complete code without any warning. But when I try to generate the code for the same WSDL and with same JAXBRI but with ns2p option it shows the following warning message and the code is also not complete. Not complete in the the binding classes does not contain setter methods for all elements. I've used the following option. wsdl2java.bat jaxbri test.wsdl The warning message I got [WARN] Cannot resolve the name 'dsig:Signature' to 'element de claration' component. [WARN] Cannot resolve the name 'dsig:Signature' to 'element de claration' component. [WARN] Cannot resolve the name 'dsig:Signature' to 'element de claration' component. \n",
            "Support based mustUnderstand header processing Axis2 and JAXWS need to add support for SOAP based validation of mustUnderstand headers. Only headers which are targeted to a that the node supports should be considered in mustUnderstand checks. \n",
            "specified MessageReceiver from services.xml is ignored given the following MyService axis2 service engine COMPLETELY IGNORES the messageReceiver for this service service code: package samples.quickstart.service.axiom; public class MyService { public String throws Exception { return \"Hello I am Axis2 version service \" My version is \" } } client code: public class AXIOMClient { private static EndpointReference targetEPR new public static OMElement { { OMFactory fac OMNamespace omNs the getVersion Method OMElement method return method; } public static void { try { OMElement getPricePayload Options options new ServiceClient sender new OMElement result String response value: \" } catch { encountered } } consistenly produces the ERROR java samples.quickstart.clients.AXIOMClient Exception encountered Receiver not found for AxisOperation: getVersion org.apache.axis2.AxisFault: Message Receiver not found for AxisOperation: getVersion at at at at at at at at } why does the Axis2 engine completely ignore the MessageReceiver specified for \n",
            "Improve Performance of RuntimeServiceDescription code Background: The ServiceDescription contains a map of RuntimeServiceDescription objects. These objects are created and bound to the ServiceDescription on \"first touch\". For the RuntimeServiceDescription objects are information used for jaxws marshalling and resource injection. Assessment: Based on profiling data from David the storage and access of these objects is going to slightly change to be more performant. I am working on a fix now. \n",
            "Problem accessing policy via external URI Storing policy information in a separate file and referencing it from within WSDL via attribute does not work. When I embed the policy details within the WSDL and then reference the policy internally running wsdl2code produces desired results. However when referencing the same policy information via an external URI the policy is ignored while wsdl2code prints out an error \"ERROR: Ignoring policy null\". Having traced this flow I can see that the policy is retrieved from the external however when the call is made to the latter raises an UnsupportedOperationException which causes the \"Ignoring policy\" message to be printed. \n",
            "LogicalMessageContextTests.testGetPayloadAsJAXB fails Please see : dims \n",
            "does not exist or no valid version could be found if I download to set cd mvn install [DEBUG] Artifact not found using stub model: Unable to determine the latest ve rsion [DEBUG] Using defaults for missing POM gin:pom:LATEST [DEBUG] using locally installed snapshot [DEBUG] Artifact not found using stub model: Unable to determine the release v ersion [DEBUG] Using defaults for missing POM gin:pom:RELEASE [INFO] [ERROR] BUILD ERROR [INFO] [INFO] The plugin does not exist or no valid version could be found [INFO] [DEBUG] Trace org.apache.maven.lifecycle.LifecycleExecutionException: The plugin 'org.apache.m does not exist or no valid version could be fo und at relevant contents of pom.xml I dont see a version tag for Is there a Thanks \n",
            "Cannot use JAXBRI data binding with the version service WSDL If you do jaxbri you get [ERROR] A with the same name \"sample.axisversion.Exception\" is already in use. Use a class customization to resolve this conflict. \n",
            "Bug 3230 Reopen. Axis2 deployment fails when deploying spring classes as services Spring classes are not able to get loaded when loaded up thru services.xml file. setting the ServiceClass parameter takes the error the proxy'd class doesnt get hooked into axis so that does not solve the problem.... [WebContainer : 0] INFO org.apache.axis2.deployment.ModuleDeployer:72 Deploying module: [WebContainer : 0] INFO org.apache.axis2.deployment.ModuleDeployer:72 Deploying module: [WebContainer : 0] INFO org.apache.axis2.deployment.ModuleDeployer:72 Deploying module: [WebContainer : 0] INFO org.apache.axis2.scripting.ScriptModule:68 script module activated [WebContainer : 0] ERROR org.apache.axis2.deployment.ServiceDeployer:91 The EdgeService.aar which is not caused The following error occurred during schema generation: Unable to load bytecode for class org.apache.axis2.deployment.DeploymentException: The following error occurred during schema generation: Unable to load bytecode for class at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at Caused by: org.apache.axis2.deployment.DeploymentException: The following error occurred during schema generation: Unable to load bytecode for class at at at ... 110 more Caused by: org.apache.axis2.deployment.DeploymentException: The following error occurred during schema generation: Unable to load bytecode for class at at ... 112 more Caused by: org.apache.axis2.deployment.DeploymentException: The following error occurred during schema generation: Unable to load bytecode for class at ... 113 more Caused by: java.io.IOException: Unable to load bytecode for class at at at at at at at ... 113 more [WebContainer : 0] INFO org.apache.axis2.deployment.DeploymentEngine:574 org.apache.axis2.deployment.DeploymentException: The following error occurred during schema generation: Unable to load bytecode for class \n",
            "Axis2 server responds with Http 200 instead of 202 for the request of a dual channel invocation In the dual channel service Axis2 server is expected to respond to the request message with http 202. This was working correctly in server responds with 200 OK for the request in the latest nightly builds. Steps to reproduce: 1. Deploy a service in Axis2 server 2. Write an dual channel async client 3. Invoke the service and monitor the message flow using tcpmon When you send the you will get http 200 as the response code. \n",
            "quickstartjibx sample's method doesn't work HashMap should be The quickstartjibx sample's method does not cause a stock's price to be updated calls continue to return presumably because the HashMap is not and each invocation is happening on a new instance of the class. Making the HashMap as it is in some of the other corrects the problem. \n",
            "Encoded use is not supported incorrect when in wsdl contents of Scott.wsdl wsdl2Java Scott.wsdl Exception in thread \"main\" org.apache.axis2.wsdl.codegen.CodeGenerationException : Error parsing WSDL at at at Caused by: org.apache.axis2.AxisFault: Encoded use is not supported org.apache.axis2.description.WSDL11ToAxisServiceBuilder.java contents: private List { List partsList null; ExtensibilityElement extElement; for iter { extElement SOAP 1.1 body element if instanceof { SOAPBody soapBody extElement; if { throw new use is not } partsList } else if instanceof { SOAP12Body soapBody extElement; if { throw new use is not sense } Take a look at the line with the comment with the question marks Martin \n",
            "Codegen with unwrapping argument fails I have a service with a boolean input param and an int return value. I always generate the client code with This produces a info message that one file cannot be overwritten. This file is the interface for the service implemented in the service. The problem that the class is not a interface and so the compiling of the service fails. When I generate the service without param everything works fine. I have attached the wsdl below. Regards Michael \n",
            "NPE bug in ServerWorker.handlerException In some scenarios receives null as second argument. This causes a NPE \n",
            "Wrong SOAP MustUnderstand Handling when using Handler Implemented a simple service provider \"DemoService\" and a simple SOAP handler \"DemoHandler\". DemoHandler was configured on DemoService's handlerChain. The DemoHandler implementationcontains a method specifying that it handles the \"myheader\" header in the namespace. When sending the attached SOAP request everything works fine. The handler is called and the server responds with an appropriate SOAP response. The request is almost the same with the only difference that the mustUnderstand attribute for the \"myheader\" header has been set to \"1\". When sending this the server responds with a SOAP fault generated Axis runtime: \"Must Understand check failed soap : myheader\" This behaviour is It does not conform to the specification v2.0. Chapter 10.2.1 mustUnderstand and chapter 10.1.1.3 mandate that all headers specified by the getHeaders method of a SOAPHandler must be considererd as \"understood\" by the runtime. \n",
            "Restore FaultyWebServiceTests Need to restore FaultyWebServiceTests. The failure log: junit.framework.AssertionFailedError: javax.xml.ws.soap.SOAPFaultException: More than one operation found. Overloaded WSDL operations are not supported. WSDL Operation name: faultyWebService In looking at the there is definitely only one operation named faultyWebService. The stack indicates we are running in BARE mode. I believe that makes the problem with this testcase directly related to: \n",
            "Axis2 maven plugin does not allow to generate sources for remote WSDL file I've seen recently an email from somebody asking if it's possible to use remote WSDL file using axis2 maven plugin and the answer was 'yes' I have the same I asked on users mailing group and was suggested to report an issue. In pom.xml the relevant section is: When I try to run mvn I get the following: java.io.FileNotFoundException: directory or volume label syntax is so it seems that instead of going to remote it is still trying to find a local file. \n",
            "java.lang.NoClassDefFoundError while running java2wsdl or wsdl2java Having installed my Axis under the as well as configuring its sys variable to the corresponding I am however unable to run properly the Java2WSDL WSDL2Java classes. Example for wsdl2java.bat: Using Using Exception in thread \"main\" java.lang.NoClassDefFoundError: I tried to \"debug\" the .bat and found that the following command does not end working as expected: FOR in DO set if I add just after it the echo command to display the value of the computed Axis2 path i.e. echo I get: 3.jar Indeed only the last 14 .jars are taken into account and added to the classpath: It seems to me like the previous ones are added to the but as the variable seems not to be greater that something like 633 char. the content is rolled up... \n",
            "name parameter should default to the name of the class The name parameter should default to the simple name of the class or interface which it describes to chapter 4 of the JSR 181 Currently the value defaults to which lead to a hard to find bug. I just completed tested on a simple fix and unit test change. \n",
            "Need a JAXWS specific Deployer Consensus on that we need a specific deployer for JAXWS with better control as compared to the Pojo Deployer. dims \n",
            "Redundant checks into WarBasedAxisConfigurator in two places the there is the following set of statements var null; something else if { do something } var can only be null here. \n",
            "overrides default for optional primitive element ADB codegen always return for unseen optional primitive regardless of what its default was initialized to. \n",
            "WSDL2Java generated sources Here is the compile error received: compile.src: [javac] Compiling 215 source files to [javac] cannot find symbol [javac] symbol : method [javac] location: interface com.company.test.testservice.TestOperationRequestDocument [javac] return [javac] [javac] Note: Some input files use or override a deprecated API. [javac] Note: Recompile with for details. [javac] Note: uses unchecked or unsafe operations. [javac] Note: Recompile with for details. [javac] 1 error \n",
            "The MessageId generator creates duplicates ERROR Error processing POST request [java] org.apache.axis2.AxisFault: The Callback for MessageID urn:uuid:5BE9C8C4B19BCC55A31203946194773 was not found [java] at [java] at [java] at [java] at [java] at [java] at [java] at [java] at The bug is probably in UUIDGenerator.getUUID \n",
            "Performance Improvement to JAXB Unmarshalling History: According to the Sun JAXB Unmarshallers for a specific JAXBContext are not thread but they can be pooled and reused. It is expensive to create a JAXB Unmarshaller. Also JAXB Unmarshaller objects can have a big footprint. Solution: The JAXBUtils code is the provider of JAXB Unmarshallers for the engine. This code will be improved to support a pooled list of Unmarshallers for each JAXBContext. The pool will be pruned if it gets too big. The pool is backed by a ConcurrentHashMap. is a new class in Java and the JAXWS module requires Java Kudos to David Strite of IBM for suggesting this fix and providing me a patch private I just completed testing. I will be committing this change shortly. \n",
            "Wsdl2java.bat does nothing The wsdl2java.bat of the axis2 nightly build of the 27 of february does absolutely nothing. The two echos displays environment variables as and the dos prompt comes out with no delay. Wsdl2java.bat with no args does not display options usage help: Using Software Using and that's all. When i switch from this axis2 nightly build to the axis2 1.3 release the same install things operates as usual. Since this my first jira issue and given the fact that i'm very new to i hope i didn't make any and if i apologize for this. Regards Florent \n",
            "NPE in HttpCoreNIOSender In case of timeout a NPE occurs because the environment doesn't create the while the handler tries to get it. \n",
            "MTOM doesnt work over JMS Performing MTOM optimization over the JMS transport does not work correctly. There are three main issues involved here: For the JMS transport a call to will always return false. This is due to the fact unlike the HTTP the JMS transport never checks whether enableMTOM has been set in config or programmatically. This means that a JMS message containing binary content will never be optimized. JMSByteMessage always sent as soap1.1 format The OMOutputFormat class defaults its soap version to soap1.1. The HTTP transport sets this according to the soap namespace used in the soap envolope. JMS however does not do this and the byte message is always sent as soap1.1 contentType of JMS message is never set The contentType of a JMS message is never set. This passes unnoticed on the server when attachments are not involved. However when a message contains attachments the expected contentType of is never present and the message is perceived as a non message which is incorrect. I have attached a working solution for the above issue so can submit if agreed Cathal Callaghan \n",
            "ignores packageName in execution group gives [INFO] [ERROR] BUILD ERROR [INFO] [INFO] One or more required plugin parameters are for [0] inside the definition for plugin: the following: ... on the command specify: \n",
            "Error extracting fault from SOAP envelope when body is encrypted When the Body of the SOAP message is AddressingInFaultHandler can't extract the SOAP fault from the body as it is still encrypted. Addressing phase is before the Security phase in the phase order. \n",
            "Schema restrictions result in a no args RuntimeException being thrown. The default ModifiedADBBeanTemplate.xsl throws a no args RuntimeException for all restrictions found in the given schema. It would be useful if the RuntimeException could include some sort of message such as throw new schema validation for property and value [\" param This would enable client code to parse the eception to fiure out there was a schema validation error. it would also be really usefull to be able to turn the client stub validation off completely. \n",
            "Classloader problem Service isolation I have two versions of the same library in and inside my AAR in the lib folder. Inside my service I'm trying to load the version from the AAR file using the following code: ClassLoader cl Class testClass package.Test testObj The classloader always picks the version from \n",
            "is ignored for dateTime values I tried to search for similar bug but couldn't find one. I have a java web service and I use Axis2 1.3 as the web service implementation. One of my methods gets a Java Date object and in the wsdl that is created by Axis2 this parameter gets which is good to because I want the user to be able not to supply this field. The problem is that if the client doesn't supply this field I get this error: string can not be less than 19 When I supply the startDate it works so not supplying the startDate parameter is clearly the case. P.S The exception text is misspelled \"charactors\" \n",
            "DispatchPhase does not consider MEPs defined in WSDL2Constants The DispatchPhase class consults the MEP for an incoming request from the AxisOperation to determine if an ACK needs to be sent. In doing in only compares this MEP against strings defined in and This means an incoming request requiring an ACK could result in an ACK NOT being sent if the MEP on the AxisOperation was defined using WSDL2Constants. \n",
            "Nullpointer exception when BuilderUtils can not resolve a Builder My client side stub communicates with an other system which returns an 500. There it throws a null pointer exception. The issue is in line 155 of the TransportUtils class. There the getClass method is invoked on a NULL when no Builder can be resolved in line 153. \n",
            "Ability to plugin a new Axiom LifecycleManager via axis2.xml Axiom has a new LifecycleManager for dealing with we should allow users to override the implementation via an entry in axis2.xml \n",
            "Fix commented out tests \n",
            "Possible NPE in XMLUtils Possible NPE in XMLUtils.initSAXFactory \n",
            "Within Eclipse WTP Axis2 Skeleton code is generated to directory even when a different project Source Folder as exists. Created an Eclipse Dynamic Web setting source directory from it's default of src to to place TestNG code under Created xsd and wsdl files and ran through standard Web service \"Top Down\" creation process [as per: Code Gen creates files in which is now not the project Source Folder so no class files are generated within the folder. During server startup we get ClassNotFound exceptions as no classes have been built. Manually moving the generated files from src to resolves the ClassNotFound issue but such manual intervention was not required with \n",
            "Following wsdl's are not working with wsdl2java tool and wsdl2c tool I'm checking wsdl's in axis2c source.I found some wsdl's which are not working with wsdl2java and wsdl2c tools.I'm attaching those wsdl's with the jira and please check wsdl2java tool with attached wsdl's. \n",
            "Support for XmlJavaTypeAdapter I was porting a cxf sample when i realized that are not picked up and used. Please see enclosed zip for a m2 project that can create standalone war that can be dropped into say tomcat. dims \n",
            "Non Blocking Dual Channel fails if MsgContext already had an replyTo Epr set to anonymous OutInAxisOperation line 265 1.3 release if null || { EndpointReference replyToFromTransport mc if { } else { } } } line should be as follows | \n",
            "WSDL2C bug with list of items endless loop I have the following in my wsdl: When the code is generated using \"org.apache.axis2.wsdl.WSDL2C aewebservicesaxis70.wsdl aewebservicesaxis70 adb I get the following for \"extraValues\" in the deserialize method. I had to add the call shown below to prevent an endless loop. I encounter this when using a REST style where a text element is inserted into the tree. for { { I had to add this line to prevent an endless loop continue; } \n",
            "is out of date Looks like the Sun copyright is no longer needed. I posted suggest new text for here: If when someone responds on I will update this jira. \n",
            "WSDL2java generates wrong code and wsdl in resource directory Using complex types with restrictions and enumerations or causes WSDL2java to generate wrong code and to produce a wrong WSDL in the resource directors. I used the following wsdl2java command: wsdl2java.sh 2.0 caservice The problem also occurs if I use WSDL 1.1 . The generated code shows that every other enumeration is missing. The same is true for the minInclusive maxInclusive restriction type. Here a code snippet of the complex types I use: ... ... WSDL2java generates to following code for ... public class KeyType implements org.apache.axis2.databinding.ADBBean { public static final javax.xml.namespace.QName new private static java.util.HashMap new public static final java.lang.String public static final java.lang.String public static final java.lang.String public static final KeyType value1 new public static final KeyType value2 new public static final KeyType value3 new field for KeyType protected java.lang.String localKeyType; Constructor protected boolean { localKeyType value; if { } } ... Also the class has a protected constructor no unprotected default constructor. The code snippet for the ModeType ... public void { if { this.localModeType param; } else { throw new } if { this.localModeType param; } else { throw new } } .... As you can see the second value is it's just an empty string. When I use 2.0 wsdl2java create the follwoing wsdl in the resource directory ... ... Same as for Java code the second every value is missing. Any Best Werner \n",
            "Axis 2 SAAJ java XPath expressions Any attemp to use axis 2 with XPath expressions from javax.xml.xpath leads to an error like this: java.lang.ClassCastException: org.apache.axiom.om.impl.dom.DocumentImpl at at at at at at at at at at at at Sample you can try: message soapBody path xp If you think empty body may cause fill it: nothing will change. Of use not usual SOAPElement: all the same. No need to XPath works fine with java's native DOM. Thank you. \n",
            "NullpointerException in org.apache.axis2.deployment.util.Utils.loadHandler method A Nullpointer Exception is thrown when initializing org.apache.axis2.client.ServiceClient. The stack trace is given below org.apache.axis2.deployment.DeploymentException at at at at at at at at at at at at at at at Caused by: java.lang.NullPointerException at ... 14 more From the source code debugging I figured out that the exception is happening on the following line in the org.apache.axis2.deployment.util.Utils.loadHandler method... String name \" name \" is now { remove the entry for \" \"from } else { edit axis2.xml \" \"and replace with the same class in org.apache.axis2.dispatchers } } The \"getPackage\" call in the \"if\" statement's condition can return null when the java.lang.Package object is not created by the class loader. This situation is valid as stated in this methods contract. This is what exactly happens in case of CLIF class loader. Hence the null pointer exception. So check has to be introduced to validate the condition. \n",
            "Cannot exclude bean properties of a parent class bean properties of a parent class can be excluded by defining beanPropertyRules parameter in the services.xml. However this feature seems broken in the current Axis2 version It has been noticed that the properties of child can be excluded with the above approach. Steps to reproduce: 1. Deploy the attached service archive 2. Get the wsdl of the service by issuing 3. Check the excluded property in the wsdl \n",
            "Temp files created when axis2 modules are deployed When a module is deployed a temp file with its content is created. This is done to get the URL of all jars from the temp files. However in axis2 v1.3 the jars are moved outside the so there is no need to make a temp file. This is critical if the AxisConfiguration is not singleton and we try to run many services in one application. The temp files are created in which calls \n",
            "AxisFault didnot give me correct QName Below is the code I generated by WSDL2Java: wsdl: Java Code: } catch { org.apache.axiom.om.OMElement faultElt if { if { .... I found do not have a namespace so I didnot get correct error response. \n",
            "restore previously commented JAXWS tests Some tests in JAXWS junit framework were commented out \"temporarily\" but have yet to be restored. I went through and restored did a little debugging on others. Please see attached patch. The test run based on the patch was fully successful: Tests run: Failures: Errors: Skipped: 0 I've included comments in the patch for two others that are commented out to help aid debugging. I don't have time at the moment to but can hopefully address them in the near future \n",
            "java.lang.Exception: org.apache.axis2.databinding.ADBException: Unexpected subelement I expose 3 operations of a service public Project[] String throws ServiceException { try { return } catch { while getting projects for the login return null; } } public Project String throws ServiceException { try { return } catch { while getting projects for the login return null; } } public String String throws ServiceException { try { return } catch { while getting projects for the login return null; } } I generated the web service Axis2 archive with the adb binding here is the code of my skeletton public com.toluna.as.ext.services.project.xsd.GetProjectsAsArrayResponse getProjectsAsArray com.toluna.as.ext.services.project.xsd.GetProjectsAsArray getProjectsAsArray throws ServiceException{ try { String schema String login projects new \" \" for schema schema \" and login GetProjectsAsArrayResponse response new Iterator it while { Project project XMLStreamReader reader 1 StreamWrapper parser new StAXOMBuilder stAXOMBuilder OMElement element 2 } return response; } catch { throw new } } public com.toluna.as.ext.services.project.xsd.GetFirstProjectResponse getFirstProject com.toluna.as.ext.services.project.xsd.GetFirstProject getFirstProject throws ServiceException{ try { String schema String login projects new \" \" for schema schema \" and login Project project XMLStreamReader reader 1 StreamWrapper parser new StAXOMBuilder stAXOMBuilder OMElement element 2 GetFirstProjectResponse response new return response; } catch { throw new } } public com.toluna.as.ext.services.project.xsd.GetFirstProjectNameResponse getFirstProjectName com.toluna.as.ext.services.project.xsd.GetFirstProjectName getFirstProjectName throws ServiceException{ try { String schema String login projects new \" \" for schema schema \" and login Project project GetFirstProjectNameResponse response new return response; } catch { throw new } } when I test it with SOAP UI I always have the following exception java.lang.Exception: org.apache.axis2.databinding.ADBException: Unexpected subelement creationDate public class Project extends ASObject { private Date launchDate; private Date endDate; private boolean launched; private boolean paused; private boolean requestEmail; private boolean webSiteAccess; private boolean useCookies; private boolean fullService; private boolean noBack; private boolean validEmails; private boolean validSample; private String url; private String urlParamName; private String urlParam2Name; private String fakeUserId; private String fakeUserId2; private String returnURLParamName; private String returnURLComplete; private String returnURLScreenOut; private String returnURLQuotaFull; private int keyType private String keyPattern; private String keyLastValue; private Long quotasPanelists; public abstract class ASObject implements Serializable { protected long id; protected String name; protected String description; protected long guid; protected Date creationDate; protected Date modificationDate; protected Date lockingDate; protected boolean deleted; protected int sharingType; protected int versionNumber; protected String versionComment; protected boolean last; protected ASObject prevVersion; protected User user; protected User versionCreatingUser; protected User versionModifyingUser; protected User lockingUser; Do you have any \n",
            "Axis2 on Jetty Tomcat bug: work dir is deleted on jetty shut down When shutting down Jetty version with Axis2 warfile work dir gets almost entirely deleted. The only thing that remains is directory [empty on full of libs on WinXP]. With Axis2 this problem does not occur. When deploying Axis2 on Jetty version everything works just fine. When shutting down jetty work dir remains as it was. It is very easy to recreate this error: download jetty from unpack create 'work' directory in jetty directory put default axis2.war file in webapps dir and run jetty. Everything should go just fine and Axis2 should work. Shut down jetty and check the work dir. There will be nothing there accept Jetty will not redeploy the what IMO means that it wasn't in fact jetty deleting the directories. I have also created an issue in Jetty's Jira: Jetty ticket has been as Jan Bartel proven this bug occurs on Tomcat as \n",
            "Handler is not being invoked The attached module is an implementation of a LoggingModule which was done orientating on the Axis User guide It was declared as a global module in the axis2.xml with a The module class of it was but when a service has been the Handler was not executed. I also tried the SOAPmonitor module the same which was working. I tried the module with the axis2 version service. Is this a Or am I configuring something I am attaching the module to test for and the axis2.xml. Please see also the mailing list for this topic: \n",
            "plugin not displaying entry fields First time submitting an sorry if this doesn't explain the problem well enough. The axis2 service archiver displays a blank entry window if the wizard was exited with missing external libraries or some other error may exist. error log: org.eclipse.jface 4 2 14:24:22.726 Problems occurred when invoking code from \"org.eclipse.jface\". 0 java.lang.NoClassDefFoundError: at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at The wizard saves the entered data into an xml file in error work around: close eclipse delete in restart eclipse run wizard and make sure you enter all information do not use back button or error could come up again wizard will be \n",
            "Potential NPE in XMPPPacketListener There's a potential NPE inside the Worker: MessageContext msgCtx null; try { instantiate msgCtx } { access msgCtx } \n",
            "org.apache.axis2.client.Stub addHeader ignores custom header attributes We are using a 3rd party which requires us to add a custom object to the soap header. This custom object has a required attribute. Debugging shows that the omElementToadd in the addHeader function of org.apache.axis2.client.Stub has the correct but the attributes are not transfered to the soapHeaderBlock. I have build fix for our case by adding Iterator atribIterator while { OMAttribute omAttribute if { } } to the addHeader function. I'm not if this is a valid solution but it works for us. \n",
            "HttpCoreNIOSender throws NullPointerException After a couple of minutes of use the system failed with the following error ERROR Received an internal server error : Internal Server Error ERROR Received an internal server error : Internal Server Error ERROR Received an internal server error : Internal Server Error Exception in thread \"HttpCoreNIOSender\" java.lang.NullPointerException at at at at at at at at at at line 236 is \n",
            "Axis2 generates incorrect schema imports in WSDL returned via I deploy a web service with a WSDL that contains the following import: the WSDL that is returned from Axis2 via returns the following: When I try to invoke this web service using a client I get the following exception: log4j:WARN Please initialize the log4j system properly. javax.xml.ws.WebServiceException: The following WSDL exception occurred: WSDLException: : : javax.wsdl.WSDLException: WSDLException An error occurred trying to resolve schema referenced at relative to java.io.IOException: Server returned HTTP response code: 500 for URL: at at at at at at at at at at 2688 ms. at at at Caused by: javax.wsdl.WSDLException: WSDLException: : : javax.wsdl.WSDLException: WSDLException An error occurred trying to resolve schema referenced at relative to java.io.IOException: Server returned HTTP response code: 500 for URL: at at ... 10 more It seems apparent that if the import begins with 'http' then it should not be \n",
            "AbstractMessageReceiver defines custom class loader without using doPrivileged AbstractMessageReceiver defines custom class loader without using doPrivileged ThreadContextDescriptor should be defined as static class \n",
            "Java2WSDL creates WSDLs that fail Eclipse validation I recently used the Eclipse WebTools WSDL validator. It doesn't like the way that Axis2 creates Schemas. If you look at the AddressBook WSDL that gives you a good example. .... wrapper elements here .... data type elements here The problem is that the wrapper elements refer to the which are defined in two separate schema chunks. So the Eclipse WSDL validator sees these as separate and cannot resolve the cross references. Now the reason I'm guessing that Axis2 generates these in separate schema is because it wants to give them separate target namespaces. So either this needs to create a single Schema chunk or a link between them. \n",
            "NPE in AxisConfiguration if null { moduleVersion } The second condition is never evaluated would cause a It should be || \n",
            "is ignored for xs:any when using XMLBeans I have a strange i'm using XMLBeans as databinding. The codegeneration seems to ignore when using xs:any. following part of my xsd: and xml: ... If i call to validate against the schema i get error: Expected in element This bug seems only in combination of axis2 and xmlbeans when using plain xmlbeans the verification is OK. Any \n",
            "RPCServiceClient response handling incorrect when there are multi byte[] object in the return bean I'm using the axis2 with Spring integrated. POJO Spring bean as service is working. But the object on the client side with is incorrect. In the return there are several byte[] attributes. On the the return object's byte[] attributes will be set with the value of the first byte[] attribute. Following is the modified WeatherSpringService code based on axis2 bundled sample. Weather.java package sample.spring.bean; public class Weather{ float temperature; String forecast; boolean rain; float howMuchRain; byte[] b1; byte[] b2; byte[] b3; public void temperature temp; } public float return temperature; } public void forecast fore; } public String return forecast; } public void rain r; } public boolean return rain; } public void howMuchRain howMuch; } public float return howMuchRain; } public void { this.b1 b; } public byte[] { return b1; } public void { this.b2 b; } public byte[] { return b2; } public void { this.b3 b; } public byte[] { return b3; } } WeatherSpringRPCClient .java package client; import javax.xml.namespace.QName; import org.apache.axis2.AxisFault; import org.apache.axis2.addressing.EndpointReference; import org.apache.axis2.client.Options; import org.apache.axis2.rpc.client.RPCServiceClient; import sample.spring.bean.Weather; public class WeatherSpringRPCClient { public static void throws AxisFault { RPCServiceClient serviceClient new Options options EndpointReference targetEPR new Get the weather the Spring Framework has already initialized it for QName opGetWeather new Object[] opGetWeatherArgs new Object[] { }; Class[] returnTypes new Class[] { Weather.class }; Object[] response Weather result response[0]; display results if { didn't }else{ : \" : \" : \" much rain : \" b1 : \" new b2 : \" new b3 : \" new } } } WeatherSpringService package sample.spring.service; import sample.spring.bean.Weather; public class WeatherSpringService{ Weather weather; byte[] b1 \"Hello byte[] b2 \"Hello byte[] b3 \"Hello public void weather w; } public Weather return weather; } } The result printed out is rpc.client.run: [echo] [java] log4j:WARN No appenders could be found for logger [java] log4j:WARN Please initialize the log4j system properly. [java] Temperature : 89.9 [java] Forecast : Sunny [java] Rain : false [java] How much rain : 0.2 [java] Byte b1 : Hello b1 [java] Byte b2 : Hello b1 [java] Byte b3 : Hello b1 \n",
            "Codegeneration creates faulty Stub with JAXBRI when a SOAP Header is defined in the WSDL A faulty Stub is generated with when a SOAP header is defined in the WSDL: The following informations in the generated \"toOM\" Method for the header are missing: the namespaces for creating the JaxbRIDataSource the name of the element for the \"createOMElement\" method code snippet: part of the \"toOM\" Method in the generated stub: JaxbRIDataSource source new org.apache.axiom.om.OMNamespace namespace return \n",
            "Unconnected sockets not implemented We are using a WSClient to call a web service. Works fine with http. Does not work with https. The Axis Error is : Unconnected sockets not implemented when setting up a ssl connection in order to verify the store config it works just We tried a number of setups: key and trust store were the same file. We used only file name to specify it dir as key and trust store were the same file. Filename specified fully qualified key and trust store are separate Filename was specified fully qualified for both. Result is the same: Unconnected sockets not implemented I found a number of entries here reporting the and also the web seems to be full of the issues. But there seems to be no solution. Any help is very much Thanks. \n",
            "org.apache.xmlbeans.impl.values.XmlComplexContentImpl cannot be cast I expose 3 operations of a service public Project[] String throws ServiceException { try { return } catch { while getting projects for the login return null; } } public Project String throws ServiceException { try { return } catch { while getting projects for the login return null; } } public String String throws ServiceException { try { return } catch { while getting projects for the login return null; } } I generated the web service Axis2 archive with the xmlbeans binding here is the code of my skeletton public com.toluna.as.ext.services.project.xsd.GetProjectsAsArrayResponseDocument getProjectsAsArray com.toluna.as.ext.services.project.xsd.GetProjectsAsArrayDocument getProjectsAsArray10 throws ServiceException{ String schema String login projectArray new try { projects new \" \" for schema schema \" and login \" Iterator it while { Project project XMLStreamReader reader } com.toluna.as.ext.model.project.xsd.Project[] returnArray GetProjectsAsArrayResponse response GetProjectsAsArrayResponseDocument doc return doc; } catch { throw new } } public com.toluna.as.ext.services.project.xsd.GetFirstProjectResponseDocument getFirstProject com.toluna.as.ext.services.project.xsd.GetFirstProjectDocument getFirstProject0 throws ServiceException{ String schema String login projectArray new try { projects new \" \" for schema schema \" and login \" Project project XMLStreamReader reader GetFirstProjectResponse response GetFirstProjectResponseDocument doc return doc; } catch { throw new } } public com.toluna.as.ext.services.project.xsd.GetFirstProjectNameResponseDocument getFirstProjectName com.toluna.as.ext.services.project.xsd.GetFirstProjectNameDocument getFirstProjectName6 throws ServiceException{ String schema String login projectArray new try { projects new \" \" for schema schema \" and login \" String projectName GetFirstProjectNameResponse response GetFirstProjectNameResponseDocument doc return doc; } catch { throw new } } when I test it with SOAP UI I always have the following exception org.apache.xmlbeans.impl.values.XmlComplexContentImpl cannot be cast to com.toluna.as.ext.services.project.xsd.GetProjectsDocument [I do not have any exception into the tomcat console] Do you have any \n",
            "XMLDispatch.createMessageFromValue fails to copy mime headers In it is failing to copy and thus they are not sent. See the test: \n",
            "Sample StockQuoteService.aar doesn't work on Sun App Server 8.1 Sample StockQuoteService.aar doesn't work on Sun App Server 8.1 on Solaris 9 Steps: deploy downloaded axis2.war to Sun App Server 8.1 by copying it to and that axis2 is deployed; build sample service StockQuoteService.aar and deploy sample service by copying it to and confirmed it get deployed by browsing to browse the updatePrice service and it worked fine: browse the getPrice service and failed: On Screen: Exception in server.log: 5: Exception Processing java.lang.IllegalStateException at at at at at at at at at at tried use java client and had the same error on server side. \n",
            "WSDLDefinitionWrapper is not being constructed with the proper Configuration information History: WSLDDefinitionWrapper wraps a WSDL Definition. The WSDLDefinitionWrapper uses information from the AxisConfiguration to determine the strategy for loading resources loading and keeping the schema in Problem: The WSDLDefinitionWrapper its companion WSDL4JWrapper expose constructors that don't pass in the configuration context or other memory limit information. When these constructors are the AxisConfiguration information is and this can lead to out of memory situation. Solution: The solution is to CLEANUP the First Step: Deprecate all of the constructors on WSDLDefinitionWrapper and WSDL4JWrapper that don't provide a memory configuration parameter . Second Step: Examine all uses of the deprecated constructors. In most a configuration is and the code is changed to use the correct constructor. In other the configuration information is not but there is an obvious choice based on the context of the call. we don't need a memory sensitive WSDLDefinitionWrapper for a temporary wsdl definiton I am testing a solution. Kudos to Vien Tran of IBM for finding this error during rigorous SVT testing with a service containing a large number of schemas. Kudos to Jeff Barrett for working with me to brainstorm a solution. \n",
            "ServiceContext.activate never executes the else block ServiceGroupContext existingSGC null; ServiceGroupContext sgc if { could not find an existing ServiceGroupContext use the restored object set parent } else { do something else The else block is never executed because existingSGC is null I suspect existingSGC should be set to \n",
            "Axis doesn't send default values If the client doesn't set the value of the field then Axis needs to set it to default since it is a required field. Axis doesn't do that Haneef \n",
            "Incorrect reference to start.bat in java2wsdl and wsdl2java scripts See the below code in or rem check the environment variable if not \"\" goto gotHome set if exist goto okHome the file start.bat does not exist. \n",
            "ServiceDescriptionImpl always creates URL for WSDL In the case of a Provider web service implementation or an implementation with an implicit the ServiceDescriptionImpl class always creates a WSDL URL. In the case when there is a WSDL URL attached to the DescriptionBuilderComposite instance it should be used. There is no need to create another URL instance in this case. \n",
            "[Break] NonWrapTests break dispatchable OperationDescription list is incorrect In the metadata the has some incorrect logic at the end: CURRENTLY: if null returnTypeName { REVIEW: Not sure the method MUST end with \"Async\"; I think it can be customized. answer || } The is always one of the forms: Thus the check for or will ALWAYS FAIL. Not only the placement of the and || and lack of perentheses means the statement is interpreted as such: answer || so the reason I'm not fixing is because the change over to this logic: answer || caused much test breakage. UNCOMMENT in JAXWSTest and fix the logic in OperationDescriptionImpl. I'll continue to look at this... \n",
            "upload large file heap i had tried to upload and download large through mtom . i got a error message on uploading test but download is ok. code and config file modified are as follows: public static boolean short File String { try { OMElement data Options options ServiceClient sender new OMElement ome String b return } catch { } return false; } public static InputStream short String { try { OMElement data Options options ServiceClient sender new OMElement ome OMText binaryNode DataHandler actualDH return } catch { } return null; } private static OMElement short File String { DataHandler expectedDH; OMFactory fac OMNamespace omNs OMElement data OMElement fileContent FileDataSource dataSource new expectedDH new OMText textData OMElement mboxnum OMElement gtType OMElement fileType return data; } private static OMElement short String { OMFactory fac OMNamespace omNs OMElement data OMElement mboxnum OMElement gtType OMElement fileType return data; } private static Options { Options options new enabling MTOM in the client side options return options; } axis2.xml is modified like this : if you want to enable file caching for attachments there' an error when large file is upload as follows: org.apache.axis2.AxisFault: Java heap space at at at at at at i had change to and it looks like the same . there'r many problems like this i have found still unsolved . \n",
            "not populated correctly Please see has been commented out. dims \n",
            "Proper usage of binding hierarchy Axis2 has a set of description classes AxisBinding .. but it doesn't use them properly in the deployment time or in runtime. For instance when a service is deployed without a the resulting AxisService doesn't contain any binding hierarchy. But when you generate a WSDL via AxisService2WSDL11 you will three three bindings automatically generated. I believe that the proper way of doing this is to create binding hierarchies representing those default bindings at the time of deployment this case via and serialize those binding hierarchies directly in AxisService2WSDL11. It would provide a cleaner way of attaching policies to a service. For example Rampart policies are meaningful only at binding level. Hence we should attach them only to SOAP bindings and maintenance of proper binding hierarchy in a service description would provide a cleaner way of doing that. This would also allow to enhance ServiceBuilder to process external policy attachments via services.xml \n",
            "Redundant check in XMPPSender if { xmppOutTransportInfo new } else if null null { } else do something else targetAddress can only be null in the else block BTW there are no statements in the first else. Is that \n",
            "dependence on ADB Is this dependence on ADB actually needed to build the \n",
            "Writing JAXWS Clients How to specify the axis2.xml and repository As of right org.apache.axis2.jaxws.ClientConfigurationFactory uses System.getProperty on and to pick up the axis2.xml and the repo. Problem is if say one application needs 2 JAXWS clients with different repo's or different axis2.xml's one with security module enabled and one then they can't in the same JVM. 2 WAR's running under So we need some to let the end user specify where to pick up the information from. For example in the servlet case from the servlet or from the thread class loader etc or a custom AxisConfigurator dims \n",
            "JAXWS Sessions working in Standalone with Simple JAXWS client Looks like the JAXWS Sessions scenarios need work. JAXWS Service inside should be able to participate in a transport session JAXWS Service inside should be able to participate in a transport session These services should be able to work with Standalone client with sessions enabled. JAXWS Client with sessions enabled. dims \n",
            "faultcode value missing namespace prefix faultcode value prefix is null. Patch fixes this. \n",
            "Client and Server adb codegen create messages that are non complient There appears to be two problems. The most obvious is that the message sent by the generated client and accepted by the generated service is incorrect . The following message body is sent for the various test cases I have tried complex nested complex type. .............content..... but it should be: .............content..... PartName should be a non qualified name. Axis 1.3 did it this and other sources support this as being the correct form for In particualr Basic 1.0 states: \"4.7.20 Part Accessors For WSDL 1.1 is not clear what if the accessor elements for parameters and return value are a part of. Different implementations make different leading to interoperability problems. R2735 An ENVELOPE described with an binding MUST place the part accessor elements for parameters and return value in no namespace. R2755 The part accessor elements in a MESSAGE described with an binding MUST have a local name of the same value as the name attribute of the corresponding wsdl:part element. Settling on one alternative is crucial to achieving interoperability. The Profile places the part accessor elements in no namespace as doing so is covers all and does not lead to logical inconsistency. \" The second problem that I have yet to narrow down is that with a much more complex the generated client sends a message with a body like this where the \"part\" element is not present: .............content..... One other difference that may be a factor in this case is that my complex service is one way. \n",
            "Class.forName does not use AxisService class loader Just noticed that the TCCL is used to load classes. So i was not able to drop classes into the service directory and get them to load up. I had to place MyClass.clas in to get the JAXWSMessageReceiver to pick it up. Is there a reason for not using AxisService's class dims \n",
            "BindException The environment is the following: there's a tomcat server running on port 8081 and http port set to 16060 in there's a tomcat server running on port 18080 and http port set to 26060 in there's a client using an axis2.xml with http port set to 7000 The client sends an asynchronous request to server which forwards the message to server B MEP is using a custom ConfigurationContext an empty configuration with multi threading support and connections as for I understand runs the http server on port Server B executes the request using sends back the result to server A which should finally be able to forward the result to the client. Please find attached the logs for server A. \n",
            "Codegen is not able to compile multiple WSDL with the same instance of ant task In case that there is an attempt to execute codegen from many task withing the same ant session. Compilation fails with: Error parsing WSDL. Solution is to create separate task deffinitions. \n",
            "WSDL2Java ignore required attributes in xsd The java class generated for the element hasn't the requires field serviceKey and BusinessKey. This happen for oher xml element similar to this one. In the following case the choice element and the two attributes are completly ignored in the generated java class: I tried to use the latest snapshot since my wsdl hasn't service I get a generation error. Attached are the two java classes of the examples showed and the wsdl. \n",
            "Enumerations in WSDL2JAVA don't create which causes failure in the server If you include an enumeration in your the resulting type from WSDL2JAVA with doesn't have a which causes it to fail when the skeleton is called on the server when it tries to deserialize the request. WSDL2JAVA command is: wsdl2java.bat .. com.kronos.dataservice DataService.wsdl SEVERE: Exception occurred while trying to invoke service method UpdateBalance org.apache.axis2.AxisFault: nested exception is: java.lang.InstantiationException: at at at at at at at at at at at at at at at at at at at at at at at at at at at Caused by: java.lang.InstantiationException: at at at ... 26 more \n",
            "JAXWS XMLSpineImpl is not properly closing ancestor om nodes The XMLSpineImpl code adds an OMSourcedElement that represents the body contents. In such the parser is consumed while building the JAXB object. XMLSpineImpl marks the ancestor OM objects as which should fully complete the tree. However the code that marks the ancestors as complete is not correct. It is only is considering the OMElement ancestors...not the OMContainerEx code. \n",
            "wsdl2java produces a stub that cannot be when the wsdl file contains an element defined as a restriction on a duration type This is the sample wsdl: wsdl:definitions xmlns:wsdl \" xmlns:wsdlsoap \" xmlns:xsd \" xmlns:ns \" xmlns:myns \" targetNamespace wsdl:types xsd:schema elementFormDefault qualified \" version 1.0.0.3 \" targetNamespace xsd:element name Operation1Content xsd:simpleType xsd:restriction base xsd:duration xsd:minInclusive value P0Y0M0DT0H0M0S xsd:restriction xsd:simpleType xsd:element xsd:schema wsdl:types wsdl:message name Operation1Msg wsdl:part name body \" element myns:Operation1Content wsdl:message wsdl:portType name MyPortType wsdl:operation name Operation1 wsdl:input message myns:Operation1Msg wsdl:output message myns:Operation1Msg wsdl:operation wsdl:portType wsdl:binding name MyBinding \" type myns:MyPortType wsdlsoap:binding style document \" transport wsdl:operation name Operation1 wsdlsoap:operation soapAction MyOperation wsdl:input wsdlsoap:body use literal wsdl:input wsdl:output wsdlsoap:body use literal wsdl:output wsdl:operation wsdl:binding wsdl:service name MyService wsdl:port name MyPort \" binding myns:MyBinding wsdlsoap:address location wsdl:port wsdl:service wsdl:definitions This is the compilation error: [javac] cannot find symbol [javac] symbol : method [javac] location: class org.apache.axis2.databinding.utils.ConverterUtil [javac] if [javac] \n",
            "Testing log4j settings Quick fix to: Configure the BasicConfigurator in the test's SimpleServer and JAXWSTest Framework. Change the log4.property to INFO \n",
            "JMS Message Id in request message context The correlation id on a JMS message is not set correctly. It appears that this is occuring because the mesage id is not set on creation of the request message context I added the following line of code and it appears to have fixed the problem. private MessageContext { InputStream in try { MessageContext msgContext new ..... \n",
            "wrong prefix set for fault code wrong prefix set for fault code due to using wrong constant in MessageContext \n",
            "Dispatch tests are commented out The dispatch tests in JAXWSTest have been commented out. They need to be This was done under revision 508157 for I've checked with the contributor and this was not intentionally part of that patch. \n",
            "MTOM sample fails with large files The MTOM sample works fine with files from 0 to until I tried to work with a large file I get an OutOfMemoryException on both side and client side: Exception in thread \"main\" org.apache.axis2.AxisFault: java.lang.OutOfMemoryError: Java heap space at at at at at server side: 2 mars 2007 18:52:28 org.apache.axis2.transport.http.AxisServlet doPost GRAVE: java.lang.OutOfMemoryError: Java heap space I am a bit since I was thinking that MTOM would permit to upload large file over streaming without requiring I set the JVM's and with large heap size Do I miss something \n",
            "JAXWS Failed to marshal LegacyException The problem is related to use of WSGen where all jaxws arteffects are stored underneath the folder. JAXWS fails to marshal the fault bean when it is stored in the .jaxws folder. Here's stack trace for the error. I will be providing the fix for this issue. ExceptionFact 1 org.apache.axis2.jaxws.ExceptionFactory createWebServiceException Create Exception: javax.xml.ws.WebServiceException: java.lang.ClassNotFoundException: jaxws.exceptions.wsfvt.server.OperationExceptionBean at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at Caused by: java.lang.ClassNotFoundException: jaxws.exceptions.wsfvt.server.OperationExceptionBean at at at at at \n",
            "in poxBuilder fails when there is no input in the body When i call the method from a builder obtained using I get an error when the body of the request has no data is no input to the org.apache.axiom.om.OMException: com.ctc.wstx.exc.WstxEOFException: Unexpected EOF in prolog at \n",
            "Cannot run generated Java client code Get exception in: I have used AXIS1 for quite some time but only for generating and running clients to call webservices. Due to the statements about improved memory handling and performance I would like to start using AXIS2 instead. This has also been triggered by a system I am working on that uses AXIS1 and it has some stability issues. In my final setup I incoorporate the webservice clients in Lotus the need for running JVM But for the current issue I have isolated the problem to running the code inside Eclipse. I would like to use the xmlbeans databinding be able to handle more complex Though the Java client is slightly executing a client generated with xmlbeans databinding gives exactly the same error as using the default as shown below. I am assuming that something is wrong with my After having tried a number of things generating code from different installing the full Axis2 setting environment trying to set Options and Configurations in the Java I ended up with trying the very simple webservice in the scenario below. And it still fails These are the steps I have performed: 1. Downloaded and installed the Codegen plugin for Eclipse 2. Created a new Java project in Eclipse default JRE I configured the source and default output folders in the project properties. 3. and selected \"Axis2 Code Generator\" 4. Selected \"Generate Java source code from a WSDL file\" 5. Use WSDL: 6. Use default options 7. Browse and select the project in Eclipse 8. Select \"Add Axis2 libraries to the codegen result project\". Pick: and press \"Check Libs\" Message: \"Axis libs loaded successfully is shown. 9. Press \"Finish\" and message \"All operations completed successfully\" is shown. 10. Refresh the project by on the project and selecting \"Refresh\". Now I can see the \"src\" folder with the Java the \"bin\" folder with the and the \"lib\" folder with the 15 Axis2 jar files. 11. Open the project select \"Libraries\" and \"Add JARs...\". Select all the jar files under the project's \"lib\" folder. 12. Create a new Java Class \"TestGet\" with the following source: import org.apache.axis2.AxisFault; import defaultnamespace.GetSubjectServiceStub; import defaultnamespace.GetSubjectServiceStub.GetNthField; import defaultnamespace.GetSubjectServiceStub.GetNthFieldResponse; public class TestGet { public static void { try { String endPoint GetSubjectServiceStub stub new GetNthField func new GetNthFieldResponse resp String x } catch { } catch { } } } 13. on the client program and select \"Run As Java Application\" 14. The code fails with the following error: log4j:WARN No appenders could be found for logger log4j:WARN Please initialize the log4j system properly. java.lang.NullPointerException at at at at What am I doing Thank you in John \n",
            "[Axis2] WSDL2C problem when wsdl type name contains characters I am using the latest trunk code for Axis2 Java as of today. My wsdl has type names that contain characters and this causes C code to be generated that also has these characters. The generated code will not compile. The characters need to be changed to underscore characters. The WSDL was generated with which converts underscore characters in the header file to dash characters in the so it is a common case to have these dash characters in the wsdl. Here's a test WSDL that shows the problem: operation request element operation response element 2.7.6e generated service And here is some of the generated code that shows the problem: getter for const setter for const The for example has the dash characters. \n",
            "Java security AccessControlException Failure occurred during a servlet call. Caused by: java.lang.Throwable: java.security.AccessControlException: Access denied at at at at at at at at at at at at at at at at at at at at at at at at at at at at at ... at at at at at at .... \n",
            "deploy and undeploy problems for service deployed in application scope From catalina.out I see RoutingService is the web service there's no init method LifecycleSupport is the ServiceLifecycle implementation LifecycleManager is an helper class which starts and stop components Startup: INFO LifecycleManager:start Controller started INFO [main] Controller started DEBUG [main] Exception trying to call init java.lang.NoSuchMethodException: at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at DEBUG [main] Exception trying to call init java.lang.NoSuchMethodException: at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at DEBUG [main] Parent class loader is: WebappClassLoader delegate: false repositories: Parent Classloader: and this one when the service is shutting down: INFO: Pausing Coyote on 09:36:45 org.apache.catalina.core.StandardService stop INFO: Stopping service Catalina DEBUG [main] INFO LifecycleSupport:shutDown Qosp is shutting down... INFO [main] Qosp is shutting down... INFO QueueScheduler:stop Controller stopped INFO [main] Controller stopped DEBUG DefaultServiceManager:stopHandlers Stopping handlers DEBUG [main] Stopping handlers ERROR [main] Servlet AxisServlet threw exception javax.servlet.ServletException: for servlet AxisServlet threw exception at at at at at at at at at at at at at at at at at at at at at DEBUG [main] Stopping filters DEBUG [main] Stopping DEBUG [main] Unloading persisted sessions DEBUG [main] Saving persisted sessions to SESSIONS.ser DEBUG [main] Unloading 0 sessions DEBUG [main] Expiring 0 persisted sessions DEBUG [main] Unloading complete 09:36:45 org.apache.coyote.http11.Http11BaseProtocol destroy INFO: Stopping Coyote on 09:36:45 org.apache.catalina.core.AprLifecycleListener lifecycleEvent INFO: Failed shutdown of Apache Portable Runtime \n",
            "Don't create SOAPMessageContext unless handlers or resource injection is required Currently creating a SOAPMessageContext for each request. This is expensive. I have a quick fix which I will apply shortly. This problem was brought to my attention by David Strite of the IBM performance team. Thanks David \n",
            "Enable client side validation the validation is only enabled on the server side. This fix enables it for the client side as well. \n",
            "Could not set \"Expect HTTP header I need to set \"Expect http but I could not find a way to do it in axis2. I tried to add it as a custom but it would not work. After I examine the code more it seems to me that it is not possible to add it. In at line if HTTP version is this header would be set. But in org.apche.commons.httpclient.methods.ExpectContinueMethod.java's this header would be removed because is never set. I searched through axis2 source code and didn't find a way to set this parameter. \n",
            "AXIS2 can not correctly map some java data type to corresponding xml data type and can not marshall and unmarshall these object I found the AXIS2 can not correctly map the following java data type to correpsonding xml data type in the generated WSDL. It considers them as complex type and further serializes their attachment java.math.BigDecimal; java.math.BigInteger; javax.xml.namespace.QName; org.apache.axis.types.Day; org.apache.axis.types.Duration; org.apache.axis.types.Month; org.apache.axis.types.MonthDay; org.apache.axis.types.NegativeInteger; org.apache.axis.types.NonNegativeInteger; org.apache.axis.types.NonPositiveInteger; org.apache.axis.types.PositiveInteger; org.apache.axis.types.Time; org.apache.axis.types.UnsignedByte; org.apache.axis.types.UnsignedInt; org.apache.axis.types.UnsignedLong; org.apache.axis.types.UnsignedShort; org.apache.axis.types.Year; org.apache.axis.types.YearMonth; If I still consider them as corresponding xml data type not a customized complex and send the value with corresponding for for one exception will be thrown the attached \"SOAP message for echoDay . It seems that axis2 can not correctly marshall and unmarshall these objects. \n",
            "Move SimpleServer out of the \"src\" directory and into the \"test\" directory. SimpleServer is only used for and so should be in the \"test\" not the main \"src\" directory. \n",
            "java.lang.NullPointerException at org.apache.axis2.description.ClientUtils.inferInTransport java.lang.NullPointerException at at at at which is not a clear error message. Server and client are generated automaticly from the wsdl with Axis2 code generator and xmlbeans databinding within Eclipse result using Here is the null pointer exception is at org.apache.axis2.description.ClientUtils.inferInTransport received when launching my client code trying to invoque the available service. } else { listener transport as sender transport listenerTransportProtocol } } Here is the wsdl : and the referenced xsd : Here is the full client code : AskForPricingStub InstrumentsDocument InstrumentType InstrumentType[] { HeaderNCBDocument HeaderNCBToFRType Calendar is \n",
            "\"org.apache.axis2.AxisFault: Incoming message input stream is null\" while engaging addressing module on client side My client class needs to engage addressing module. This is my client package calc1; public class { public static void try{ EndpointReference targetEPR new EndpointReference myEPR new Options options new RPCServiceClient sender new QName opAdd new Integer a new Integer b new Object[] params new Object[] { b }; Class[] returnTypes new Class[] { Integer.class }; Object[] response Integer result response[0]; if else opAdd new Integer a new Object[] params new Object[] { a}; Class[] returnTypes new Class[] { Integer.class }; Object[] response Integer result response[0]; if else } } Even if the addressing module is in the classpath I get AxisFault. This is the exception i get trying to engage addressing module on client side org.apache.axis2.AxisFault: Incoming message input stream is null at at at at at at at I noticed from SOAPMonitor that apart the AxisFault the request and response messages are correct but only the request one has the wsa header fields: SOAPRequest SOAPResponse How can I get wsa fields in the SOAPResponse module is already engaged on service side and is the Dropping the engage instruction from the client code causes the exception to disappear but I have a in the services.xml. \n",
            "wsdl Relative path not supported When client creates a service using relative path for WSDL jaxws wsdl4jWrapper is not able to read the wsdl definition. I will fix the code to read classLoader resourse and create the wsdl definition accordingly. \n",
            "Session Management not supporting different session identifiers I'm having a problem with session using a Service Client. I have two methods calling two different operations of a web service. The webservice is not implemented in axis2. I need to use a session so the web service can identify the axis2 client by each call. My class defines a single ServiceClient to make two different call. It has following option turned on: When I make the first call to the it runs the webservice and responds correctly. Following header is then passed: 200 OK Connection: 646 By the second call the client does not put the session data back to identify itself. So it passes only this information: SOAPAction: \"urn:anonOutInOp\" Axis2 Authorization: Basic [based64usernamepassword] Host: localhost:5554 453 This was posted to the user mailing list and the conclusion was that axis2 does not support ssnid as session id. So a axis2 client can't communicate with another application server using session management. \n",
            "getAxisConfiguration method of FileSystemConfigurator raising exception I am getting following exception when trying to call the getAxisConfiguration method of FileSystemConfigurator java.lang.NoSuchMethodError: at at at at at at at at at at at at Exception in thread \"main\" Can you please tell me what can be possibly \n",
            "AXIS2 generates invalid fault element for SOAP1.1 binding in the WSDL WSDL generator of AXIS2 has a bug. When I retrieve the WSDL for Version web service using the following method: the generated WSDL is invalid if a operation has fault message. The SOAP 12 binding element is just SOAP1.1 binding element[1] is invalid. It should be [2]. [1] original SOAP1.1 binding element \" [2] correct one \n",
            "Caused by: org.apache.axis2.schema.SchemaCompilationException: ... is not supported JAVA VERSION java version \"1.6.0\" SE Runtime Environment Java Client VM mixed CLASSPATH WSDL COMMAND org.apache.axis2.wsdl.WSDL2Java M cKessonUserService.wsdl com.mckesson.secureServices.wsdl.usr RESULT Exception in thread \"main\" org.apache.axis2.wsdl.codegen.CodeGenerationException : java.lang.RuntimeException: java.lang.reflect.InvocationTargetException at at at Caused by: java.lang.RuntimeException: java.lang.reflect.InvocationTargetExcepti on at at ... 2 more Caused by: java.lang.reflect.InvocationTargetException at at at at at ... 3 more Caused by: org.apache.axis2.schema.SchemaCompilationException: is not supported. at at at at at at at org.apache.axis2.schema.SchemaCompiler.processAnonymousComplexSchemaT at at at at at at ... 8 more WSDL tells me this wsdl is this wsdl ALSO works with axis1.4 by the created by Apache Axis version: 1.3 Built on Oct 2005 \n",
            "quickstartjibx sample does not work Following exception thrown when running ant generate.service task in quickstartjibx sample. [wsdl2java] SystemId Unknown; Line Column Had IO Exception with stylesheet file: databindsupporter [wsdl2java] SystemId Unknown; Line Column Had IO Exception with stylesheet file: databindsupporter compile.src: [javac] Compiling 4 source files to [javac] cannot find symbol [javac] symbol : method [javac] location: class samples.quickstart.service.jibx.StockQuoteServiceMessageReceiverInOnly [javac] [javac] [javac] canno t find symbol [javac] symbol : method [javac] location: class samples.quickstart.service.jibx.StockQuoteServiceMessageReceiverInOut [javac] envelope [javac] [javac] Note: Some input files use unchecked or unsafe operations. [javac] Note: Recompile with for details. [javac] 2 errors BUILD FAILED Steps to reproduce: 1. Navigate to directory 2. Enter ant command \n",
            "org.apache.axis2.wsdl.WSDL2C: WSDL Choice element not handled when generating 'C' code WSDL: Code Gen options: org.apache.axis2.wsdl.WSDL2C test.wsdl server10 adb Resulting Only the name part is generated: struct { NameValue; }; \n",
            "Unexpected subelement WSDL and XML seems correct See attached WSDL file. When running method I get exception Exception in thread \"main\" java.lang.RuntimeException: java.lang.RuntimeException: Unexpected subelement handle at at at at Caused by: java.lang.RuntimeException: Unexpected subelement handle at ... 4 more SOAP request: POST SOAPAction: \"urn:createasyncfeeder\" Axis2 Host: bananarama.blah.blah.com:6100 chunked SOAP response: 200 OK Server: 508 Connection: It seems to me that elements have correct names according to schema in WSDL. Please advice. also bug \n",
            "Caused by: java.lang.RuntimeException: org.apache.xmlbeans.XmlException: error: Problem parsing referenced XML resource java.io.FileNotFoundException: PLEASE ADD PATCH TO THE NIGHTLY BUILD Caused by: java.lang.RuntimeException: org.apache.xmlbeans.XmlException: error: Problem parsing referenced XML resource java.io.FileNotFoundException: system cannot find the path at ... 8 more Caused by: org.apache.xmlbeans.XmlException: error: Problem parsing referenced X ML resource java.io.FileNotFoundException: syst em cannot find the path at at at at at at at \n",
            "Making JSON sample work properly The JSON sample in Axis2 was not copying to the when the source is built. And also the necessary jars for the json module was not copying into the lib directory. I have made the required changes in the maven.xml in this patch. \n",
            "Invalid code generation using wsdl2java.bat for SOAP WSDLs for referenced element was not I am unable to successfully generate .java classes from SOAP WSDLs using wsdl2java.bat in axis2 ... Below is the error message I get ... Exception in thread \"main\" org.apache.axis2.wsdl.codegen.CodeGenerationException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException at at at Caused by: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException at at ... 2 more Caused by: java.lang.reflect.InvocationTargetException at at at at at ... 3 more Caused by: org.apache.axis2.schema.SchemaCompilationException: The referenced element was not at at at at at at at at at at at at at at at at at ... 8 more I've reviewed our BOD structure and its is valid ... everything seems fine in XMLSpy. I've been able to generate our .java files using our JMS WSDLs which is using the same BODs as our SOAP WSDLs .... I need help on this issue ... I've tried and ... and cant seem to get the .java files generated from our SOAP WSDLs ... I can provide addition documentation as needed .... This is a CRITICAL issue for me and I need \n",
            "java2WSDL does not generate nillable true When I generate wsdl from Java the codegen plugin doesn't generate correctly the attribute. API.java is the service interface. Configuration is the type returned by the operation in the API and example.wsdl is the wsdl generated by the plugin. \n",
            "wrong prefix set for fault code to Patch applies to saaj module. Simple fix. See patch. \n",
            "Java2 Security exception in Threadpool In some environments where Java2 Security is the ThreadPool code will get an AccessControlException where access to groups is denied. Stack Trace: java.security.AccessControlException: Access denied at at at at at at at at at at at at at at at at at at ....... \n",
            "\"input line is too long\" error when executing the tools in Windows 2000 When trying to run the axis tools are .bat in Windows the following error is displayed: \"La línea escrita es demasiado larga.\" Win 2k or english should \"The input line is too long\". This occurs because the Windows 2000 line length limit is shorter than in Win and the content is too long. To make it just change the by arround when calling the JVM: From: ........ To: ...... Gabriel \n",
            "When running the databinding sample if a wrong symbol is a successful response is given without throwing an error Was running the databinding sample and experienced the following. Below are the steps taken to produce the issue 1. Execute the command \"ant run.client and received the results successfully. 2. Executed the same command with a wrong symbol ant run.client and you will still get the same results. Since this symbol does not it should throw an error instead. \n",
            "Having problems with vectors in my web service I have a web service on axis 2 which is called by an RPCClient. My problem is that because my Web service calls a class which contains a vector i get the null rcl Exception and specific on StAXOMBuilder. My RPCClient is: package com.something; import javax.xml.namespace.QName; import org.apache.axis2.AxisFault; import org.apache.axis2.addressing.EndpointReference; import org.apache.axis2.client.Options; import org.apache.axis2.rpc.client.RPCServiceClient; public class RPCClient { public static void [] args1 throws AxisFault { RPCServiceClient serviceClient new Options options EndpointReference targetEPR new SLTerm sl new SL newsl new QName opAddElement new Object[] opAddElementArgs new Object[] { newsl }; } sl class: package com.something; import public class SL { private terms new private String part null; public void { } public { return terms; } public String { return party; } public void { this.part part; } } SLTerm class package com.something; public class SLTerm { private String bd null; private String name null; private String null; public void { this.bd bd; } public String { return bid; } public void { this.name name; } public String { return name; } public void { sc; } public String { return } } Service: package com.something; public class DBService { public void { new } } Insert class package com.something; import import java.util.Vector; import javax.xml.parsers.DocumentBuilder; import javax.xml.parsers.DocumentBuilderFactory; import javax.xml.parsers.ParserConfigurationException; import javax.xml.transform.Result; import javax.xml.transform.Transformer; import javax.xml.transform.TransformerConfigurationException; import javax.xml.transform.TransformerException; import javax.xml.transform.TransformerFactory; import javax.xml.transform.dom.DOMSource; import javax.xml.transform.stream.StreamResult; import org.w3c.dom.Document; org.w3c.dom.DocumentType; import org.w3c.dom.Element; public class Insert { public { SL sl new DocumentBuilderFactory dbf DocumentBuilder db null; try { db } catch { } Document document Element QoSdb for term : { Element OfferType Element Part Element bd Element name Element sc } Saving the document on a specific dir String test String docName \"test.xml\"; TransformerFactory tf Transformer transformer null; try { transformer } catch { } DOMSource source new Result dest new try { } catch { } } End insert } As you imagine i save an xml document created by the rpc client using the values of the vector I get the null rcl exception... If anyone could help .... Thanks \n",
            "Problem installing latest eclipse plugins for Axis2 CodeGen and Axis2 Service Archiver. I am using eclipse 3.1 and axis2 1.1.1. I am trying to install the axis2 plugins for eclipse. I deleted a the old plugin files as instructed in the readme.txt file and copied the latest plugin files to the folder and I get the following error when I try to start the plugin from eclipse. was unable to load class org.apache.axis2.tool.codegen.eclipse.CodeGenWizard.\" I earlier versions of the plugins worked fine for me. I had this problem after downlaoding and installing the latest Axis2 eclipse plugins. tried reverting back to the old versions of Eclipse and it works fine. But when I try to use the latest versions of the eclipse I am not able to start the plugins. I am having issues. The Stacktrace for the the eclipse log is as follows org.eclipse.osgi 4 0 12:59:36.628 An error occurred while automatically activating bundle 0 org.osgi.framework.BundleException: The activator org.apache.axis2.tool.codegen.eclipse.plugin.CodegenWizardPlugin for bundle is invalid at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at Caused by: java.lang.UnsupportedClassVersionError: major.minor version at at at at at at at at at at at at at at at at ... 70 more Root exception: java.lang.UnsupportedClassVersionError: major.minor version at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at \n",
            "client not run behind a proxy I've got a client of Google Web Services. I run it behind a so I add next lines to stub generated with code generator plugin for Eclipse: Auto generated method signature param0 public googlesearch.DoSpellingSuggestionResponseDocument googlesearch.DoSpellingSuggestionDocument throws java.rmi.RemoteException { try{ org.apache.axis2.client.OperationClient EMS INI Obtenir les opcions de la connexio org.apache.axis2.client.Options a Transport sense per que el nostre proxy no ho admet La connexió ha de ser Per defecte ja la pero per si de cas Establir proxy i usuari amb permisos org.apache.axis2.transport.http.HttpTransportProperties.ProxyProperties b new Establir les noves opcions FIN create SOAP envelope with that payload org.apache.axiom.soap.SOAPEnvelope env null; ..... That client runs ok with Axis2 but now I updated to Axis2 Nighty of 15th Feb 2007 and client doesn't work. I sniff http port and there is a diference in the POST header. Axis2 1.1 send this post POST SOAPAction: \"urn:GoogleSearchAction\" Axis2 Host: api.google.com 321 Axis2 Nighty send this post POST SOAPAction: \"urn:GoogleSearchAction\" Axis2 Host: 321 It seems like proxy settings owerride hostname api.google.com. \n",
            "Adding method to read Sync OperationDescription for Async Operation I am moving the change I made for getting Sync OperationDescription for an AsyncOperation to OperationDescriptionImpl. Also changing AsyncResponse to not return WebServicesExceptoin when a user defined Exception is thrown. Also modifying the test case to asser on correct Exception. \n",
            "Metadata code does not need to handle overridden methods in the case of SEI's The metadata layer of should not try to remove overridden methods of an SEI as interfaces do not override methods. \n",
            "Avoid loading class during metadata Loading application classes should be avoided during the metadata processing layer. The first step to achieve this goal is to move the and classname defaulting to the jaxws marshal layer. The current code in the metadata layer attempts to find and classnames doing class loading. This is inefficient. And and do not provide defaults for the classname parameters. The proposal is to move this calculation to the marshalling layer in JAXWS. can use a proprietary mechanism to wrapper classes as needed. \n",
            "BUILD BREAK There were some weekend changes that broke the build. I am currently investigating a solution. Here is the snippet from continuum. [junit] Running org.apache.axis2.jaxws.framework.JAXWSTest [junit] Tests run: Failures: Errors: Time elapsed: 8.063 sec Friendly reminder to be careful when you commit changes. \n",
            "Typing error \"dierctory\" A misspelled word \"dierctory\" can be found at the location \n",
            "Documentation and Sample for EJB Provider I checked in EJB provider is not available for Axis2. There is an RTF file in there and some sample code. I did not check that in. Can you please look into dims \n",
            "SimpleTypeMapper.getOMElement throws a NullPointerException in AXIS 2.1.1 release when given a java.util.List with some VO. In case of List of Strings it works fine. Below is the method which is used for populating the List and serializaing and the same. public void throws Exception{ String namespace String prefix \"vo\"; String localPart \"units\"; QName qnameList new List lstToConvertToOMElement new the list with some data. List testUnits new MySampleVO objSdmTableColumn new \" OMElement omLstElement new new OMElement is obtained. omLstElement } List objListType new instanceof Yessssssssssssssssssssssss got the List object back\" List lstDeserialized \" java.util.Iterator itrList Object obj Yessssssssssssssssssssssss got the object back from the list \" } } } The MySampleVO code is pasted below import java.io.Serializable; import java.util.List; public class MySampleVO implements Serializable { private String name; private String label; private String expressionString; private String type; private boolean marked; private String quantityType; private List units; private String format; public { this } public String String String String List String { this.name name; this.label label; this.expressionString expressionString; this.type type; this.quantityType quantityType; this.units units; this.format format; } public String { return name; } public String { return label; } public String { return type; } public String { return expressionString; } public List { return units; } public String { return quantityType; } public boolean { return marked; } public void { this.marked marked; } public void { this.expressionString expressionString; } public void { this.label label; } public void { this.name name; } public void { this.type type; } public void { this.units units; } public void { this.quantityType quantityType; } public String { return format; } public void { this.format format; } } \n",
            "Exception when invoking a service in RESTful manner using a generated stub I created a service and deployed in tomcat. Then generated a stub using wsdl2java When I tried to invoke the service using a client in RESTful following exception occurs at the client side. org.apache.axis2.deployment.ModuleDeployer deploy INFO: Deploying module: addressing Exception in thread \"main\" java.lang.RuntimeException: java.lang.UnsupportedOperationException: The parser is already at at at Caused by: java.lang.UnsupportedOperationException: The parser is already at at at ... 2 more I was able to invoke the same service in RESTful manner using a client which used Axis2 client API. a This issue occurs only if you use a generated stub. Following code was used to invoke the service in RESTful manner. NulltestStub stub new Options opts NulltestStub.SayHello request new NulltestStub.SayHelloResponse response : \" \n",
            "unreliable behavior of sendRobust The sendRobust method is not reliable at all. Messages are delivered to the but on the sender side errors happen this causes me some big The used ConfigurationContext is: multiThreadedConfigurationContext ConfigurationContextFactory MultiThreadedHttpConnectionManager connectionManager new HttpConnectionManagerParams params new HttpClient httpClient new \n",
            "not able to call a service from another service I have a POJO exposed as a Webservice using Axis2. I have tested this service using RPCServiceClient and it works fine. This service needs to talk to other services which are also POJO's exposed as Webservices using Axis2. The other services also work fine when invoked by RPCServiceClient mechanism. But if I invoke those services from my Axis2 service using the same mechanism of RPCServiceClient it gives me the following exception. java.lang.reflect.InvocationTargetException at at at at at at at at at at at at at at at at at at at at at at at at at Caused by: java.lang.NullPointerException at at at at at at at at at at at ... 25 more i am calling first from the client using RPCServiceClient. from meth2 i am calling second using RPCServiceClient again. the services work fine when invoked from within a client. the exception is only when the second service is invoked from within another service. \n",
            "java.lang.List returns only an element I've got two web one with a return type and another with a return type None of them returns the elements of the they only returns element service serveiProvaList returns package principal; import java.util.ArrayList; import java.util.List; public class GestorGeneral { public { llista new return llista; } } It returns this 200 OK Server: chunked Date: 19 Feb 2007 16:03:50 GMT 167 0 service APService returns package com.thales.vhccc.ap.dao; import java.util.ArrayList; import java.util.Date; import java.util.List; import com.thales.vhccc.ap.bean.APAttendance; import com.thales.vhccc.ap.bean.APPharmacy; import com.thales.vhccc.ap.bean.APVaccine; import com.thales.vhccc.dao.exception.AttendanceBusinessException; import com.thales.vhccc.dao.exception.PharmacyBusinessException; import com.thales.vhccc.dao.exception.VaccineBusinessException; public class APDaoImpl implements APDao { public String throws AttendanceBusinessException { TODO method stub llistaAtencions new APAttendance episodi1 new \" \" Date a new return llistaAtencions; } } It returns 200 OK Server: chunked Date: 19 Feb 2007 16:03:36 GMT 173 0 \n",
            "JRE6 Java Web Start Axis 2 v1.1.1 causes a thread to hang unexpectedly I have encountered a bizarre problem which seems to surface occasionally when using a combination of Java Web Start for Java SE 6 Axis 2 v1.1.1 and the Betfair API. I am using Axis 2 in xmlbeans and it is one Betfair API call in particular which is messing although the problem seems to lie either in JWS or in Axis 2. Approximately of the a call to the call of the Betfair API from a Java desktop app deployed via Java Web Start hangs at least one of the threads depending on API services. Here is a stack trace of the guilty thread: \"Timer 0\" runnable [0x05fce000..0x05fcfb94] java.lang.Thread.State: RUNNABLE at at at at at at at at at at at at at at at at at at at at at at at locked at at at at This then results in CPU and the only solution is to then close the program and restart it. Quite often there is more than 1 thread stuck in a similar situation to the one so perhaps they are all waiting on not sure. This may be purely a bug in but I submitted it here just in case. Unfortunately I'm only creating the bug at the moment using the Betfair API and my Betfair so if you have a Betfair account let me know and I can give your account permission to access the Betfair API using my application. You can access the WSDL for the Betfair API at : The API call which is causing problems is The structure of the WSDL file appears to be and all other Betfair API calls are working correctly. \n",
            "Axis 2 as a access doesn't work When the server is https doesn't work. https itself is supported through Httpclient. The credential is put in to \"state\" as: The problem is that if it's real port is and the \"port\" here is the default \"80\". when the response comes the actually port is returned. That caused the credential not found. This is only one of the issues. The credential handling code below is really wrong: if { if { for NTLM creds new } else { for Digest and Basic creds new } } else { only for Digest and Basic creds new } whether it's basic or Digest is not decided by whether domain name and realm applies to basic and not integrated. If you look at the IIS web server config you will see. \n",
            "generated wsdl:fault is not BP2032 conform If I start with an hand written which is also BP then the WSDL2Java generates an which is not conform to the BP2032 The problem that the WSDL2Java generates a wrong soap:fault element within the wsdl:fault element. will be generated to The WSDL2Java replaces the soap:fault element with the soap:body element and the BP test results in an error. \n",
            "NullPointerException invoking a stub method Service skeleton generated from wsdl with axis2 1.1.1 Client stub generate with axis2 1.1 generation problems with 1.1.1 Trying to invoke a stub method form a client class I get: java.lang.NullPointerException at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at Tomcat log exception is: Feb 2007 11:45:54 AM org.apache.catalina.core.StandardWrapperValve invoke SEVERE: for servlet AxisServlet threw exception java.lang.NullPointerException at at at at at at at at at at at at at at at Feb 2007 11:45:54 AM org.apache.catalina.core.StandardHostValve custom SEVERE: Exception Processing java.lang.IllegalStateException at at at at at at at at at at at at at at \n",
            "SAAJ API throws a misleading exception when looking for a factory implementation I was trying to use Axis2 SAAJ API with Sun's SAAJ implementation. So I created the appropriate files accessible from the classloader bogus classnames for during factory lookup I always got an exception that Axis2 provider could not be loaded. After debugging the class a bit it appears that my custom factory class was found and attempted to be loaded in line 120 of the file. the method is called within a bigger try { .. } catch {} statement and therefore any exception thrown by the method is ignored then the code in line 126 gets executed and the misleading exception is It's misleading in the sense that I specified overwrite and it's being used but the code is still trying to load Axis2 provider. So I think it would be nice to at least display a warning when an overwrite is used but the class cannot be loaded or maybe the FactoryFinder should just throw the exception when it fails to load the class specified in the file. \n",
            "Documentation and Sample for EJB Provider I checked in EJB provider is not available for Axis2. There is an RTF file in there and some sample code. I did not check that in. Can you please look into dims \n",
            "annotation is not picked up When i deploy a service using JAXWSMessageReceiver that has annotation. the handlers are not picked up nor invoked. There is a TODO item in the EndpointInterfaceDescriptionImpl.java as follows. I can also see a JavaClassToDBCConverter that has a attachHandlerChainAnnotation which can help. But the only location the JavaClassToDBCConverter class is instantiated is in a test case... Need to process the other annotations that can on the server side and at the class level. They as follows: HandlerChain SoapBinding WebServiceRefAnnot BindingTypeAnnot Sec. 7.8 Used to set either the or WebServiceContextAnnot via dims \n",
            "The methods in the metadata description package should not cause fatal errors Wrap the methods of the metadata description classes with a try catch block. \n",
            "... makes WSDL2Java code generation choke See attached using generated by gSOAP 2.7. Axis2 v1.1.1 chokes on when generating Java classes from WSDL. Error message: [codegen] SEVERE: Missing part named \"parameters\" Please advice. I removed the \"parts\" parameter because I noticed that this is an optional parameter according to WSDL spec. Code generation now but code still does not run. Please see bug Both Axis 1.4 and XFire 1.2 eats this WSDL with no problems. \n",
            "Unable to set the action for a Fault message generated when throwing an AxisFault Part of the reliable messaging specification is that when sending a Fault message is RM it should contain the action At the moment it is not possible to throw an AxisFault and get the action set to anything other than the default addressing action \n",
            "[Axis2] WSDL2C boolean not handled correctly code does not compile I have a boolean type in my WSDL and code is generated that fails to compile. WSDL: operation request element operation response element 2.7.6e generated service Generated code: Compile error on this line The text value should be assigned like: \n",
            "WSDL2Java doesn't generate all classes and properties of classes from complex types. I am facing an issue with Axis2 wsdl2java code generation. Some of the complex types are not generated in Java Stub class. I am attaching the Java Class and WSDL file for your reference. Please notice that \"InvalidDataSourceReference\" and similar elements are not generated in Stub class extenstion to .java from I used to generate the classes but still DataSource class doesn't have right properties in it. This class should have had \"DataSourceReference\" and \"InvalidDataSourceReference\" as a property. PS: I tried using nightly build as well on 1.1.1 branch. A quick would be best. \n",
            "Missing CRLF Before First MIME Boundary in Chunked SwA Messages There is a missing CRLF before the first MIME boundary in SwA messages when chunking is enabled. Chunking requires one CRLF after the chunk but the MIME boundary also requires a preceding CRLF: \"Note that the encapsulation boundary must occur at the beginning of a following a CRLF\" The HTTPTracer output for a chunked Axis2 client invocation: Listen Port: 8888 Target Host: Target Port: 5005 Request POST SOAPAction: \"\" Axis2 Host: chunked 22a6 8bit A successful chunked client invocation using cURL includes 2 CRLFs: Listen Port: 8888 Target Host: Target Port: 5005 Request POST Host: Accept: chunked Expect: 3ff4 8bit \n",
            "Make threadsafe Paraellel maven build presents warning that this plugin is not threadsafe. \n",
            "Add Transport Ports to MessageContext At the moment Axis2 is only recording the transport IP addresses in the kernel MessageContext. This patch is also recording the and in through the module. I have attached an unified diff of the change \n",
            "Maven does not allow module names to be specified on multiple lines. Currently the Maven Plugin does not permit you to place the named modules on more than one line. If you are configuring a lot of then this leads to a very long line. if a is added it breaks the plugin. {code:xml} {code} In my patched I have added three lines to \"AbstractCreateRepositoryMojo.java\" to simply remove whitespace between the defined module names at the start of the execution. {code:java} public void throws MojoFailureException { artifacts new if { modules } {code} Thus I can specify: {code:xml} someModuleD {code} IMHO an even better configuration may be to replace the \"modules\" String in the MOJO with a for: {code:xml} {code} \n",
            "Make threadsafe Paraellel maven build presents warning that this plugin is not threadsafe. \n",
            "Submit for consideration I have created a simple maven plugin to wrap the \"XSD2Java\" functionality of ADB This ticket is simply to submit my project for the maven module for review consideration for integration into Axis2. I tried to conform to the existing Axis2 Maven plugin setup as much as possible. Unfortunately what is still missing in my module are \n",
            "Maven Maven WAR plugin with artifacts I have a conflict currently between the and the At some point someone upgraded the Maven WAR plugin so that it automatically packs any runtime dependency into the resulting WAR. Unfortunately it is also not possible to disable this \"feature\" on the I to use the to place different \".mar\" artifacts into two Axis2 repositories in the same WAR and While the does its job the WAR plugin always runs last and packs MAR artifacts into My \"workaround\" which is most likely not was to change the CreateRepositoryMojo.java so that it works on MAR artifacts with scope \"provided\" instead of \"runtime\" and compile\" instead of \"runtime\". This keeps the WAR plugin from packing them automatically and allows me to run two separate executions for my two repositories. {code:java} Creates an Axis2 repository from the project's runtime dependencies. This goal is typically used to build an Axis2 repository that will be packaged into some kind of distribution. package compile public class CreateRepositoryMojo extends AbstractCreateRepositoryMojo { The output directory where the repository will be created. private File outputDirectory; protected String { return } protected File { return outputDirectory; } } {code} I am not sure what a solution would look like...or even if it is a concern for this The solution would be an option to exclude .mar artifacts in the ... but if possible I want to get away from having to customize the Axis2 Plugin with every new release. \n",
            "Document the parameter on the WSDL2Java reference page It would be nice to have the parameter introduced with documented on the reference page[1]. [1] \n",
            "Expose isMakeConnectionAnonymous on EPR At the moment the Axis2 EPR has a method hasAnonymous that returns true if the address is either WSA anonymous or using makeConnection annonymous. I propose that this method continues to work as but a new method is exposed called isMakeConnectionAnonymous. The hasAnonymous can be changed to use that new method. The isMakeConnectionAnonymous might be useful to Sandesha \n",
            "WebServiceContextAnnot should be deleted The class WebServiceContextAnnot implements the interface this interface in not an annotation interface. The web service context is actually loaded using the so having a WebServiceContextAnnot appears to be unnecessary. Getting rid of it seems like a reasonable option given that there are some 2.1 API methods on there that will not be implemented. \n",
            "LocalTransportSender can be used on multithread. I was changed LocalTrasportSender for multithread. We can LocalTransportSender on mutlithread by using attached code. Please check attached codes. I hoped that this enhanced added to next release. \n",
            "WSDL2Java should be able to generate Async MessageReceivers By default Axis2 generates synchronous services the MessageReceivers extending the Sync abstract message receivers. The result of this is that when a client calls with a real the HTTP connection blocks waiting for the service to finish processing. This is easily fixed by changing the message receiver to extend the Async abstract message receiver. In this works really well. You change two letters in your generated code and now both async and sync calls work nicely. So... my proposal is that we add an option to WSDL2Java to generate this. \n",
            "JAXB CustomBuilder support in JAXWS layer. Problem: We want to unmarshall the soap body payload as an OMSourcedElement backed by a JAXB object. Solution: The proposed solution is to create a new JAXBCustomBuilder. The JAXBCustomBuilder is registered on the and it will automatically demarshall the payload into an OMSourcedElement backed by a JAXB object. Here is a quick summary Receive first message. The JAXWS unmarshalling code builds a JAXBContext and unmarshalls the payload. The JAXWS unmarshalling code builds a JAXBCustomBuilder with the same JAXBContext. The JAXBCustomBuilder is placed on the ServiceContext. Receive second message The Dispatch code associates the ServiceContext with a MessageContext. This event is intercepted and triggers the JAXBCustomBuilder to be registered on the StAXOMBuilder. When the StAX events of the payload are the JAXB object is automatically unmarshalled. Note that this defect requires changes that are being made as part of Rich \n",
            "getter for configuration on CodeGenerationEngine to access generated info Dear Apache I am on porting my code from Axis1.x to Axis2 I need some access on generated Wsdl2java configuration output. Using the WSDL2Java implicitly means there is no access on generated information in Axis2 like list of generated It seems to me that providing a simple getter method on \"configuration\" of org.apache.axis2.wsdl.codegen.CodeGenerationEngine Class would solve the problem elegantly. This improvement would really help me a hell Thx in Tamas K. \n",
            "Improve structure of JAXWS tetss This is based on a proposal from Nick Gallardo. The goal is to improve the structure of how function tests are added in to the jaxws test framework the bucket is a mix of unit tests and function tests. We will split that up and introduce a new module which contains the function tests in a more organized framework than exists today. This removes the burden of having to run the unit tests under the JAXWSTest driver. \n",
            "Refactor the ThreadContextMigratorUtil class to use parameters instead of properties. Implementations of the ThreadContextMigrator interface are currently managed using the ThreadContextMigratorUtil class. As these implementations represent static configuration not just runtime it would be better to store them as parameters on the AxisConfiguration. This would also allow us to extend the AxisConfigurationBuilder to recognize ThreadContextMigrators in the axis2.xml file. \n",
            "Request addtional flexibility in Java2WSDL to override the java method to WSDL operation mapping rules Axis2 automatically exclude the following methods in Utils: To add the exclude method when generating scheams here the exclude methods will be session releated axis2 methods public static void { } Is it possible to override this Axis2 maps a java method with void return into an ONEWAY WSDL is it possible to override For a method like: void could prefer to receive an empty response instead of oneway. \n",
            "change JMS tests to not use port 61616 which is the default for Geronimo and ActiveMQ JMS in Geronimo uses port 61616 by default. I have experienced some test failures due to port 61616 in use. I recommend changing the module test cases to use 61654. I googled and didn't find any popular packages that use 61654 by I will attach a patch. \n",
            "Allow pluggable Exception handling in server flow Extend the InvocationListener interface to add a method that will be called anytime exceptions occur in the code. This will allow registered implementations to act on the current exception and possibly map the exception to a different type. \n",
            "Enhance the JAXWSDeployer to configure the runtime to be able to create endpoint references. We need to enhance the JAXWSDeployer the to cache the endpoint URIs that will be used to create an endpoint reference when one isn't explicitly provided by the user. \n",
            "Adding configurable parameter for Metadata Exchange This JIRA is to add configrable parameter for Metadata Exchange function. Following are the two configuration requirements that currently identified: a. Once \"metadataExchange\" module is engaged globally in we need a way to disable GetMetadata request for a service. b. When a GetMetadata request is the element returns multiple units. A MetadatSection could be either the embedded XML an endpoint reference to a Metadata Resource i.e. or a URL i.e. Location element. The spec does not define what output forms: Location or MetadataReference should be returned for a GetMetadata request. MexMessageReceiver just default to generating Metadata Sections for all the 3 possible output forms as stated in the spec. We need a way to configure the Metadata Section content to return for a GetMetadata request. For if there is large amount of large amount of inline xml might not be desirable. The allows to configure only GetMetadata response with Metadata Sections of Metadata Reference and Location instead of actual information. Solution implemented: Adding \"metadataExchange\" element parameter configuration in axis2.xml and allows to support the above configuration needs as well as future needs. Following are the configurables items: enable attribute possible values: \"false\". This is used to disable MEX support for a service. When MexDisabledException will be returned to the sender of GetMetadata request. outputform element contains optional \"dialect\" attribute and required \"forms\" attribute. possible values for \"forms\": not default is and reference. Note that the outputform only avoided unnessary processing in creating Metadata sections for data format that is not needed. As an If the above configuration is added to the this means the GetMetadata response will contain Metadata Sections of actual WSDL and URL for the WSDL and for other dialects such as only Metadata Sections with MetadataReference and Location will be included in the response. The order of precedence for the output form will be similar to the data locator a. dialect specific at service level i.e. configured in services.xml b. service level i.e. without dialect attribute specified c. dialect specific at global level configured in axis2.xml d. service level i.e. without dialect attribute specified e. default output forms to all: reference Summary of code changes: New class: org.apache.axis2.mex.MexDisabledException Modified classes: MexConstants adding constants for configurable items refere in \"metadataExchange\" parameter MexMessageReceiver Access the parameter axis configuration and service configuration Check if MEX is disabled before processing Call instead of default to all 3 output forms. MexUtil: Added APIs: \n",
            "Improved the list information. Improved the subscription and mailing list details in the files in xdocs. \n",
            "InputStreamConfigurator I've been also having problems with the FileBasedConfigurator that looks for the axis2.xml file. Depending on where it is if it is packed in a I won't be able to use it. isn't that great for projects that depend on a project that actually does the Web Service calls using So I created an which is the exact same as the except that it uses the ClassLoader to load the axis2.xml. Is there already something like And if is it something that would be helpful for you Below is the InputStreamConfigurator that I hope it helps: package anything; import java.io.File; import java.io.FileInputStream; import java.io.FileNotFoundException; import java.io.InputStream; import org.apache.axis2.AxisFault; import org.apache.axis2.Constants; import org.apache.axis2.deployment.DeploymentConstants; import org.apache.axis2.deployment.DeploymentEngine; import org.apache.axis2.deployment.FileSystemConfigurator; import org.apache.axis2.description.Parameter; import org.apache.axis2.engine.AxisConfiguration; import org.apache.axis2.engine.AxisConfigurator; import org.apache.commons.logging.Log; import org.apache.commons.logging.LogFactory; public class InputStreamConfigurator extends DeploymentEngine implements AxisConfigurator { private static final Log log LogFactory To check whether need to create a service side or client side private InputStream axis2xml null; private String repoLocation null; Load an AxisConfiguration from the repository directory specified repoLocation axis2xml public InputStream { if { checking wether user has set the system property repoLocation } we've got a repository location in mind. Let's make sure it exists. try { if { File repo new if { save it if so this.repoLocation } } } catch { log find repository location '\" repoLocation this.repoLocation null; } Deal with the config file. If a filename was specified as an arg to this just respect it. if { If check for a system property setting Get from the classloader if it exists axis2xml } this.axis2xml axis2xml; } First create a Deployment use that to create an AxisConfiguration Axis Configuration AxisFault public synchronized AxisConfiguration throws AxisFault { InputStream axis2xmlSream; if null { axis2xmlSream axis2xml; } else { ClassLoader cl axis2xmlSream cl } {throw new can not find the given axis2.xml \" axisConfig Parameter axis2repoPara axisConfig if repoLocation if null || { } else { } return axisConfig; } public void throws AxisFault { } public void { if null || { } } } \n",
            "Update the resource.properties files Updated and removed some of the i18n messages from both kernal and medata bundles. \n",
            "Update OMBuilder interface to handle REST cases REST messages can be serialized in several ways. we currently support the following serialization formats. and In order to build the message on the server side the current OMBuilder interface is not sufficient. This is the current init method. public void String This is not sufficient for some serializations such as and In order to handle we need to parse the URL in adition to the input stream and to handle we need to parse the order to determine the to the init method. I propose updating the init method to public void String String String Keith \n",
            "Permanent JMS Response Queue When using the JMS transport a service client stub specifies a temporary JMS queue as the ReplyTo destination. A useful feature would be to be able to configure a permanent ReplyTo queue for the generated client stub and the service endpoint. In a communication the association would be made through the message id or correlation id. \n",
            "JAXWS Should cache the methods to unnecessary reflection. Currently the EndpointLifecycle manager is performing reflection on the service instance to determine if it has a method with We should do this one time and save the information away in the \"injection description\". I am currently testing a patch. This problem was discovered by David who is part of IBM's performance analysis team. Thanks David \n",
            "Reviewed and made minor corrections to files in xdocs. Reviewed and made minor corrections in the and the pojoguide files. \n",
            "soap over jms Hi I am new to Axis2 and to axis in general. I need to create an Axis2 client starting from the WSDL provided by the server. I have gone through changing the axis2.xml file with the filowing information: and after that I have used the wsdl2java tool to generate the java stub. I have then created a simple client that was using this stub: public class testAxis2JMS { args public static void { TODO method stub try{ String endpointURL \"com.tibco.tibjms.naming.TibjmsInitialContextFactory\" IntfTestWSfromXSDProcessServiceStub stub new Indirizzo ind new Output out : \" : \" } } } } Now when I send the request to the jms server the message is successfully sent. The problem is that the web service that I am calling needs to have some more information on the JMS header sent from my client to the jms server. The jms message sent look like this: Feb 07 17:18:09 CET 2007 The problem is that it should look like this: Feb 08 10:09:16 CET 2007 There are this two properties in the jms message header and that I need to add in order to make the Web Servixce server work. API doesn't support custom JMS properties and I do not have an easy solution. Fabio \n",
            "improve unwrapping option to support non complex data types Currently option workes for complex types only. But the schema that i have attached has to complex types. I guess it might b trivial to improve unwrapping to support this schema. \n",
            "AxisFault is too general AxisFault is too general as exception roughly equivalent to and this makes the debugging very difficult. What about providing more specialized \n",
            "goal not found Problem : When running goal under jdk build is broken with the following message. BUILD FAILED File...... Element... ant:copy Line...... 420 Column.... 47 not found. Json module is excluded from jdk 1.4 build. Regardless of this the build is searching for the json when running the goal. In Copy the json jar \n",
            "Adding utility APIs for Metadata Exchange The patch includes utility APIs and minor bug fixes described below: org.apache.axis2.dataretrieval changes: 1. ServiceData changed from protected to public customized data locator has access to the 2. DataLocatorFactory api changed to public 3. DataRetrievalUtil::convertOMElement throws exception to handle the case when there is no ServiceData.xml to load if null result.length check length for data result array Mex Module added fromOM mehtods to populate java class object from also following convenient and 1. MexUtil new APIs public static Metadata throws MexException{} public static Metadata String throws MexException{ 2. Metadata new APIs public MetadataSection[] dialect public MetadataSection[] String public MetadataSection[] String OutputForm 3. Other misc MetadataReference Added toOM deal with etc. Message Receiver dialet to dialect Sample Usage: Sample usage Please refer java doc for details. Metadata metadata Return all WSDL metadata sections MetadataSection[] sections Return all inline WSDL metadata sections \n",
            "Provide a mechanism to pick up the epr address values from a configuration mechanism for the generated stub Right now we hard code the epr address value in the generated stub code. If we want to change it we will have to use the constructor that takes in the epr value. And this forces the users to implement a mechanism to hold the epr address values in the case where the developed service will move from staging to production environments. It will be great if we can generate the stub in a way where we can provide a config mechanism such a as file and override the epr value. \n",
            "SchemaReader Update I am adding enhancements to SchemaReaderImpl to ensure that we cache the schemas that have been read. This change will increase the performance and ensure that same schema node is not revisited once read. I am also removing the Cicular Dependency check. I am providing the patch for Rich Scheuerle helped design the new Algorithm and the implementation seems to be working as expected. \n",
            "Deployment patches These modifications provide functionality for: propagating exceptions up remote deployment via the method in the repo listener. The remote deployment can be achieved by obtaining the repoListener instance from the WarBasedConfigurator in the and calling after the remotely received file has been copied in the services dir. This allows for immediate feedback but must be syncronized with the Scheduler that is constantly running for Angel \n",
            "Reviewed : Reviewed and made minor corrections to: and in xdocs \n",
            "Improve Spring Integration for Axis2 I wanted to create an application that has tight integration between Axis2 webservices and Spring. There is already a solution presented at the Axis2 but I found that solution very cumbersome in my opinion and doesn't support the JSR 181 annotations. With my proposed approach it is possible to fully integrate the Axis2 with a spring whether it is or in a web server such as Tomcat. This solution also supports both the JSR 181 annotated classes and the regular To fully integrate Axis2 with Spring I have overridden the SimpleAxis2Server class used by the standard A full listing of this class is included in my example application. The important stuff is in line 21 up to 36. First it determines the absolute path of the repository and config location parameters. Then it passes those to the AxisRunner constructor 10 to and starts the server. After it successfully starts the Axis2 server it returns the bean to the Spring Container. After the creation of the bean it will invoke setDeployedWebservices 46 to which will cycle through the passed webservice classes and deploy them at the created That's No additional configuration or packaging is needed. If the Spring container starts so does the Axis2 and the webservices get deployed. The needed configuration in order to integrate Axis2 is quite simple. Below is a complete listing of my applicationContext.xml com.example.poc.webservice.WeatherSpringService With a little bit more effort I think it's also possible to integrate this solution with the Spring component making it possible to annotate the webservice classes and the with I have tested my with Tomcat 6 and Sun Webserver 7. \n",
            "Adding ability for EndpointInterfaceDesc to respect LegacyWebmethod property if set from Manifest.mf. Currently the JAXWS metadata module's EndpointInterfaceDescriptionImpl has the ability to retrieve valid endpoint methods by reading the system property When this system property is set a customer using newer JAXWS apis can still use the applicaton build using older JAXWS apis. I am extending this feature so that a customer can now set the property in a manifest file. If both system property and manifest property are set then the system property will override the value in manifest property. \n",
            "AddressingOutHandler performance improvements We should omit optional headers to avoid unnecessary axiom element serialization. Therefore we should stop sending messageID and noneURI replyTo headers on response messages. \n",
            "AddressingOutHandler performance improvements We should omit optional headers to reduce unnecessary axiom element serialization. Therefore we should stop sending the messageID header and the replyTo header if the address is the NoneURI in response messages. \n",
            "Convert wsamapping parameter into child element of the operation tag Change module.xml into a child element of the mapping is not a parameter of the as much as its a configuration of how messages are routed to the \n",
            "Split the core code into secured classes to make it so that users can't see all the internal stuff Any service write can access complete Axis system by just adding init method in his service class and he can others services we have to provide a way to avoid service authors mess with other services and modules. \n",
            "AxisServlet private fields and methods to protected. To allow maximum code reuse of AxisServlet by extended change all private methods and fields except \"serialVersionUID\" field from private to protected. thx \n",
            "UnsignedLong would be improved by implementing the Comparable interface All elements inserted into the set must implement the Comparable interface. Workaround is to use org.apache.axis.types.UnsignedLong \n",
            "Modified installation guide maven images to relate to maven1.x replaced imgaes dir in to maven 1.0.2. also changed links of maven to maven 1.x in installation guide \n",
            "To Add remote address to the message context in AXIS2 The remote Address is not being set in the messageContext in this will be required to identify the client address. Axis1's AxisServlet in the HttpServletRequest HttpServletResponse method This is how it is set. This needs to be added in Axis2 inside the createAndSetInitialParamsToMsgCtxt method. the constant var is not there in the MessageContext.java file. Can someone please \n",
            "java.lang.ArrayIndexOutOfBoundsException in MTOM Example I'm trying to use the MTOM imagetransfer example. Everything works fine when I use small images When I try to send larger files kb and there is an java.lang.ArrayIndexOutOfBoundsException. \n",
            "made corrections to of Axis2 0.94. Review apply patch made improvements on newly included http version management section in apply patch \n",
            "more migration guide docs for modules On the mailing list a little while back I agreed to do some documentation for the migration guide. I started with modules. I plan on doing data binding next. Please review and apply patch uploaded in next email. \n",
            "Remove unused hostConfiguration from axis2.xml There is an element called in axis2.xml and nobody is using that so its better to remove that. \n",
            "wsdl2java fails with CodeGenerationException NullPointerException wsdl2java books.wsdl Exception in thread \"main\" org.apache.axis2.wsdl.codegen.CodeGenerationException : java.lang.RuntimeException: org.apache.axis2.schema.SchemaCompilationException : java.lang.NullPointerException at at at Caused by: java.lang.RuntimeException: org.apache.axis2.schema.SchemaCompilation Exception: java.lang.NullPointerException at at ... 2 more Caused by: org.apache.axis2.schema.SchemaCompilationException: java.lang.NullPoi nterException at at at at at ... 3 more Caused by: java.lang.NullPointerException at at at ... 7 more \n",
            "Axis2 Code Generator for Eclipse generates code that does not quote SOAPAction in HTTP Header and thus is not complient. According to the Basic Profile the value of SOAPAction in the HTTP must be quoted and the reciver may respond with a fault if it is not. The stub code generated by the Eclipse Plugin from the WSDL does not do this. It could be argued that such quoting should be done in the core of AXIS2 not just the but there may be other issues at that level I am not aware of. At a minimum the tool should do this for HTTP bindings as its users are least likely to be aware of this sort of issue. Extract from Profile... \"R2744 A HTTP request MESSAGE MUST contain a SOAPAction HTTP header field with a quoted value equal to the value of the soapAction attribute of if present in the corresponding WSDL description. \" \"R2745 A HTTP request MESSAGE MUST contain a SOAPAction HTTP header field with a quoted empty string if in the corresponding WSDL the soapAction of soapbind:operation is either not or present with an empty string as its value. \" \"R1119 A RECEIVER MAY respond with a fault if the value of the SOAPAction HTTP header field in a message is not quoted. \" \n",
            "Remove unused HostConfiguration element from axis2.xml There is an element called in axis2.xml and nobody is using that so its better to remove that. \n",
            "Remove setting of default chains and message receivers in default constructor of AxisConfiguration Remove setting of default chains and message receivers in default constructor of ConfigurationContext .. in that case there's no need to put any defaults because the user is taking over and doing their own thing anyway. \n",
            "Issue with client embeddability and you can only create an Axis2 client that supports if you also create new directories on the client and set to point to this repository. I think this affects embedability. It would be great if we could simply pop a module into the classpath. Obviously this isn't much of an issue on the but for the client it would make it much easier to embed into other projects. One proposal on how to do that is to create a new module archiving model and use the Java JAR file Service Provider spec. We could use this with a new pair called o.a.a.m.ModuleInfo { public String } Suppose the module was called Then the existing loader could look for in other words the MAR format pushed down one level based on the module name. Now this could simply be in a JAR called and the SP stuff would identify the name and version and where to look for it. This does leave a problem with the remote URL repository. We could maybe figure out how the JAR SP code works and replicate that for a URL based thereby using the same mechanism in both cases. \n",
            "ADB base64Binary handling I noticed that the code generated from ADB converts binary data back and forth in the case of Base64Binary schema type MTOM optimised contents.. AFA i understood this behaviour leads Axis2 to read the Binary data in MIME parts and converts them to Base64binary and then once again converts that Base64String to bytes... This behaviour is can lead to serious memory issues and this will be a limiting factor for code generated services to handle large binary attachments.... IMHO use of DataHandlers directly rather than encoding binary back and forth is the correct way to go.. This is what we are doing in the OMTextImpl... In that case if data came as an then it won't undergo any conversions.. If they came in line as Base64 then they will decode to binary... We can either change the methods to use DataHandlers instead of byte[]. Or we can keep them as it is by getting and setting byte[] internally to data handler... \n",
            "Axis2 should be able to start a server without needing the WSDL Serving up WSDL from an endpoint is an entirely optional feature of SOAP. If I choose not to do the endpoint is still valid. But Axis2 will fail if it cannot get the WSDL. if there is no configuration pointing to the WSDL it tries to create an AxisService instance using for some with a dependency on both and Axis2 could maybe warn that there is no but it should not be necessary either to have on the classpath for or to serve up WSDL at an endpoint. This is the stack trace if wsdl4j is absent: Caused by: java.lang.NoClassDefFoundError: at at at at at at at at at at at at at at at at \n",
            "Ability to override hostname and port in EPRs Add a parameter to transports that allow the that is used in EPRs to be overridden. For if I am on a server behind a the will reply something like but the real addressable name may be www.company.com. Similarly with a I may have a ADSL NAT router in front of my so my machine's IP is called but the addressable IP is myserver.dyndns.org. So we need to be able to configure transports. Similarly the port maybe so that also needs the ability to override. \n",
            "Axis2 should not open an inbound http port by default When Axis2 starts up the they open up an http listener by default. This may be what people want if they are doing fully async but if they are not the majority of SOAP users are then it is just another security risk to be managed. 1. the listener should be off by default. 2. some kind of switch can turn it on when or even when bidirectional async messaging starts up. \n",
            "made correction on axis2 0.94 release date. apply patch axis2 0.94 release year was corrected from 2005 to 2006 on index.html in xdocs \n",
            "Improving client side REST handling RestSender has to be modified to handle REST support. \n",
            "Remove unnecessary fields from headers For on a there is usually no need to include a unless there is a session using RefPrs. \n",
            "The wsdl doesn't compile under ADB option Wsdl2java [Axis2 0.94 release] throws NullPointerException when it runs against the wsdl at with ADB option. The command that generates the exception: wsdl2java mtomecho.wsdl It generates the same message with the wsdl link: wsdl2java adb Note that the commands with both option xmlbeans\" and option none\" are fine. mtomecho.wsdl Using Using Exception in thread \"main\" org.apache.axis2.wsdl.codegen.CodeGenerationException java.lang.RuntimeException: org.apache.axis2.schema.SchemaCompilationException java.lang.NullPointerException at org.apache.axis2.wsdl.codegen.CodeGenerationEngine.generate at at Caused by: java.lang.RuntimeException: org.apache.axis2.schema.SchemaCompilation Exception: java.lang.NullPointerException at org.apache.axis2.wsdl.codegen.extension.SimpleDBExtension.engage at org.apache.axis2.wsdl.codegen.CodeGenerationEngine.generate ... 2 more Caused by: org.apache.axis2.schema.SchemaCompilationException: java.lang.NullPoi nterException at JavaBeanWriter.ja at SchemaCompiler.ja at SchemaCompiler.java:19 at SchemaCompiler.java:14 at org.apache.axis2.wsdl.codegen.extension.SimpleDBExtension.engage ... 3 more Caused by: java.lang.NullPointerException at org.apache.axis2.schema.writer.JavaBeanWriter.getBeanElement at org.apache.axis2.schema.writer.JavaBeanWriter.process at JavaBeanWriter.ja ... 7 more \n",
            "Corrected some erroneous HTML tags in Axis2 dir. Apply patch HTML tag errors were fixed in docs in the Apply patch. \n",
            "more migration guide docs for databinding Here's my contribution for the databinding migration of axis 1.x to axis2 . Please review and apply. Patch will be attached on next comment. \n",
            "Make EJBUtil aware We found that we had problems integrating Axis2 with WebLogic in that we couldn't any of the EJB receiver code apparently because the security established at InitialContext creation was then lost when org.apache.axis2.rpc.receivers.ejb.EJBUtil.EJBClientWorker invoked its run method in a separate thread for the EJB causing a WebLogic security error invoking the service. We checked with Oracle and they feel it's most likely that the separate threads are the cause as WLS doesn't subjects across threads. Thus the second thread that does the actual invocation of the service doesn't have the authentication done in the first thread when the InitialContext is which is successfully validated by our login module. We coded our own receiver to avoid this additional threading—essentially duplicating the Axis2 functionality. I've been told that for EJB environments that threading should not be leaving it to the container environment to manage. Had confirmation from Martin Gainty and request to open this JIRA case: \" yep the statics of EJBUtil will not work in a environment as seen here public class EJBUtil { public static final java.lang.String \"beanJndiName\"; \" \n",
            "Axis2 site redesign Axis2 Confluence space and Confluence exported site needs improvement. \n",
            "Clean up metadata resources.properties file Remove unused keys from the metadata resources.properties file. Correct several improper calls to in jaxws and metadata code. \n",
            "hidden dead code in org.apache.axis2.context.ConfigurationContext In org.apache.axis2.context.ConfigurationContext are the following lines: else if { the session String serviceGroupContextId if { serviceGroupContext if { TODO: Adding this code so that requests to services deployed in soapsession scope will work TODO: soapsession functionality is still broken serviceGroupContext new throw new to find corresponding context\" \" for the serviceGroupId: \" } } The code tries to get a ServiceGroupContext through This method throws an if it can't find an so if can never be true. On a side note: the dead code would behave completely different than Axis does at the because it would create a new ServiceGroupContext with the given id instead of throwing a fault and rejecting a request with a serviceGroupId. \n",
            "Comply with 2.2: do not send response when Provider returns null The 2.2 section states that when a Provider invoke method returns it is considered that no response needs to be sent by the service. Currently in the runtime there is no way for a Provider which does not specify a WSDL file to act like a operation an operation that does not return a SOAP but instead responds with an HTTP The current behavior of a web service Provider which does not specify a WSDL file is to always return a response. In the case where the Provider returns the response consists of a SOAPEnvelope which contains a SOAPBody that is empty. The following is an example of a Provider which returns null and does not have a WSDL file: public class HelloProvider implements { public Source { return null; } } The invocation of the following SOAP response: The desired behavior is for the invocation to return no SOAP response. \n",
            "Support an option to allow invalid xml characters to be removed from an outbound JAXB serialization Background: The engine uses JAXB data objects. The JAXB data objects are marshaled to xml using a JAXB provided Marshaler. The Marshaler writes information to an XMLStreamWriter will be the axiom provided Problem: If a customer populates the JAXB bean with characters the JAXB Marshaler will write the illegal characters without errors. However the SOAP node receiving the message will fail. Solution: Provide a property that a customer can set the to recognize and remove illegal characters. This solution will have an axiom and axis2 contribution. \n",
            "Securing passwords in axis2.xml Currently the password in the axis2 configuration are plain text . This can be a security hole. \n",
            "Turn on WSDL 2.0 validation which is turned off by default WSDL 2.0 validation is turned off by default in Woden. It'll be good if we can turn this on. I will check this into trunk. Thanks Chathura for pointing this out. Deepal can we check this into the 1.3 branch \n",
            "Add new phase to add all the addressing handlers It is nice to have a phase to add all the addressing handlers rather than adding them to PreDispatch phase \n",
            "using HTTPSListener when configuring transports per service org.apache.axis2.transport.http.HTTPSListener defined in org.apache.axis2.transport.http.ListingAgent should be declared public and not private as it is rith now.Furthure the port parameter that comes from axis2.xml should be taken into account in the init method in order to set the port memeber the the scheme member i think it can be hardcoded to \"https\" \n",
            "Make SOAP 1.2 bindings as they break older Axis 1 clients We're trying to create some Axis 2 services which are usable by other clients .NET and Axis At we had problems due to but upgrading to Axis 2 fixed that. the WSDL is still unreadable to the Axis 1 client because of the SOAP 1.2 bindings which are also present in the file: java.io.IOException: ERROR: Missing element inFault \"XMLStreamException\" in operation in binding sayHello The attached patch adds a configuration option to disable generation of these bindings. \n",
            "Set header fields of JMS message I need to set the two JMS message header fields and I achieved to set the content type with: Options options Shouldn't this also be possible for the Mime I read the workaround proposed by you to replace the JMSSender class by a copy where these two properties are set with a string property in the class but this is not an option for me. Dominik \n",
            "AntCodegenTask doesn't allow to specify external binding customization when using Ant task for generating Java code from WSDL doesn't allow to specify external binding customization files for data binding. When generating Java classes from XSD documents using XJC such feature is available. \n",
            "Add a default log4j.properties file to Axis2 distrubution when running tools Axis2 distrubution does not add an log4j.properties file into classpath when running tools. So some of the info message are not shown to the user. this is the case in running the simple http server as well. \n",
            "Some improvements to 2.0 support for WSDL2Java This patch provide improvements to the following areas 1. Usage of Holder Class for the method parameters 2. Usage of annotations in the generated SEI. Thanks Sameera \n",
            "Jaxbri supports unwrapping I have introduced some code blocks to \"org.apache.axis2.jaxbri.CodeGenerationUtility\" class which will make jaxbri to support unwrapping of schema elements. This is really an essential feature for implementing wrapper style mapping of method parameters in When generating Therefore I would really appreciate if this patch can be committed to the trunk early. Thanks Sameera. \n",
            "[PATCH] Upgrades 'Simple' HTTP and NIO HTTP transports to HttpCore There has been a number of improvements and bug fixes Axis2 'simple' and NIO HTTP transports should pick up [1]. I am attaching a patch that upgrades Axis2 to the latest HttpCore API. All test cases pass for me. Oleg [1] \n",
            "Change default http protocol to 1.0 from 1.1 When a new client it generated with the WSDL2Java tool the base http protocol is 1.1. Not all web servers implement the http 1.1 protocol and it is very difficult to debug the problem. A client will send the but then in our the server would not even register that a request was made. apache access logs never showed the A very difficult problem to debug. We actually had to place a network sniffer on our testing machines to see the request being sent from our client and only lucked into seeing somewhere that we could change the protocol setting and tried it. I would think that a product like Axis2 would be built out of the box to work with the lowest common denominator. Which in this case is the http 1.0 protocol. Then allow the end users to upgrade the protocol as needed. From my understanding almost all web servers are backwards compatible with the http 1.0 so why not use it as the default Thank you for your time. \n",
            "MessageContext Persistence Performance Improvement MessageContext Persistence Performance Improvement Background: When a MessageContext is persisted reliable the MessageContext object and associated objects are written out to the ObjectOutput. When a MessageContext is hydrated it is read from an InputObject. The utility provides static utility functions to provide safety mechanisms to write and read the data. Problem: The IBM performance team has profiled this code. They found that the writing and reading of these objects is time consuming. Some of the performance penalties are due to the use of static methods hindering the ability to reuse byte Other penalties are due to the way that we determine if an object can be \"safely written\". This JIRA issue addresses a number of these concerns. Scope of Changes These changes only amend the existing writeExternal and readExternal support. There is no impact on any code that does not use these methods. No additional logic api's are added or changed. Specific Concerns and Solutions: The original logic writes objects into a buffer. If a serialization error the algorithm safely accommodates the error. The downside is that it is very expensive to write each object to a temporary buffer. Solution: A new marker is introduced. If an object has this marker interface or is a lang wrapper object then the object is written directly to the ObjectOutput. Eliminating the extra buffer write increases throughput. A similar change is made to the read algorithm. The new algorithm detects whether the object was written directly or whether it was written as a byte buffer. In the case where it is written no extra buffering is needed when reading. If a buffer is needed to write or read an the ObjectStateUtils class creates a new buffer. This excessive allocation of buffers and subsequent garbage collection can hinder performance. Solution: The code is to use two new classes: SafeObjectOutputStream and SafeObjectInputStream. These classes wrap the ObjectOutput and ObjectInput objects and provide similar logic as ObjectStateUtils. The key difference is that these are not static utility classes. Therefore any buffers used during writing or reading can are reused for the life of the object. In one series of this reduced the number of buffers from 40 to 2 for persisting a MessageContext. When an outbound MessageContext is its associated inbound MessageContext is also persisted. The problem is that the inbound MessageContext may have a large message. Writing out this message can impact performance and in some cases causes logic errors. Solution: Any code that hydrates an outbound MessageContext should never need the message associated with the inbound MessageContext. The solution is to not persist the inbound message. In the current \"marker\" strings are persisted along with the data. These marker strings may contain a lengthy correlation id. This extra information can impact performance and file size. Solution: I reduced the number of \"marker\" strings. The remaining marker strings are changed to the \"common name\" of the object being persisted. In most the log correlation id is no longer present in the marker string. In I made changes to only create a log correlation id \"on demand\". The log correlation code uses the UUIDGenerator. Creating the log correlation id \"on demand\" limits unnecessary locking. Miscellaneous. I spent time fine tuning the algorithmic logic in SafeObjectInputStream and SafeObjectOutputStream to eliminate extra buffers ByteArrayOutputStream These are all localized changes. Other Related Changes The externalize related code is refactored so that all lives in the new org.apache.axis2.context.externalize package. The ObjectStateUtils class is retained for legacy reasons. I didn't want to remove any api's. The implementation of ObjectStatUtils is changed to delegate to the new classes. New tests are added. I added classes DebugOutputObjectStream and DebugObjectInputStream. These classes are installed when is true. The classes log all method calls to and from the underlying ObjectOutput and ObjectInput; thus they are helpful in debugging errors. Andy Gatford has provided code that uses the context classloader when reading persisted data. The high level logic used to write and read the objects is generally the same. The implementation of the algorithms is In some this required changes to the format of the persisted data. An example is that each object is preceded by a boolean that indicates whether the object was written directly or written into a byte buffer. I increased the revision id because I changed the format. Kudos Much thanks to the following people who contributed to this helped with helped with testing or provided performance profiles: Ann Andy Dan Doug and Richard Slade. Next Steps I am attaching the patch to this JIRA. I will be committing the patch in the next day or two. Please let me know if you have any questions or concerns. Thanks Rich Scheuerle \n",
            "Allow file based override for MetadataFactoryRegistry Currently the MetadataFactoryRegistry can only be utilized programatically. This allows for consumers of MDQ to call the factory to register custom and it also allows for the static initialization overrides that take place in the registry now. We can also allow for a file based override. The MetadataFactoryRegistry will be updated to read a file that contains a list of interfaces and overrides. It will then register these and these overrides will take precedence over the static overrides in the initialization code. \n",
            "How to enable Fast Infoset is not documented How to enable Fast Infoset is documented. Can some one please add the following text to the relevant area of the How to enable Fast Infoset In the \"axis2.xml\" under the section \"messageFormatters\" add the following Message POX Message Formatter SOAP Message Formatter Under the section \"messageBuilders\" add the following Message Builder. POX Message Builder SOAP Message Builder If you want to use SOAP set the content type of the message to and if you want to use POX set the content type to of the message to \n",
            "Plug MDQ deployment into Axis2 deployment model Currently the metadata processing for JAXWS the creation of the metadata description hierachy based on annotations and is not integrated into the Axis2 deployment model. The JAXWS unit tests are using a deprecated factory method which builds the desription hierarchy when an inbound request for a service is received. The deprecated method is called from EndpointController.getEndpointDescription. This deprecated method causes obsolete code paths to be executed and does not go down code paths that are used for actual server integration. Actual server integration example in plugs the JAXWS metadata processing into the server's deployment logic. This is done by creating DescriptionBuilderComposite objects and using those DBCs to create the description hierarchy. The processes of creating the JAXWS descrition hierachy also creates the Axis2 description hierachy AxisService and based on annotations I think the following needs to be done: 1. Add a plug point in the Axis2 deployment logic that allows plugging in to the deployment or perhaps overridding it completely 2. In the JAXWS tests require a running the plugpoint or override would create the JAXWS and associated Axis2 description hierachy during application deployment. 3. The logic in EndpointController.getEndpointDescription should change to consider not finding the JAXWS description hierachy an error and reject the inbound request. The deprecated method should be removed. 4. Note that there is a convenience method that will take an implementation class and create the DBCs using relfection which may be helpful. \n",
            "No access to the operationContextMap in the ConfigurationContext class I'm upgrading my existing code based on axis 1.1 to the 1.3 version and I get a following problem: I used the method to check if the map is empty or still has any registered operation contexts. I use that e.g. during the application shutdown to if some service calls are still running if using non blocking In 1.3 version the operationContextMap has only private so i can't check if it is empty or not. So i would like to have something like method in the ConfigurationContext class. If there is another way to the information I please let me now. regards \n",
            "There is no reason for HTTPSListener to be inner class org.apache.axis2.transport.httpHTTPSListener is innerr class for org.apache.axis2.transport.httpListingAgent. Therefore it must be instantiated diffrently using reflection in AxisConfigBuilder.processTransportReceivers in case we need it as TransportReceiver....instead of changing the implementation of the inner class just have to be removed from Listing defined as a normal java class in the same package...i can provide patch if this is acepted...i personally see no reason for the class to be inner \n",
            "Axis2 JAVA2WSDL need to convert the javadoc into wsdl documentation. This is related to POJO scenario. This would be an nice to have a feature. I am not exactly sure about the possibility of obtaining the javadoc from the compiled we need to figure out that its possible to compile the source preserving Anyway if we include annotations in the method signature then we can definitely include that in the relevant place in the wsdl as documentation. \n",
            "Add log statements to jaxws msg util classes Added some trace statements to jaxws message util class to get a more meaningful trace information during problem determination. \n",
            "Consolidate functionality of org.apache.axis2.saaj.util.SAAJUtil and org.apache.axis2.jaxws.message.util.SAAJConverter Both org.apache.axis2.saaj.util.SAAJUtil and org.apache.axis2.jaxws.message.util.SAAJConverter provides the ability to convert between SAAJ and OM Constructed elements the consolidation of twos should be considered. \n",
            "Performance Changes related to property migration code Mike Rheinheimer and I are contributing 2 performance changes. Both are related to the application property migrator code. Problem: The code that migrates properties to and from the MEPContext is too slow. Solution: The solution is twofold. there are synchronized locks in ApplicationMigratorUtils that are span too much code. This will be recoded. the code in MEPContext that gets the application scoped properties is using too many temporary maps. Instead the code should iterator over the objects. \n",
            "Add Clarification To Axis 2 Eclipse Plug In Installation instructions page It would be extremely helpful to avoid further confusion if you could state clearly on the webpage detailing installation instructions for the Eclipse that you require the Eclipse IDE for Java EE developers to be installed. I've just spent 2 days trying to figure out why this was not working on my normal Eclipse installation and only discovered the answer while trawling through the mailing list archives. Relevant webpage: \n",
            "Runtime processing and schema generation is not consistent for java.util.List Axis2 generate schema for java.util.List correctly and it's identical to Array schema but run time expect additional wrapping element for lists. The impact is client generated from above WSDL file is not usable with the service hence this need to be changed. It is possible to use same Schema for both Lists and Arrays and return instances depend on actual service method signature. \n",
            "Provide support for complex object types. It is not possible to pass complex type objects via a web service invocation. The following error is thrown while attempting to do so. [ERROR] Exception occurred while trying to invoke service method echoArray org.apache.axis2.AxisFault: Unknow type at at at at at at at at at at at at at at at at at at \n",
            "Configuration guide should clearly state the root elements and locations for axis2.xml services.xml and module.xml I had a bit of difficulty figuring out that the root element of axis.xml was This should be clearly stated in I also think the documentation should also state where to find said file. The same goes for the other two files mentioned in the title. \n",
            "Fixing an issue in WSDL generation for the services exposed only in local transport The relevant discussion on can be found here [1]. [1] \n",
            "wsdl2java generated exceptions do not display the received fault messages if created with constructor without parameters if received and thrown in If the exceptions generated from are used with the constructor without then they just contain as a exception message the name of the class and ignore the complete content of the even if there is much more information available. This is especially problem in where wsdl2java generates the received exception instantiation with what leads to the fact in stub is effectively no exception message available. for example in the results normally the stacktrace of some exceltion ExceptionClassName with exception message is shown without any You have always to go into the debugger and figure out what is the real fault behind the exception messsage \"ExceptionClassName\" is. This is very time consuming. one can take the exception generated by Axis and extend but then if the wsdl it has to be etc. etc. my proposal is to override in the generated exception the method by something similar to: public String { String locMessage if null null null || { locMessage } return locMessage; } where getXXXXFaultMessageContent is the name of the access method to fault generated according to the name convention already used in the wsdl2java tool. With similar construct there would be no necessity to change the generated code and would be very helpful for the default usage of the Axis2 tools. \n",
            "Confused by the logic of so rewrote it The logic of the FileSystemConfigurator confused the hell out of so I ended up with modified code. Semantics should be the same except possibly for edge cases. Explicit handling of relative paths. May or may not be useful. \n",
            "XmlOptions used to serialize a message in a generated Stub are not accessible I use the Axis2 wsdl2java generator with the following options: MyTest.wsdl Test xmlbeans In the generated stub the function creates XmlOptions to serialize the message: org.apache.xmlbeans.XmlOptions xmlOptions new As a consequence XmlOption used while instantiating the param element are not taken into account. In particular if we specify the use of default namespace as follows: org.apache.xmlbeans.XmlOptions xmlOptions new RequestDocument query RequestDocument Would it be possible to either keep the XmlOptions as an attribute of the XmlObject or provide a method to pass XmlOptions to the client stub for reuse while serializing the messages. \n",
            "Provide support for complex type arrays. An array with complex type objects cannot be invoked via webservice. Sample POJO service is as follows. public class ArrayTest { public Object [] Object [] array { return array; } } \n",
            "wsdl2java Stub generation should be optimized to allow better customization of exception mappings The Stub generates the processing methods with the help of the internal variables for exception mappings to keep the fault mapping private java.util.HashMap faultExceptionNameMap new private java.util.HashMap faultExceptionClassNameMap new private java.util.HashMap faultMessageMap new which are populate in private method populateFaults. All internal access to the internal mappings is done through the direct call of the methods of the given like: it makes to the user of the generated classes impossible to define some own exception mappings without the change of the generated so after the regeneration it has to be again etc. a lot of unnecessary work. Also the split of the data into three lists is not very systematic. Solution for this would be to define the hiding the concrete implementation of the retrieving of the meppings and use them everywhere instead of calling the methods of faultExceptionClassNameMap and faultMessageMap directly. They could be created similary to following proposal: protected boolean protected String protected String protected String The default implementation could simply hide the same maps into the given but everybody could redefine the methods in inherited stub class without the necessity to change the generated class and append some own which could be also inherited from the generated one. This would be with a small amount of work a great improvement the possibility to use the generated stub classes without modifications. because of the impossibility to redefine simply the exception nobody can see the fault messages by the faults thrown in client the issue \n",
            "JAXWS: Add Support with Attachments For and the customer's SOAPMessage may contain AttachmentParts. These AttachmentParts may be MTOM or SWA style. Major Changes: The MessageUtils class contains methods to \"get Message from an Axis2 MessageContext\" and \"put Message onto a n Axis2 MessageContext\". These methods are upgraded to handle both MTOM and SWA Attachments. The ProviderDispatcher is upgraded to inspect the binding to determine whether to enable MTOM on the Axis2 MessageContext.. This is similar to the code already present in JavaDispatcher. Added code to the JAXBAttachmentMarshaller to handle SWA Attachments don't have a test for Added tests for 4 cases: xml only xml and mtom xml and swa xml and swa \n",
            "Proper error message should be given and user should be returned to the options list when providing invalid option in ServiceLifeCycle client Currently system just returns an exception when user provides a wrong option in Library client of ServiceLifeCycle sample. Please return a proper error message and provide user with the options list again when enters a wrong option. \n",
            "calculate defaults in case of missing WebFault annotation attributes calculate defaults in case of missing WebFault annotation attributes. The WebFault annotation is required to be present on a generated Exception but is not required to have any attributes. we should try to calculate defaults. \n",
            "Problems in generated CallbackHandler in client side When I generate client side code it generates a CallbackHandler abstract class but the issue with that is it does not have any abstract methods. So I think we should generate that class with abstract methods then user can easily understand what he needs to do. Sample CallBackHandler class is attached below; public abstract class DateServerCallbackHandler { protected Object clientData; public { this.clientData clientData; } public { this.clientData null; } public Object { return clientData; } public void com.mydomain.service.xsd.DateServerStub.GetDatesResponse { } public void { } } \n",
            "Editorial Review Fixed a few formatting issues and grammatical errors \n",
            "JMS destination should not be dedicated to only a single service I'm creating this issue to address the improvements of JMS destination usage discussed in the [1]. Here is the summary: Requirements A single destination can be used for messages of different services Multiple destinations can be used for messages of the same service Proposal At client side: Including the service name in the EPR Adding service name to the JMS message header before sending it same approach used for transferring At service side: Setting \"to\" field of the MC to the value of service name field retrieved from JMS message header. Setting \"soapAction\" field of the MC to the value of SOAPAction field retrieved from JMS message header is already done with the current Advantages of the proposal Being more consistent with the other as all of them include service name to EPR No need for an association between destination and thus no need association in services.xml Being able to use a single destination for multiple services Being able to dispatch messages come from different destionations to the same service [1] \n",
            "Attachment optimization using JAXWS SOAP Binding properties for MTOM Per current JAXWS client can only enable attachment optimization by setting the ENABLEMTOM variable to \"true\" using the method in the SOAPBinding API. This enhancement will give client an alternate way to enable optimization just by specifying the SOAP Binding properties for MTOM as the binding protocol. using Dispatch invocation for JAXWS client can only enable attachment optimization by doing the { SOAPBinding binding } With this JAXWS client can also enable optimization just by specifying the SOAP binding property for MTOM { } \n",
            "Add MethodMarshaller support With Rich's RPC updates to the Message we now need the MethodMarshaller support to go along with that. \n",
            "Performance Pooling The following changes will be made: JAXB Pooling Optimization JAXBContext objects are now pooled in a WeakHashMap. JAXB Advanced Pooling Optimization: Added code to pool JAXB and JAXBIntrospector. Pooling is initially disabled for these objects until we get more information from the IBM performance team. To enable the set MTOM Travesal Optimization Changed the MTOM traversal code to use the more performant OMNavigator utility. Pooling Optimization: Refactored this code to use OM StAXUtils. OM StAXUtils contains code to pool these objects. closing: Scrubbed jaxws component and added calls where appropriate. Servicability: Additional servicability is added to identify why a message is consumed. The \"Message is already consumed\" error is changed to advise the user to run with debug. Running with debug will highlight the place in the code where the message is first consumed...which will greatly aid in error detection. Added more trace \n",
            "Editorial Review Fixed some minor formatting issues and grammatical errors \n",
            "WSDL2Java: option works different for WSDL 1.1 and 2.0 If using a WSDL 1.1 the option can point to local e.g. wsdl2java xxx.wsdl 1.1 wsdl2java 1.1 This does not work if using WSDL 2.0 documents. In this it seems like the WSDL document must be loaded from a HTTP server. wsdl2java xxx.wsdl 2.0 wsdl2java 2.0 wsdl2java 2.0 \n",
            "Suggestions to improve Axis2 Web site I have a few important suggestions to improve the site through which we can convey more accurate information at a glance Web browser Title in Axis2 site Website browser title currently reads as Axis 2.0 Isn't it best it reads as Java as this site is specific to Axis2 Java implementation although it is not mentioned in the URL. Also using 'Axis2' instead of 'Axis 2.0' is more consistent. Wiki link Axis2 wiki link should be added to the main navigation bar under 'Project Information' as it is not been linked from the docs index page. Better have it on the navigation menu bar as it is common to all releases. Adding Java As is specific may be we would want to point out this fact in one glance as in site Why don't we add 'Welcome to Apache and also on the top of the main navigation menu bar we can have Java' instead of 'Axis 2.0' So if you think these suggestions are worthy then it'll be great if we can include these with Axis2 1.1 release on the web site Chatra \n",
            "SOAPMessage MimeHeader support Added code and test to send support SOAPMessage MimeHeaders for and I will commit shortly. rich \n",
            "Improvement to the DBC processing Fixed several and added callback for invoking the WSDL Generator \n",
            "Parameter of type object is always passed as javax.activation.DataHandler If a POJO web service method has a parameter of type the actual parameter passed to this method is always of type javax.activation.DataHandler. If the parameter element in the SOAP request contains an xsi:type that attribute should be used to determine the type of object to create to pass to the parameter. For in the following the type xsd:Value should be used to create the parameter param0 type xsd:Value is defined in the \n",
            "Some MTOMPolicy module improvements are not merged to Axis2 1.5 branch Some of the improvements done on the Axis2 trunk after branching are not merged to Axis2 1.5 branch. \n",
            "Performance Imporvement when using I am making a small change to improve performance when a is used by an application. Currently when a message block is represented by we are expanding OM before we this change is to avoid OM Expansion and directly serialize the xml represented by OM into an Output Stream there by improving the performance and avioding un necessary expansion of OM. \n",
            "Please allow timezones other than UTC when formatting dates If a method returns a java.util.Date or an object with a java.util.Date the date is always converted to UTC before formatting as a string. It would be nice if it could be specified to return dates in the local timezone since dates are represented in the local timezone everywhere else in the application. \n",
            "WSDL2Java doesn't support For the default and fixed constraints are defined here: Consider the following XML schema definitions: ADB code generated for the ResultCode element is correct in setting the default value of the code field to 0: protected long localCode ADB code generated for the SuccessCode element is incorrect according to XSD definition for the fixed element. It actually appears to completely ignore the fixed attribute. Considering the XSD definition for the fixed I think the generated code should declare the code field as final and set the final value as follows: protected final long localCode It follows that the generated code should not contain a setter method for the code field. \n",
            "Is it possible to I've added some comments Added one possible suggestion to resolve the although others were mentioned in the comments of as well. \n",
            "Please make RPCMessageReceiver and related classes more flexible RPCMessageReceiver calls a number of static that call other static and private methods. Many of these methods are also very long. This makes it near impossible to customize RPCMessageReceiver via inheritance. This situation would be improved a lot by this: Change static methods in SimpleTypeMapper etc. to instance methods Allow subtypes to be used instead of each of those classes example by creating instances in factory methods that may be \n",
            "Add some tolerance to I currently try to use a given web service which returns \"inconsistent\" responses concerning the encoding setup: The HTTP header is set and claims to head an but the XML content itself claims to be of As far as I can see this causes my Axis2 1.4.1 client based on xmlbeans to throw the following exception: org.apache.axis2.AxisFault: Character Set Encoding from transport information does not match with character set encoding in the received SOAP message at at at at at at at at at [...] The response itself looks like: 200 200 \"Date: 16 Jun 2009 15:02:40 \"Server: Servlet 2.4; \"l in is not allowed in extracted from logs generated by \"org.apache.commons.httpclient.Wire Formally thats but in real world it is all about and that is: about as far as its clear what is \"meant\". Thus it would be nice to be able to deliberately \"weaken\" the validation process especially for the encoding: It should be possible to switch of the check of XML encoding setup against HTTP header encoding setup and instead simply use the XML encoding setup. Especially if a given remote service must be the client code implementer has no influence on what the service returns she simply has to arrange her code to match the given service. And in my this simply seems impossible with the released Axis2 1.4.1 client code. \n",
            "Improve the ListenerManager startup behavior ListenerManager should initialize all the listeners while initializing the listener and starting of the ListenerManager should start the listeners. for synapse requirements we need to get rid of the shutdown hook and there has to be an option to not to set the shutdown hook while starting the listener manager. this is required in the 1.5 release because synapse 1.3 is going to depend on the 1.5 release of axis2. \n",
            "provide more performant way to manipulate SOAP headers in handlers I have an improvement I'd like to commit. Background: handlers can retrieve and manipulate SOAP headers if they wish. this is a relatively expensive considering the transformation of the underlying message OM data from Axiom to SAAJ spec requires but for efficiency implentation uses Axiom under the Proposal: Allow handler implementations to retrieve and manipulate SOAP headers by allowing them to retrieve headers off the MessageContext parameter passed into them. The patch is trivial to enable this support. Writing tests was the big effort in putting this together. See patch. \n",
            "Please add support for loading type table when service is deployed with wsdl file When a service is deployed with a wsdl the type table in the AxisService doesn't get populated like it does when the wsdl is generated at runtime. The type table is used to populate xsi:type so the lack of type table means that the xsi:type attributes are not generated. It should be easy to move the already existing code for loading a type table in DefaultSchemaGenerator.loadMappingFile so that it could be used during service startup. Java2wsdl might also be modified to produce a suitable file for this. \n",
            "Upgrade CommonsHTTPTransportSender to use httpclient 4.0 3 areas currently using 3.1: 1. The code that interfaces between Axis2 and the underlying e.g. the Stub class. This code only refers to org.apache.commons.httpclient.Header and could easily be made independent of This is what the patch in does. 2. MultipartFormDataFormatter uses code from to build requests. Maybe this code should be rewritten to use HttpMime [1] mime4j. 3. The code in the HTTP transport. Note that in Axis2 1.5 this code is no longer part of the kernel and lives in a separate module. The core question here is whether we should upgrade that code from 3.1 to HttpClient 4.0 or if it is better to keep two separate transport sender implementations least It would be interesting to get Oleg's opinion on this. For the legal issue around I think the best solution is to allow the user to register additional AuthSchemeFactory classes in the transport configuration in axis2.xml. People who need NTLM can than use the code from [2]. [1] [2] I am willing to provide a patch to upgrade to httpclient 4.0. I have completed some work locally and I believe most of the existing functionality has been replicated successfully in httpclient 4.0 but still more areas need to be settled before the local work becomes a candidate for commit into the trunk. Unanswered I assume upgrading to httpclient 4.0 rather than providing a separate transport is the best long term solution. Drop support for option Reason DefaultHttpClient already supports http and https schemes by default do we really want to allow a user to use a different This doesn't seem to be a commonly used feature. If we still need to support this option then an instance of Scheme would need to be passed in by the user and registered in the SchemeRegistry in turn used to build the HttpClient. We can no longer use a DefaultHttpClient if we do we would have to extend it most likely. drop authenticator preemptive authentication support Preemptive authentication is considered unsecure and is strongly discouraged. Moreover the code found in examples: is no longer officially supported. Which means that we should drop preemptive authentication support from the trunk; alternatively we can allow a number of pluggable mechanisms to allow users to enable preemptive auth. The user would have to provide HttpRequestInterceptor and HttpResponseInterceptor implementations as well as a means to properties to configure a BasicHttpContext for use with the HttpClient. As a the user could fully initialize it's own AbstractHttpClient instance and pass it through the existing option. Drop support for httpclient 4.0 already releases http connections the connection after every http method execution. Therefore this property becomes obsolete. Axis2 and java compiler source compliance I see that some axis2 modules still compile with 1.4 source compliance. Should this be On mailing lists I saw that Axis2 already started moving to java 5. Should Axis2 1.4 kernel module still use java compliance should we change source compliance for the kernel to \n",
            "Child first class loading Currently Axis2 follows the parent first class loading for service and module loading. The reason for this is it uses DeploymentClassLoader loader which is extended from the ClassLoader class. The loadClass method of the ClassLoader class looks like this. protected synchronized boolean throws ClassNotFoundException { check if the class has already been loaded Class c if { try { if { c } else { c } } catch { If still not then invoke findClass in order to find the class. c } } if { } return c; } it first check for parent class loader classes and then for its classes. So we can add child first class loading simply reversing this order in a override loadClass method as follows. protected synchronized boolean throws ClassNotFoundException { Class c if { try { c } catch { c } } return c; } \n",
            "Poor error handling when a request parameter of the wrong type is sent to a POJO web service If a request parameter in a SOAP or REST request to a POJO web service is not of the expected the error messages that are returned to the client and that appear in the logs are often not very good. For the faultcode is soapenv:Receiver be soapenv:Sender since the error was caused by an invalid and the name of the offending parameter or field doesn't appear anywhere. Here is a sample request is declared as The response is: input string: The tomcat log contains: [ERROR] For input string: java.lang.NumberFormatException: For input string: at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at [ERROR] For input string: org.apache.axis2.AxisFault: For input string: at at at at at at at at at at at at at at at at at at at at at at Caused by: java.lang.NumberFormatException: For input string: at at at at at at at at at at ... 20 more \n",
            "Extending Axis2 API to add deployers programmatically Herewith I am attaching a patch. This patch will enable users to add deployers programmatically. Here in this I have added two method to the DeploymentEngine. They are public void String String public void String This patch won't break anything but will extend Axis2 API \n",
            "java2wsdl should report an error if class specified with is not a valid SchemaGenerator If the class specified with the option to java2wsdl doesn't exist or doesn't implement no error is reported and java2wsdl generates a schema with the default SchemaGenerator. This makes it hard to find out if a class specified with is being used or not. java2wsdl should report an error and return a exit status and not generate a schema if it can't use a class set with The flag for NamespaceGenerator seems to have the same problem. \n",
            "Add the namespace to package mapping option to the plugin Add the namespace to package mapping option to the plugin \n",
            "Enable REST support by default. After installation of Axis2 1.1 the Axis2 did not display. Instead a message requiring REST support to eb enabled was displayed. In order to make it make it work I edited as follows: replaced with: \n",
            "make eclipse plugins releasable from the ant build inside tools improve the ant build at the folder to release the eclipse plugins. \n",
            "Tune addressing by not transmitting optional headers If we assume that fewer SOAP headers in a message leads to better as far as the processing of that message is then we should tune addressing headers by not sending optional headers. \n",
            "Axis2 does not decodes SOAP responses using the character encoding set on the response's XML declaration. Problem converting from to My SOAP server isn't axis2 sends SOAP responses like this one shown at the end of this message. The soap server does not set the http header as was expected so it's not possible to get the charset used in the response body from that. But the server defines the character encoding on the response's XML example: Axis2 is ignoring the character enconding defining on the XML declaration and is decoding all the strings sent as if they were The result is I cannot display the words correctly here on the The method returns crazy characters instead of my latin characters á ó ç ã I proved that axis2 uses to decode the network inputstream when I ran the following method on the OMElement returned as response: It returns and it should return Not only it returns but it is indeed using to decode the what is wrong for this situation. The improvement I'm asking here is update axis2 so it obey to the encoding definition on the response's XML declaration. thank bruno. AN EXAMPLE OF A SOAP RESPONSE SENT FROM MY SOAP SERVER: 200 OK 1269 \n",
            "Axis2 Backward compatibility mode When we out of a WSDL in Axis2 and when we compare that generated code with that you get from Axis 1.X there are couple of differences. Out of them if following can be when makeBackwardCompatible flag is it will great for users who are transferring from Axis 1.x to Axis2. 1. Remove the wrapping of generated objects. Axis 1.x does not generate classes for top level or at least they are not visible in method signatures. 2. Rename the Axis2 generated class to follow the same naming convention and interface as in axis1.1. For example: should be renamed to should be renamed to \n",
            "minimize response from RPCMessageReceiver Is there any way to minimize SOAP response from RPCMessageReceiver With my sample I can receive this response. Each element has namespace definition. This response is but little bit heavy. I think response like below is enough. \n",
            "test folder is created when the generated ant script was executed When we code gen for a WSDL we also get a ant build script. When it was used to create the aar it also generates an empty folder named test. This empty folder better be cleaned up. \n",
            "findService implementation for SOAPActionBasedDispatcher I've implemented and successfully used over MDB based JMS transport explicitly adding JMS releated definition into the I'll attach both the patch and the test files. Sorry for I'm not able to prepare a deployable package. Ali Sadik Kumlali \n",
            "Using doPrivileged constructs instroduced from This patch uses the doPrivileged which was introduced from to grant more permission to the applications runs within Java 2 Security environment. \n",
            "Improvements to DBC procesing to support parameters and operations Improved the description hierarchy to check for and process the DBC in all the necessary getter methods \n",
            "Enhancements to DBC Builder processing to add tests and increased functionality This is an improvement to the DBC processing software . It provides more as well increased functionality \n",
            "eclipse plugins build should refer project.properties for version of the dependencies currently the build file does not refer the project.properties file located at the etc folder to obtain the dependencies \n",
            "Standard distribution doesn't contain an explanation about the artifacts included in it When some one downloads Axis2 standard for the first he has not clue until he downloads the docs distribution separately. I think there should be a small text document explaining what is in especially mentioning about the included samples and scripts. \n",
            "Typos usability of web admin console Admin login: Warning: Please note that configuration changes done though the administration console will be lost when the server is restarted. Why was the login form moved to the Deactivate services What's the purpose of the checkbox \"Deactivate\" and the \"Clear\" They don't seem to make any sense. If I want to deactivate a I'd just select the service and click the \"deactivate\" button. Same issue with activation of services \n",
            "Procedure to create multi projects for Eclipse Current documentation in states: The Maven eclipse plugin does not support Maven multiprojects. You will need to execute maven eclipse from each of the module directories.\" the following command can be used to create multi projects for Eclipse: maven multiproject:goal Then in setup a Classpath Variable for and select File Import Existing Projects into Workspace Select root directory. Selecting the root of the Axis source discovers all of the modules and allows all to be imported as individual projects at once. \n",
            "Displaying a WARN message instead of failing a service deployment when a specified transport is not available. Axis2 throws exceptions when the specified transport of a service is not available. And the service becomes faulty as well. If this service has specified multiple transports and these other transports are Axis2 should expose the service in other without simply failing the deployment. e.g 1. Service Foo has specified http and https transports. Now We configured Axis2 only with Http transport. When we deploy the service Foo in the default behavior of Axis2 is to fail the service deployment saying \"Https transport is not available.\". But my suggestion we should deploy the service Foo in Http transport and display a WARN message to notify that this service will not be exposed in Https. e.g 2. Service Bar has specified https and jms transports. We configured Axis2 only with Http transport. Now this service cannot be exposed in either Https or jms. Hence Axis2 should fail the deployment of the service Bar. I've created a patch to support this bahavior. I will attach a patch shortly. Sameera. \n",
            "Support for exposing ejb 3.x as axis2 supports exposing ejb2 components as Refer [1]. This is handles via extending Message receiver to jndi contexts and handle invocations. For eg: org.apache.axis2.rpc.receivers.ejb.EJBInOnlyMessageReceiver org.apache.axis2.rpc.receivers.ejb.EJBMessageReceiver Currently this implementation works with ejb 2.0. Since ejb 3.x has changed architectural since ejb2 this implementation is not usable with ejb 3. I'm working on improving it to support ejb 3.0. But we may have to move away from support for ejb2 while doing this. As ejb 2 is a pretty old standard [2] and ejb 3 is widely used. I'am still working to come up with a implementation for this. [1] [2] \n",
            "Additional Fraction Constructor I'm writing some code who's output includes fractional measurements meant for human consumption. I need a constructor for Fraction which allows you to restrict the denominators to a finite set. This is necessary due to the fact that tools are only available with certain fractions. For it's next to impossible to find a ruler with inch marked I'm attaching a patch which implements the functionality. I've attempted to mimic the style of the existing code as much as possible. One caveat: I don't speak French so the french error message is a translation and probably very poor. \n",
            "Cannot specify proxy and authentication In our environment we are behind a proxy server requesting authentication. I'm using the plugin and as the wsdl file is referring to external schemas such as the generation fails with the ConnectException: Connection refused. Is there a way to indicate which proxy and authentication to use in order to retrieve files located on external We need to be able to indicate which proxy authentication to use and to indicate also the domains for which proxy is not requested local Below the exception stack: Retrieving schema at relative to java.net.ConnectException: Connection refused: connect at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at at Best Cristian \n",
            "Upgrade Axis2 to use xmlschema2 This involves writing some test coverage for existing xmlschema features and porting to new xmlschema2 API. \n",
            "Secure password of mail transport sender configuration in axis2.xml by using secureVault mail transport sender configuration contains the mail server password. This is configured in the axis2.xml in plain text. Therefore there must be way to secure it. \n",
            "WSDLSupplier should support for both WSDL 1.1 and WSDL 2.0 WSDLSupplier should support for both WSDL 1.1 and WSDL 2.0 \n",
            "fails to build aar while using m2e in workspace resolution mode First time posting an issue request. Apologies if I'm doing it wrong... When building in Eclipse using m2e in workspace resolution the is not prepared for a \"dependency\" which isn't an assembly but is instead a folder containing the compiled classes from within the local workspace. I propose that if the incoming dependency happens to be a directory that it get packaged up and copied to the destination instead of blowing up with an exception. is no place to attach a so I'll include a code snippet illustrating my Modifying this function in AbstractAarMojo.java will give the intended result: private void File throws IOException { TO DO: Remove this method and use the method in WarFileUtils when Maven 2 changes to 1.2. if { if { JarArchiver jarArchiver new try { destination } catch { wrap ArchiverException in IOException throw new } } else { preserve timestamp } } } \n",
            "WSDL customization API for Axis2 and stabilize WSDL 2.0 features This project idea consists of collection of Axis2 issues related to WSDL features and mainly focus on following two areas. Introduce a API to customize default WSDL generation behavior of Axis2 and this need to be supported to both WSDL 1.1 and WSDL 2.0. Stabilize WSDL 2.0 features and add missing features. Following are the set of issues that have been identified as compulsory tasks of this project and required to provide detailed technical design with proposals. WSDLSupplier configuration check is not WSDLSupplier should support for both WSDL 1.1 and WSDL 2.0 customization of dynamic WSDL creation Provide an for setting parameters for Java2WSDL generation. Control what wsdl bindings returned via services.xml Axis2 should support to use \"useOriginalWSDL\" property for WSDL 2.0 Further following are some of the optional tasks identified and it's expected to complete some of those issues as well Not required to fix following complete list of Axis2 wsdl2code code generation bug caused by \"localName\" Axis 2 does not pick up wsdl2.0 which is modified to include whttp:location and whttp:method for Restful services WSDL2JAVA no setters in ADBBean WSDL20ToAxisServiceBuilder does not read policies in WSDL 2.0 docs Broken WSDL for operations added by modules Issue with schema import in the wsdl file NullPointerException in if no fileSet is specified Possible bug when generating code for livebookings wsdl not locate the schema document when tomcat starts up Woden attempts to load every time it parses a WSDL document if Axis2 instructs Woden to do Copying data from inputStream to OuputStream needs appropriate buffer size Policy attached to an input operation in a WSDL does not get copied to the Stub operation by WSDL2Java \n",
            "NB 7.1.1 does not generate proper for projects On NB 7.1.1 with GF3.1.2 and Java I run into the following problem. I followed the NB flower album service trail. I've built the and it deployed well in GF; but callin the test page fails. The cause was that no class bytecode was compiled. The sub reason was that did not have the proper conditional statements for src code and test code setup; they are somewhat empty. To know is that this file gets generated. I found the reason that this happens when the engaed java has a part with jars as requested to build an use apache rampart for saml. To get succesfull rampart samel test during build you need at this place; renaming the endorsed directory to cured the problem. I suggest to either fix the issue or bespook it with apache rampart and NetBeans developers. The requirement for the endorsed directory and its content can be found at the rampart binary distribution in the README. If you forget to and maybe newer version have a problem when it comes to build with mvn install. That is the reason why I would have your attention to this problem which affects not only Axis2 or NB when setups are wrong but Rampart builds the other way arround. So we have two products which can not use the endorsed dir and one product which does not build without it; who will sort this out for the rest of the Josef.Stadelmann \n",
            "Test cases to test the Exposed Transports functionality in Axis2 When you develop you can specify the list of transports on which you service should be exposed. This class will test this functionality. e.g. https transport is not available in Axis2. Therefore the deployment of the EchoService2 should fail. This service echo the given input and this was developed to text the axis system working correctly \n",
            "Add String method to org.apache.axis2.databinding.typemapping.SimpleTypeMapper Currently org.apache.axis2.databinding.typemapping.SimpleTypeMapper class has OMElement method. Only usage of the OMElement parameter of this method is to retrieve the text encapsulated in it by calling method. String would be a more cleaner version of this method. Introducing String is useful since converting a String into a simple type is a common requirement. In in many places of Apache Synapse project this sort of conversions are done using newly written code. If String method is introduced to SimpleTypeMapper then it can be reused by number of places including some code in Apache Synpase project without writing new code for the same purpose. \n",
            "Able to resolve relative paths for imported from a wsdl Tried below steps with wso2 ESB 4.0.3. a proxy service with setting property as true as referring to a service's wsdl which contains schema definitions as relative paths[eg: created the proxy service we tried 'wsdl validator' validation to of imported schema urls. \n",
            "Request for a doc which describes how to set an axis2 classpath manually: purpose of each jars in the folder I want to set an axis2 client classpath manually but I didn't find any useful axis2 doc which gives me this information. On another webservice stack I have been able to find such doc at So the question is: why the axis2 team doesn't provide this information which could be very useful Best Regards. \n",
            "separate configuration files for client and server side Unfortunately Axis2 1.6.1 receives no separate configuration files for client and server but still uses essentially the same file This configuration file contains settings for the client side which only make sense in the server side. \n",
            "Add String method to org.apache.axis2.databinding.typemapping.SimpleTypeMapper Currently org.apache.axis2.databinding.typemapping.SimpleTypeMapper class has OMElement method. Only usage of the OMElement parameter of this method is to retrieve the text encapsulated in it by calling method. String would be a more cleaner version of this method. Introducing String is useful since converting a String into a simple type is a common requirement. In in many places of Apache Synapse project this sort of conversions are done using newly written code. If String method is introduced to SimpleTypeMapper then it can be reused by number of places including some code in Apache Synpase project without writing new code for the same purpose. \n",
            "Message Receiver Adds a new URL class loader to TCCL per each request. In Current Message Receiver its adds a new URL class Loader instance as TCCL for each request. This becomes a major performance hit as it cause to create XMLOutputFactory at Axiom level for each response from the server. And also this may cause OOM situation since at AXIOM level it cache the XMLOutput factories per class Loader by default. So in this case the Hash map entries that's used for this cache will get accumulated. Charith \n",
            "Test cases to test the Exposed Transports functionality in Axis2 And I've added a test case[2] to test the exposed transport functionality in Axis2. This also covers the I've introduced by previous patch. https transport is not available in Axis2. Therefore the deployment of the EchoService2 should fail. This service echo the given input and this was developed to text the axis system working correctly \n",
            "url rewrite not working when using policy set Will be adding some jaxws client code to check for Maintain Session enblement by the Transport layer when client application enable Maintain Session using Policy Set. \n",
            "Switch to turn off ServiceGroupID processing in Axis2 When working in SOAP Axis2 always tries to find service group if header is set in the incoming SOAP message. This behavior is not always desirable when Axis2 is acting as a SOAP where the actual service group may not have deployed in the intermediary engine Such scenario would fail the intermediary Axis2 engine when it tries to find the service group. it is neccessary to have a switch to diable service group ID processing in which can be easily configured using the axis2.xml. \n",
            "Avoid the double write in the Message Context serialization to improve performance In the message context there are some cases where an object needs to be written to a temporary buffer to check whether it will serialize ok or not. This is done to avoid corrupting the actual output stream if an error occurs. To improve try to write the temporary buffer to the actual output stream instead of serializing the object twice. \n",
            "Reviewed: Reviewed and made minor corrections in the following files: and \n",
            "Reviewed : Reviewed and made minor changes to and in xdocs. \n",
            "[xdocs] dynamic labels for documentation using maven resource filter Right now release dates are hard coded in the HTML files themselves. I have added a maven resource filter to take them to a separate resource file. Thus these values can be made dynamic with respective to static HTML files. Steps : 1. Locate inside xdocs folder 2. Add an entry to pattern to it. 3. Open any html file inside xdocs folder put in the place where you want 'valuet' o appear. 4. Run goal check the generated artifact. I have added an example to file. Thank you. sumedha \n",
            "Request and response content streaming for SimpleHttpServer I am submitting for your consideration a patch that implements request and response content streaming for SimpleHttpServer. The patch introduces a custom API on top of lower level HttpCore components similar to the Java Servlet API. This enables Axis2 engine to stream content in and out while processing messages without having to use intermediate content thus eliminating the last significant deficiency in the SimpleHttpServer left from the the old implementation based on Commons HttpClient test classes. All test cases pass for me. Please let me know what you think. Oleg \n",
            "Invalid wsdl is generated by java2wsdl when rpc binding style is specified See the attached which was generated by java2wsdl when rpc binding style is specified. It includes the following element. This should include type element instead of 'element' since rpc binding style is specified when generating the wsdl. Steps to reproduce: Generate the wsdl by issuing the following command. java2wsdl Mathsclass . MyAxisservice rpc \n",
            "Shell scripts do not tolerate and with spaces in paths Several of the scripts provided in do not tolerate paths with such as those for and being located in Cygwin something like I've prepared patches for and wsdl2java.sh that alleviate this problem by adding more quoting to the variables in the scripts. \n",
            "Counter class is messy The org.apache.axis2.util.Counter class is messy: 1 The use of reflection is not needed and it's indeed dangerous since errors happen only at run time 2 There's too much synchronization \n",
            "Upgrade SimpleHttpServer to HttpCore I am attaching a patch that upgrades SimpleHttpServer to the latest release of HttpComponents Core. I understand the timing is rather bad but nonetheless please consider this patch for inclusion into the coming 1.2 as it would enable Apache Synapse to depend on the same release of HttpCore as Axis2. The patch basically renames one class and removes a bunch of unused variables and should a minimal impact on Axis2 HTTP code any at Most of the changes between 4.0a3 and 4.0a4 took place in the NIO HTTP implementation. There have been virtually no changes in the classic code used by the SimpleHttpServer. Given all I think it should be pretty safe to upgrade even so late in the release process. Oleg \n",
            "handler round 2 I will be applying the next round of handler integration code. Nick Gallardo will have to follow with a fix to JAXWSProxyHandler. He is already aware of this. \n",
            "Axis2 TCP support is in experimental level MTOM support disabled required for interop over TCP From issue it would appear that MTOM support over TCP has been disabled. As this is configurable in software and via config files not sure why it has been removed so completely. The problem: I wish to communicated from an AXIS2 client to WSE3 over TCP. Thilina Gunarathne informs me that this is working fine over HTTP. that will require an ISS server and the whole point of using WSE3 is to not required an IIS hence the comms is over TCP. This works fine in WSE3 client to WSE3 webservice. When communucating over TCP WSE3 will MTOM encode hence requirement for MTOM support when using TCP. To allow for interop over TCP the current level of support for TCP in AXIS2 needs to be improved. I understamd that currently it is 'in experimental level' due to the absence of a published TCP Binding for SOAP. If anyone has examples of interop over TCP please get in touch though I would be very surprise if it is using AXIS2 1.1.1. \n",
            "Generated WSDL does not implement the Microsoft rules on wrapping Unfortunately the WSDL that Axis2 generates is not \"picked up\" as WRAPPED by the Microsoft svcutil tool. The reasons are pretty minor. My personal preference would be that Microsoft should fix but given that we want Axis2 to interoperate as well as possible I propose that we change these. WCF svcutil looks at the names of the generated parts. We generate \"part1\" but svcutil is looking for the part name \"parameters\". Dumb I have reported this to Microsoft. I propose we also generate the part name \"parameters\" since its a simple fix. WCF svcutil expects the target namespace of the wrapper element to match the target namespace of the WSDL. Frankly I don't understand this either since it doesn't affect the messages on the but here is the comment they produce: CODEGEN: Generating message contract since the wrapper namespace of message getProfileRequest does not match the default value Currently we produce different namespaces e.g. for the WSDL and for the schema. I propose we also change this to improve interop despite where the blame I propose we stop appending since I think it looks ugly \n",
            "Axis2 kernel pom contains unnecessary dependencies Axis2 kernel pom contains dependencies that are no longer used by the module. Ideally those dependecies should be removed. Oleg \n",
            "Null DataHandler objects as MIME attachments Using raw MIME it is desireable to be able specify a null DataHandler object as a method parameter when there is no attachment to be returned. in a document retrieval service when the document image is not Both client and server threw NPE's when this happened. This change allows this to work. The resulting soap message message is a mime type message with only one the soap envelope. This is allowable per Profile 1.0 clause R2917. Code description and implementation was originally done by Bruce \n",
            "ADB should report warning or error when encountering a mixedType I have a schema that uses a complex type with mixed content: ADB doesn't support and the error is manifested at as: org.apache.axis2.AxisFault: org.apache.axis2.databinding.ADBException: Unexpected subelement node \n",
            "JAXWS: Fix the logging of user exceptions thrown by the webservice Problem: The JAXWS web service provided by the user may throw an exception. If the exception is an not an expected exception an unchecked then it should be logged as an error to aid servicability. Unchecked exceptions should not be logged as errors. Solution: I am renaming the jaxws FailureLogger class to WebServiceExceptionLogger. This logger will log unexpected exceptions unchecked to the error log. If a user wants more extensive the user may specify debug logging for the WebServiceExceptionLogger. This will cause all exceptions thrown by the WebService to be logged. I will be checking in this code soon. \n",
            "JAXWS: MustUnderstand checker should not recalculate the headers needed by the sei methods Background: MustUnderstand checking must be performed for all required headers. This includes the headers associated with JAXWS method parameters and headers associated with JAXWS handlers. Problem: Currently the JAXWS headers associated with the JAXWS method parameters are recalculated on each request. This has a performance overhead. Solution: The solution is to calculate the JAXWS headers for the method parameters one time and save the list on the AxisService. The JAXWS header calculation associated with handlers remains unchanged. Next Step: I am doing the final testing on the change. Kudos to David Strite who discovered this performance boost and worked with me on the proposed change. \n",
            "Remove limitation of Maintain Session value to String type. Updated a method in BindingProvider.java in jaxws client side to return an object type instead of casting the object to a String type. This was done to accommodate applications that may return maintain session value as any object type other than String. Prior code: ..... String sessionValue null; ..... sessionValue ..... Current changes: ..... Object sessionValue null; ..... sessionValue ..... \n",
            "Axis2 kernel currently has a direct dependency on Commons HttpClient 3.1 This seems conceptually wrong to me. The kernel ought not have any dependencies on a transport specific libraries A more practical reason: it is just a matter of time HttpClient 3.1 will be superceded by HttpClient 4.0 and support for commons HttpClient will be discontinued. If there is an agreement this is indeed an which should be I will happily invest time looking into what it takes to decouple HttpClient from Axis2 kernel. Oleg \n",
            "Make AXIS2 1.4.1 compatible with When starting AXIS2 1.4.1 with the existing services and Rampart Rahas the following error messages appear: [ERROR] The which is not caused A ClassNotFoundException error occurred in loading the message receiver org.apache.rahas.STSMessageReceiver org.apache.axis2.deployment.DeploymentException: A ClassNotFoundException error occurred in loading the message receiver org.apache.rahas.STSMessageReceiver at at at at at at at at at at at at at Caused by: org.apache.axis2.deployment.DeploymentException: A ClassNotFoundException error occurred in loading the message receiver org.apache.rahas.STSMessageReceiver at at ... 12 more Caused by: org.apache.axis2.deployment.DeploymentException: A ClassNotFoundException error occurred in loading the message receiver org.apache.rahas.STSMessageReceiver at at at ... 13 more Caused by: java.lang.ClassNotFoundException: org.apache.rahas.STSMessageReceiver at at at at at at at at at at at at ... 15 more [ERROR] The which is not caused org.apache.rampart.Rampart org.apache.axis2.deployment.DeploymentException: org.apache.rampart.Rampart at at at at at at at at at at at at at Caused by: org.apache.axis2.deployment.DeploymentException: org.apache.rampart.Rampart at at ... 12 more Caused by: org.apache.axis2.deployment.DeploymentException: org.apache.rampart.Rampart at at ... 13 more Caused by: java.lang.ClassNotFoundException: org.apache.rampart.Rampart at at at at at at at at at at at at ... 14 more [INFO] Deploying module: [INFO] Deploying module: smtpfault [INFO] Deploying module: mar [INFO] Deploying module: metadataExchange org.apache.axis2.deployment.DeploymentException: The rampart module is not valid or has not been deployed. at at at at at at at at at at at at at Caused by: org.apache.axis2.deployment.DeploymentException: The rampart module is not valid or has not been deployed. at at at ... 12 more Caused by: org.apache.axis2.deployment.DeploymentException: The rampart module is not valid or has not been deployed. at at ... 14 more Caused by: org.apache.axis2.deployment.DeploymentException: The rampart module is not valid or has not been deployed. at at ... 15 more Caused by: org.apache.axis2.deployment.DeploymentException: The rampart module is not valid or has not been deployed. at ... 16 more [ERROR] The AccountInformation.aar which is not caused The rampart module is not valid or has not been deployed. org.apache.axis2.deployment.DeploymentException: The rampart module is not valid or has not been deployed. at at at at at at at at at at at at at Caused by: org.apache.axis2.deployment.DeploymentException: The rampart module is not valid or has not been deployed. at at at ... 12 more Caused by: org.apache.axis2.deployment.DeploymentException: The rampart module is not valid or has not been deployed. at at ... 14 more Caused by: org.apache.axis2.deployment.DeploymentException: The rampart module is not valid or has not been deployed. at at ... 15 more Caused by: org.apache.axis2.deployment.DeploymentException: The rampart module is not valid or has not been deployed. at ... 16 more [INFO] org.apache.axis2.deployment.DeploymentException: The rampart module is not valid or has not been deployed. org.apache.axis2.deployment.DeploymentException: The rampart module is not valid or has not been deployed. at at at at at at at at at at at at at Caused by: org.apache.axis2.deployment.DeploymentException: The rampart module is not valid or has not been deployed. at at at ... 12 more Caused by: org.apache.axis2.deployment.DeploymentException: The rampart module is not valid or has not been deployed. at at ... 14 more Caused by: org.apache.axis2.deployment.DeploymentException: The rampart module is not valid or has not been deployed. at at ... 15 more Caused by: org.apache.axis2.deployment.DeploymentException: The rampart module is not valid or has not been deployed. at ... 16 more [ERROR] The SecureService.aar which is not caused The rampart module is not valid or has not been deployed. org.apache.axis2.deployment.DeploymentException: The rampart module is not valid or has not been deployed. at at at at at at at at at at at at at Caused by: org.apache.axis2.deployment.DeploymentException: The rampart module is not valid or has not been deployed. at at at ... 12 more Caused by: org.apache.axis2.deployment.DeploymentException: The rampart module is not valid or has not been deployed. at at ... 14 more Caused by: org.apache.axis2.deployment.DeploymentException: The rampart module is not valid or has not been deployed. at at ... 15 more Caused by: org.apache.axis2.deployment.DeploymentException: The rampart module is not valid or has not been deployed. at ... 16 more [INFO] org.apache.axis2.deployment.DeploymentException: The rampart module is not valid or has not been deployed. [INFO] Deploying Web service: version.aar [INFO] [SimpleAxisServer] Started [SimpleAxisServer] Started [INFO] Listening on port 8080 \n",
            "Correct spelling and other errors in the documentation. See Summary these changes will be done in no particular order. As each change is completed it will be uploaded to the project. \n",
            "Locking parameter vis its' locked attribute A parameter in axis2 look like as follows as you can see there is an attribute called \"locked\" and no one has used that. The correct implementation of that attribute should be as follows; If the locked attribute is true then no one in the description hierarchy below that can override the that parameter. an eaxmple if the locked attribute is true in axis2.xml then neither in module.xml nor service.xml can have the same parameter with locked attribute set to A parameter can be locked at any level. \n",
            "The build needs to have a different goal to run the interop tests We need to have a seperate goal for the maven build to have the interop tests. The idea is that some interop tests need to interact with remote servers. This is NOT supposed to be a requirement for a user hence the default goal should not have any reference to tests that connect to remote servers \n",
            "Propagate transport info to MessageContext For is VERY useful in the field and people use it. Could we please come up with a list of such properties that we need to support in dims \n",
            "switch to File Storage based on of the Attachments switch to File caching based on size of the attachment.... \n",
            "SAAJ TCK compliance for Axis2 SAAJ implementation Run Axis2 SAAJ implementation again SAAJ TCK and provide all the missing implementation. Currently attachment support is missing in SAAJ complete that. Ashutosh \n",
            "Parameter values as OMElements An extract from : It'll be much more flexible for the developers if they can access the XML element describing the parameter as an OMElement. This mechanism will enable the developer to store much more than just a String value in the parameter definition: Also consider the following example: this will allow setting additional parameter ATTRIBUTES that can be used to specify the flow. [1] Ref: [1] \n",
            "Resolving Operation at dispatcher using local name of the first Element in a soapbody when the style is Dispatcher should be able to resolve the operation in folowing conditions When 1. The soap action is same for all the operations in service 2. Local name of the first child is not equal to the operation name style is 3. Local name of the first child is equal to the name Dispatcher can use element name that is the local name of first child and also mentioned in the to resolve the operation . A sample WSDL and a relevent Soap messages are as follows: Request Soap for EchoString Oparation: POST SOAPAction: Connection: Host: soapinterop.java.sun.com 411 is a String Response soap: 200 OK SOAPAction: \"\" chunked Date: 17 Aug 2005 12:20:37 GMT Server: Apache 196 is a String 0 Requst Soap for EchoStruct operation: POST SOAPAction: Connection: Host: soapinterop.java.sun.com 485 is a String response saop for echoStruct operation 200 OK SOAPAction: \"\" chunked Date: 17 Aug 2005 12:54:39 GMT Server: Apache 1f8 is a String 0 \n",
            "Need a integration test for the non blocking two channel used with AsyncInOutMessageReceiver Need an integration test for the non blocking two channel client with AsyncInOutMessageReceiver.... \n",
            "Introducing the Data binding for the Asynchronous programming model case Currently the Callback handler in the for each of the resume operations it gets a AsyncResult as a parameter. auto generated Axis2 call back method for echoStringArray method public void { here with the code to handle the response } This should be changed to get the data bound to this operations as well. \n",
            "Codegen support for setting parameters withing Soap header blocks Current WSDL2Java code generation doesn't facilitate to set arguments withing soap header blocks. i.e. when the wsdl looks like as it's prefered to have mehtods such as HeaderDocument header of ... withing the stub. A sample Gayan \n",
            "Configurable Dispatching order In the current implementation there are four dispatchers execution order of them are hardcoded my idea is it should be configurable. \n",
            "Configuring chaining The user cannot configure a module or a handler within a to be at user defined points in the inflow and the outflow. Consider the following example: A user engages 5 which drops hanlders in to various places in the outflow. The outgoing SOAP message should be logged using the 'Logging module' after certain handler invocations. Therefore the user should be able to specify that the hanlders in the logging module should be invoked after each of those handlers from the 5 moduels that the user engages. But since the module.xml within the .mar file is not expected to be modified by the user it cannot be used to deploy the handlers in the reqired places. And as of now we cannnot use axis2.xml do the above. \n",
            "Better Paramter searching mechinshm Implement the searching mechanism as describe in the mail \n",
            "Jetty based SimpleHTTPServer This is yet another lesson learned from Axis 1.X. A lot of code is not tested well because a typical deployment is a servlet and none of the tests in the harness are run inside a servlet. gzip anything that exercises the thread context class loader stuff Just like the move to CommonsTransportSender based on jakarta commons I think we should port the JettyAxisServer in Axis 1.X clean it up and use that in Axis 2.0 as the default environment for testing get rid of the dims \n",
            "[PATCH][document] release download page new release download page seemed smoother to create a new download page which can be wired up before the links are updated. plan to add a redirect from the old url to the new once the new download page is in place and working. the project specific blurb is a little brief: maybe needs fleshing out before a 1.0 release. \n",
            "OMDocument must have XML Version and Char encoding OMDocument must contain information regarding the XML Version and Character encoding. And those should be present when serialized. There should be a flag to set this on and off when serializing. \n",
            "Extracting Char Encoding and version information from incoming SOAP messages Current StAXSOAPModel builder do not get char set encoding and version from the recd SOAP message. This has to be fixed and there should be a check to see whether transport charset information and SOAP message information do tally. Current OMOutput overrides the char information in the SOAP Document. \n",
            "Remove code duplication ... among the StAXOMBuilder and StAXSOAPModelBuilder. Refactor it. \n",
            "Moving deployment descriptor parsing form stax to OM In current implementation all the descriptor parsing in deployment section are done directly using Stax I think this make difficulty in adding more and more configuration options into those descriptors so my idea is to use StaxOMBuilder to read descriptors and using that populate all the deployment time descriptions like ServiceDescriptions OperationsDescrptions etc... \n",
            "Support for Exploded directories From Glen Daniels: I notice that we don't seem to support exploded directories yet. Is anyone working on We should be able to just drop a directory structure like underneath and have the deployer treat it exactly the same as if the same files were compressed into \"echo.aar\". \n",
            "Inability to handle faults before creating message context When engine receives a SOAP message it gets the creates a creates a message context and put the created envelop of the in to the message context. The constructor in the StAXSOAPModelBuilder has a code to parse the header part of the received SOAP message. if an error encountered in this constructor code two headet blocks envelope namespace there will be an exception thrown from the builder with correct information. But the error handling has no information about the version of the SOAP message received. Engine currently sends a SOAP 1.1 irrespective of the version of the incoming faulty message. My suggestion is to get the SOAP version initialy from the content type information from the transport and create a message context with that. Then even there is a fault in builder fault handling section has enough information to process it. \n",
            "SOAP Fault information in SOAP Header SOAP 1.2 spec requires some fault information to be present in SOAP header of the response SOAP Fault message. I fixed the current system to send the correct fault information in the body. But need to send the relevant information in the SOAP header according to SOAP 1.2 specification. \n",
            "Need to provide a way to configure modules when referring them Through axis2.xml and service.xml we can add module references and if there is a module reference element in those descriptors then those module will be engaged into globally and service respectively. But there can be instance that some module need to be configure through those and when we referring to module providing a way to add module configurable parameter into those descriptors. I prefer following way of specifying them. In addition to that when we engaging module at the run time the corresponding methods has to change to take parameter list as argument. Comments ..... \n",
            "Check all properties that can be set via call in Axis 1.X and attempt to support those. Just ran into socket timeout property yesterday. need to be able to specify it in call. dims \n",
            "Setting properties to be available in the context hierarchy by the generated stubs We shoulld be able to set properties at the generated stubs where those properties can be used in the handlers of modules. Handlers can access them through the message context. Hence the setting of the properties by the stub should add them to the context hierarchy. org.apache.axis2.clientapi.Call already does this as follows: public void Object { } \n",
            "Use Admin Client to Enable and configure MTOM Need to enable and Configure MTOM and other attachments parameters by Admin Client \n",
            "Databinding completeness in the stubs that are generated We should project stub methods tha are completely agnostic of the databinding mechanism utilized to generate them. I'm copy pasting the issue that was mailed to on 28th July 2005 Transcript of the mail follows Hi I planned to test a stub based style of invocation with this wsdl [attached SimpleTest.wsdl]. Its the wsdl for a webservice which hosts a method of the signature public String I started with wsdl2java to generate stubs for me. I then set out to write a test client was lacking from wsdl2java artifacts that got that would just assume as if it was invoking a local method named echoString on the stub. Strangely the method signature of in the generated stub is seen to expect an XMLBeans specific EchoStringDocument kind of object as its input parameter. This makes us think that data binding is not facilitated to the user fully. User shouldn't have to bore the onus of creating an EchoStringDocument object and pass it as parameter to the stub at least when he is using the stub based isn't Is this feature on our wish list or am I missing Thank you Jayachandra \n",
            "Review CommonsHTTPSender in Axis 1.X and update CommonsHTTPTransportSender Cross check support for proxies...i remember a patch from Simon for gzip support as well in Axis 1.X. We need to port all those functionality to Axis 2.0 dims \n",
            "In eclipse codegen plugin even if an invalid wsdl is specified the wizard allows you to move forward In the eclipse codegen plugin if the user specifies an invalid wsdl the wsdl to java scenario the next button is still enabled to go to the next page. When the wsdl path is specified it attempts to load the wsdl in order to fill the contents in the next page. Therefore if the wsdl is loading the wsdl will fail. We can use this to stop user from going to the next page from the wsdl location page. It will be convenient for the user to know then and there that the wsdl is invalid. \n",
            "Request for support for configuring AXIS2 with XMLBeans to tune namespace output when writing XML data I use code like this to my XMLBeans namespaces for textual output: XmlOptions xmlOptions new HashMap suggestedPrefixes new String xmlStr The first difficulty I have is with explicit prefixes like \"xmlns\" in these combinations: \"xmlns:tns\" or \"xmlns:soap\". They don't seem to be accepted as specification by XMLBeans and lead to a guessed namespace abbreviation in output of XMLBeans. Omitting the \"xmlns:\" part works for the suggestedPrefixes HashMap but I require them also to be explicitly mentioned with \"xmlns:\" prefix at least in the namespace definition section created by XMLBeans because they will later be subject to XML signing where every bit counts. I cannot achieve this so far. My main question is: How can I how AXIS2 calls for outputting the Keith Chapman commented in the WSO2 online forum: \"Axis2 allows you to pass in options to these various dataBinding frameworks by prefixing the option with But going through the XMLBeans integration code in axis2 I don't see us taking note of the options you mention above. Perhaps you could raise this as a JIRA on the axis2 list.\" I found the XMLBeans integration code in this directory: the Axis2BindingConfig in file CodeGenerationUtility just seems to configure the mapping of URIs to package names. What I need to tune are the settings when writing the data wihtin an XMLBean to a file or e.g. using XmlOptions as stated above. can this be in With some I might be able to do the in AXIS2 myself. I need to create an XML that conforms exactly to a given specification in each and every bit because it is subject to an XML signature. Since the mentioning of namespaces is not adjusted perfectly by XML this is a serious issue. Since the XML structures are stored in their own class structures not just as simple text in the SOAP I can't easily them. Is there any point where I can easily add some patches to the SOAP or AXIS2 libraries to really adjust every bit of XML before The best spot for patches I can think about right now is the XML canonicalization which also requires some complex attribute handling. Does anybody have some other Are there any interfaces or interceptors foreseen for XML Are there any easily adaptable examples for using them in this Does anybody have experience the XML for using XML signatures that have to be exactly compatible with a 2 years old server using some other implementation for canonicalization and XML \n",
            "Ability to specify session scope in jaxws services Since the services.xml file is ignored when deploying an annotated class as a web it appears the only available session scope is the default request scope. I'm converting an old web service that ran using the Sun implementation. It's a stateful service and I'd like to preserve the service semantics. To do I need a way of specifying which session scope to use in an annotation. \n",
            "Create servicejars directory inside repository directory Some of the JAXWS samples use servicejars directory to deploy jar files. But it is not created by default with Axis2 distribution. \n",
            "jaxbri binding should report exception in addition to \"Unable to create JAXBContext for class\" I have a schema that reported the following error: Unable to create JAXBContext for class: vivisimo.velocity.test.Dictionary I had to recompile the entirety of Axis to add one line after it: Which made debugging a whole lot This is in the file: \n",
            "MTOM Serialization Policy Assertion 1.1 is not supported in Axis2 MTOM Serialization Policy Assertion 1.1 is not supported in Apache Axis2. \n",
            "Add support to Axis2 specification allows us to endpoint reference by providing identity information about the endpoint. This mechanism can be used to provide the public key information of the service using the WSDL as we discussed in the security strategy discussion. I am planning to add this feature to Axis2. The plan is to set the identity information in a service parameter and when building the AxisService2WSDLXXBuilder can serialize the identity information correctly according to the spec. When Rampart is engaged Rampart can set this property according to the Rampart configuration in the or one can set public key data using this parameter directly. \n",
            "AxisService's scope inside ServiceLifeCycle is always \"request\" scope regardless of actual By the AxisService constructor sets the scope to be \"request\". The org.apache.axis.deployment.ServiceBuilder is responsible for setting this value to be the actual value specified in the services.xml file. the method which handles processes the service life cycle attribute before it processes the service scope attribute. As a the AxisService object which is passed to the method is always the default scope regardless of what the user has specified in their services.xml. I believe that by simply rearranging the order in which these attributes are processed we can avoid confusion in situations where users are performing scope specific actions in their ServiceLifeCycle implementations. It may be beneficial to leave off processing of the service life cycle attribute for as long as so that when the method is finally users are given the most accurate representation of their service. Manny Lim \n",
            "JAXWS: Store the exception thrown from a web method implementation in a property so that it can be queried by an outbound jaxws handler Scenario: A JAXWS webservice on the server throws an exception or The JAXWS engine converts the exception into a message containing a SOAP Fault. An outbound JAXWS application handler is installed. In the handleFault the customer wants to do some work related to the exception. For the customer may want to log exception information in a database. Problem: The conversion of the Exception SOAP Fault is lossy. Some of the information about the Exception is lost. For the stack trace of the exception is not captured should not be in the SOAP Fault. Other java information is also lost. Solution: Store the Exception on a new property. The outbound JAXWS application handler can then access the exception directly to query java specific information. Next Step: I have coded the solution and verification tests. The changes are minimal and I will be committing the changes later today. \n",
            "Extracting AxisDescription as the base class of all other Description classes As per mailing thread: taken place at mailing we need to extract a base class for all other Description classes AxisOperation .. \n",
            "Dispatching order The Dispatching order should be changed such that the SOAP Action based dispatching would get precedence over Request URL based Dispatching \n",
            "Migrate to Maven2 Its kinda good to move in to Maven2 from Maven 1.x. According to maven development team the multiproject support was not integrated well in to Maven 1.x but its now in the core of Maven 2. So it has better support. Since we are using multiproject capabilities a its better if we can move on to maven2. This is just a wish from me for some one coming new in to Axis2. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzLQLrpyInq-"
      },
      "source": [
        "df = pd.read_csv('jbehave_cleaned.csv')\n",
        "#df = pd.read_csv('jbehave_feat.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3tkJpxuOInrB",
        "outputId": "64b42d60-1ccc-499b-ab58-6a530586c15d"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-299dd651-b5e7-493a-88e9-5a93a8f6b556\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>summary</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adding CORS Support User agents commonly apply...</td>\n",
              "      <td>New Feature</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>JMX support Adding JMX support for AXIS2. See</td>\n",
              "      <td>New Feature</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Provide new plugpoint in code This work will p...</td>\n",
              "      <td>New Feature</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.1: Add support for AddressingFeature and Sub...</td>\n",
              "      <td>New Feature</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Add support for and Complete support for the n...</td>\n",
              "      <td>New Feature</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-299dd651-b5e7-493a-88e9-5a93a8f6b556')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-299dd651-b5e7-493a-88e9-5a93a8f6b556 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-299dd651-b5e7-493a-88e9-5a93a8f6b556');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             summary         type\n",
              "0  Adding CORS Support User agents commonly apply...  New Feature\n",
              "1     JMX support Adding JMX support for AXIS2. See   New Feature\n",
              "2  Provide new plugpoint in code This work will p...  New Feature\n",
              "3  2.1: Add support for AddressingFeature and Sub...  New Feature\n",
              "4  Add support for and Complete support for the n...  New Feature"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lre1CviXInrF",
        "outputId": "743a6bbd-262c-490b-ac26-3b2249452ef9"
      },
      "source": [
        "df['type'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Bug            230\n",
              "Improvement    230\n",
              "New Feature    230\n",
              "Name: type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH9Qh9aAInrI",
        "outputId": "bd828cd1-fa92-47bb-f2ab-f948fa9f04a5"
      },
      "source": [
        "possible_labels = df.type.unique()\n",
        "\n",
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index\n",
        "label_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Bug': 1, 'Improvement': 2, 'New Feature': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lsxjH2WInrN"
      },
      "source": [
        "df['label'] = df.type.replace(label_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zr0SvIonInrQ",
        "outputId": "d646bd0a-ebb1-482c-e2ac-c661c44cabed"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2979cc94-a75b-43e6-85e3-ca8abda62954\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>summary</th>\n",
              "      <th>type</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adding CORS Support User agents commonly apply...</td>\n",
              "      <td>New Feature</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>JMX support Adding JMX support for AXIS2. See</td>\n",
              "      <td>New Feature</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Provide new plugpoint in code This work will p...</td>\n",
              "      <td>New Feature</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.1: Add support for AddressingFeature and Sub...</td>\n",
              "      <td>New Feature</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Add support for and Complete support for the n...</td>\n",
              "      <td>New Feature</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2979cc94-a75b-43e6-85e3-ca8abda62954')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2979cc94-a75b-43e6-85e3-ca8abda62954 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2979cc94-a75b-43e6-85e3-ca8abda62954');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             summary         type  label\n",
              "0  Adding CORS Support User agents commonly apply...  New Feature      0\n",
              "1     JMX support Adding JMX support for AXIS2. See   New Feature      0\n",
              "2  Provide new plugpoint in code This work will p...  New Feature      0\n",
              "3  2.1: Add support for AddressingFeature and Sub...  New Feature      0\n",
              "4  Add support for and Complete support for the n...  New Feature      0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPrtUPExInrT"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(df.index.values,\n",
        "                                                  df.label.values,\n",
        "                                                  test_size=0.15,\n",
        "                                                  random_state=42,\n",
        "                                                  stratify=df.label.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qcc6gO6InrW"
      },
      "source": [
        "df['data_type'] = ['not_set']*df.shape[0]\n",
        "\n",
        "df.loc[X_train, 'data_type'] = 'train'\n",
        "df.loc[X_val, 'data_type'] = 'val'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "mLxWepY7InrY",
        "outputId": "4563ea02-c71b-4e87-c408-072b40f82f87"
      },
      "source": [
        "df.groupby(['type', 'label', 'data_type']).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1aef275b-298f-43f0-a848-38bff02b93ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>type</th>\n",
              "      <th>label</th>\n",
              "      <th>data_type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">Bug</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
              "      <th>train</th>\n",
              "      <td>1402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">Improvement</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
              "      <th>train</th>\n",
              "      <td>1403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">New Feature</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th>train</th>\n",
              "      <td>1402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>248</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1aef275b-298f-43f0-a848-38bff02b93ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1aef275b-298f-43f0-a848-38bff02b93ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1aef275b-298f-43f0-a848-38bff02b93ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                             summary\n",
              "type        label data_type         \n",
              "Bug         2     train         1402\n",
              "                  val            248\n",
              "Improvement 0     train         1403\n",
              "                  val            247\n",
              "New Feature 1     train         1402\n",
              "                  val            248"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vfQaJneInre",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "ab2e099a3fd64426981889e6eb8dfdb4",
            "903f94a48d6748448ac93a9b46d59b0e",
            "92873b8da76f418fa7f15aa09ae5b1ad",
            "b03d2d163ba44acdbb6b55ebf1475949",
            "1a173c05a20845bd8044b72d0335fffb",
            "e39ea7a566364189a9d8b6112cb1999c",
            "b6051d4dd18c4954beebbae5c6163338",
            "085adf9844874d64b0bf49389e3ef08a",
            "7791072f30f64fa8b3aae6f3676268ad",
            "7311fa97239f4e6eaed1288f1bb331a5",
            "fb39ef5c9cdc415ea5e56e40f1472098",
            "6bef79c9b77d4807a7cb0f2a26340d05",
            "0e20a952006648219e4478b5421335bf",
            "5843e60464db4ed8a811d3c070b5c0e3",
            "b1bd72c4832346598abaac69da811ebf",
            "d84bd636dfb944d8a567f747039a55fc",
            "154f7c3acfe34f708bae616378feae35",
            "10dcb88aff394dcda50bc94532d9481d",
            "08b61133d5704c5d917936ba46d7b297",
            "d1f4c899c2284bb292bd78395b9c0091",
            "479ff166501e4ecfb568cb6ea448ddd4",
            "d1fbecb3523344adbdfb959a797a9fa3",
            "c14c8c3e07f3441fba53215616fa2fab",
            "ec465e1695404cbaa033f7091996b456",
            "878797b5eebd4db6bf1af7bd98dd254a",
            "0affb2a5bf5247959cc147c648c0934c",
            "8c03bd440cb547eb90d8f027f867c6b6",
            "4c5fad33f068408a94962dd91a3d7330",
            "6f711bdcffa5484486fe80114a19b0e4",
            "5ae08fa3cb2047329ffc680ffccbbf1a",
            "89a8dd3846c046c3a8ce22849d1e4f48",
            "1e030210df4740088cd3c8e97cb7f4eb",
            "a779491eb1ee434da7e56316e66710d1",
            "6f282be2cdbb4f0d8d53369f545803de",
            "ac49e5428a77425e83482073885e2652",
            "5cac0b6c5ff84ac38b8a70faad3c29c5",
            "23e27f0d7ca4420b9389676f29189958",
            "89626bda3a644c9fb87bb4f6ea537bdf",
            "904df4cbf9d04f33b6ed3121152d3be1",
            "cf4c1fcb0ff542f2875b61accca4af31",
            "a24403d9d1244447af44ddd7ba4a9ce3",
            "5d4fe851bfee40a29371697ba16243b5",
            "85cb167213aa4bb2a1fc735b8ec93dbd",
            "e7d779653ab64d81804b02f79aad30e5"
          ]
        },
        "outputId": "404c7e24-36c7-4891-f7fb-1cbd1e84a57b"
      },
      "source": [
        "#tokenizer = BertTokenizer.from_pretrained('distilbert-base-uncased',#'allenai/scibert_scivocab_uncased') # 'bert-base-uncased',\n",
        "#                                          do_lower_case=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base',#'allenai/scibert_scivocab_uncased') # 'bert-base-uncased',\n",
        "                                                do_lower_case=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab2e099a3fd64426981889e6eb8dfdb4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6bef79c9b77d4807a7cb0f2a26340d05",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c14c8c3e07f3441fba53215616fa2fab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f282be2cdbb4f0d8d53369f545803de",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7aPxLIuCxyt",
        "outputId": "50609d56-f84f-4579-e285-f6836a011b4d"
      },
      "source": [
        "text_file = open(\"vocab.txt\", \"r\")\n",
        "new_tokens = text_file.readlines()\n",
        "print(new_tokens)\n",
        "print(len(new_tokens))\n",
        "text_file.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Acceptance \\n', 'Acceptance criteria\\n', 'Acceptance test\\n', 'Activity\\n', 'Activity model\\n', 'Actor\\n', 'Adequacy\\n', 'Agile\\n', 'Ambiguity\\n', 'Artifact\\n', 'Association\\n', 'Attribute\\n', 'Backlog\\n', 'Baseline\\n', 'Behavior\\n', 'Behavior model\\n', 'Bug\\n', 'Burndown chart\\n', 'Business requirement\\n', 'Cardinality\\n', 'Change management\\n', 'Change request\\n', 'Changeability\\n', 'Class\\n', 'Class diagram\\n', 'Class model\\n', 'Completeness\\n', 'Composition\\n', 'Conflict\\n', 'Requirements conflict\\n', 'Consistency\\n', 'Constraint\\n', 'Context\\n', 'Context boundary\\n', 'Context diagram\\n', 'Context model\\n', 'Control flow\\n', 'Correctness\\n', 'Customer\\n', 'specification\\n', 'customer\\n', 'Decision table\\n', 'Defect\\n', 'Design\\n', 'Document template\\n', 'Domain\\n', 'Domain model\\n', 'Domain requirement\\n', 'Effectiveness\\n', 'Efficiency\\n', 'Elaboration\\n', 'Elicitation\\n', 'Entity\\n', 'diagram\\n', 'Error\\n', 'Evolutionary prototype\\n', 'Exploratory prototype\\n', 'Fault\\n', 'Fault tolerance\\n', 'Feasibility\\n', 'Feature\\n', 'Feature diagram\\n', 'Feature model\\n', 'Functional requirement\\n', 'Functionality\\n', 'Glossary\\n', 'Goal\\n', 'Goal model\\n', 'Increment\\n', 'Iteration\\n', 'Kind of requirement\\n', 'requirements\\n', 'Mock-up\\n', 'Model\\n', 'Modeling language\\n', 'Modifiability\\n', 'Natural language\\n', 'Necessity\\n', 'requirement\\n', 'Object\\n', 'Object model\\n', 'Performance\\n', 'Persona\\n', 'Priority\\n', 'Prioritization\\n', 'Problem\\n', 'Process\\n', 'Process model\\n', 'Product\\n', 'Product backlog\\n', 'Product line\\n', 'Product owner\\n', 'Prototype\\n', 'Prototyping\\n', 'Quality\\n', 'requirements\\n', 'functional requirements\\n', 'Refactoring\\n', 'Redundancy\\n', 'Release\\n', 'Reliability\\n', 'Requirements analysis\\n', 'Requirements baseline\\n', 'Requirements branching\\n', 'Requirements conflict\\n', 'Requirements discovery\\n', 'elicitation\\n', 'Requirements document\\n', 'Requirements elicitation\\n', 'Requirements Engineer\\n', 'Engineering\\n', 'stakeholders\\n', 'system\\n', 'management\\n', 'Requirements model\\n', 'negotiation\\n', 'Requirements source\\n', 'Requirements specification\\n', 'Review\\n', 'Risk\\n', 'Role\\n', 'Safety\\n', 'Scope\\n', 'Security\\n', 'Semantics\\n', 'Sequence diagram\\n', 'Service\\n', 'Specification\\n', 'Sprint\\n', 'Stakeholder\\n', 'Standard\\n', 'State machine\\n', 'State machine diagram\\n', 'Statechart\\n', 'Synonym\\n', 'Syntax\\n', 'System\\n', 'System boundary\\n', 'System context\\n', 'System requirement\\n', 'specification\\n', 'Tool\\n', 'Traceability\\n', 'UML\\n', 'Unambiguity\\n', 'Understandability\\n', 'Usability\\n', 'Use case\\n', 'Use case diagram\\n', 'User\\n', 'User story\\n', 'Validation\\n', 'Variability\\n', 'Variant\\n', 'Variation\\n', 'Verifiability\\n', 'Verification\\n', 'Version\\n', 'View\\n', 'Viewpoint\\n', 'Vision\\n', 'Walkthrough\\n', 'Wireframe\\n', 'ADC\\n', 'ALU\\n', 'ANSI\\n', 'ASCII\\n', 'abstraction\\n', 'access\\n', 'access time\\n', 'accident\\n', 'accuracy\\n', 'accuracy study processor\\n', 'actuator\\n', 'adaptive maintenance\\n', 'address\\n', 'addressing exception\\n', 'algorithm\\n', 'algorithm analysis\\n', 'alphanumeric\\n', 'American National Standards Institute\\n', 'American Standard Code for Information Interchange\\n', 'analog\\n', 'analog device\\n', 'analog-to-digital converter\\n', 'analysis\\n', 'anomaly\\n', 'application program\\n', 'application software\\n', 'architectural design\\n', 'architecture\\n', 'archival database\\n', 'archive\\n', 'archive file\\n', 'arithmetic logic unit\\n', 'arithmetic overflow\\n', 'arithmetic underflow\\n', 'array\\n', 'as built\\n', 'assemble\\n', 'assembler\\n', 'assembling\\n', 'assembly code\\n', 'assembly language\\n', 'assertion\\n', 'assertion checking\\n', 'asynchronous\\n', 'asynchronous transmission\\n', 'audit\\n', 'audit trail\\n', 'auxiliary storage\\n', 'band\\n', 'bandwidth\\n', 'bar code\\n', 'baseline\\n', 'BASIC\\n', 'basic input/output system\\n', 'batch\\n', 'batch processing\\n', 'baud\\n', 'benchmark\\n', 'bias\\n', 'binary\\n', 'BIOS\\n', 'bit\\n', 'bits per second\\n', 'black-box testing\\n', 'block\\n', 'block check\\n', 'block diagram\\n', 'block length\\n', 'block transfer\\n', 'blocking factor\\n', 'blueprint\\n', 'bomb\\n', 'boolean\\n', 'boot\\n', 'bootstrap\\n', 'boundary value\\n', 'boundary value analysis\\n', 'box diagram\\n', 'bps\\n', 'branch\\n', 'branch analysis\\n', 'branch coverage\\n', 'bubble chart\\n', 'buffer\\n', 'bug\\n', 'bus\\n', 'byte\\n', 'C\\n', 'C++\\n', 'CAD\\n', 'calibration\\n', 'call graph\\n', 'CAM\\n', 'CASE\\n', 'cathode ray tube\\n', 'cause effect graph\\n', 'cause effect graphing\\n', 'CCITT\\n', 'CD-ROM\\n', 'central processing unit\\n', 'certification\\n', 'change control\\n', 'change tracker\\n', 'check summation\\n', 'checksum\\n', 'chip\\n', 'CISC\\n', 'client-server\\n', 'clock\\n', 'CMOS\\n', 'CO-AX\\n', 'coaxial cable\\n', 'COBOL\\n', 'code\\n', 'code audit\\n', 'code auditor\\n', 'code inspection\\n', 'code review\\n', 'code walkthrough\\n', 'coding\\n', 'coding standards\\n', 'comment\\n', 'compact disc - read only memory\\n', 'comparator\\n', 'compatibility\\n', 'compilation\\n', 'compile\\n', 'compiler\\n', 'compiling\\n', 'complementary metal-oxide semiconductor\\n', 'completeness\\n', 'complex instruction set computer\\n', 'complexity\\n', 'component\\n', 'computer\\n', 'computer aided design\\n', 'computer aided manufacturing\\n', 'computer aided software engineering\\n', 'computer instruction set\\n', 'computer language\\n', 'computer program\\n', 'computer science\\n', 'computer system\\n', 'computer system audit\\n', 'computer system security\\n', 'computer word\\n', 'computerized system\\n', 'concept phase\\n', 'condition coverage\\n', 'configurable\\n', 'configuration\\n', 'configuration audit\\n', 'configuration control\\n', 'configuration identification\\n', 'configuration item\\n', 'configuration management\\n', 'consistency\\n', 'consistency checker\\n', 'constant\\n', 'constraint analysis\\n', 'Consultive Committee for International Telephony and Telegraphy\\n', 'Contrast with software item\\n', 'control bus\\n', 'control flow\\n', 'control flow analysis\\n', 'control flow diagram\\n', 'Control Program for Microcomputers\\n', 'controller\\n', 'conversational\\n', 'coroutine\\n', 'corrective maintenance\\n', 'correctness\\n', 'COTS\\n', 'coverage analysis\\n', 'CP/M\\n', 'CPU\\n', 'crash\\n', 'CRC\\n', 'critical control point\\n', 'critical design review\\n', 'criticality\\n', 'criticality analysis\\n', 'cross-assembler\\n', 'cross-compiler\\n', 'CRT\\n', 'cursor\\n', 'cyclic redundancy [check] code\\n', 'cyclomatic complexity\\n', 'DAC\\n', 'data\\n', 'data analysis\\n', 'data bus\\n', 'data corruption\\n', 'data dictionary\\n', 'data element\\n', 'data exception\\n', 'data flow analysis\\n', 'data flow diagram\\n', 'data integrity\\n', 'data item\\n', 'data set\\n', 'data sink\\n', 'data structure\\n', 'data structure centered design\\n', 'data structure diagram\\n', 'data validation\\n', 'database\\n', 'database analysis\\n', 'database security\\n', 'dead code\\n', 'debugging\\n', 'decision coverage\\n', 'decision table\\n', 'default\\n', 'default value\\n', 'defect\\n', 'defect analysis\\n', 'delimiter\\n', 'demodulate\\n', 'demodulation\\n', 'dependability\\n', 'design\\n', 'design description\\n', 'design level\\n', 'design of experiments\\n', 'design phase\\n', 'design requirement\\n', 'design review\\n', 'design specification\\n', 'design standards\\n', 'desk checking\\n', 'detailed design\\n', 'developer\\n', 'development methodology\\n', 'development standards\\n', 'DFD\\n', 'diagnostic\\n', 'different software system analysis\\n', 'digital\\n', 'digital-to-analog converter\\n', 'direct memory access\\n', 'directed graph\\n', 'disk\\n', 'disk drive\\n', 'disk operating system\\n', 'diskette\\n', 'DMA\\n', 'documentation\\n', 'documentation plan\\n', 'documentation\\n', 'DOS\\n', 'drift\\n', 'driver\\n', 'duplex transmission\\n', 'dynamic analysis\\n', 'EBCDIC\\n', 'editing\\n', 'EEPROM\\n', 'electrically erasable programmable read only memory\\n', 'electromagnetic interference\\n', 'electronic media\\n', 'electrostatic discharge\\n', 'embedded computer\\n', 'embedded software\\n', 'EMI\\n', 'emulation\\n', 'emulator\\n', 'encapsulation\\n', 'end user\\n', 'enhanced small device interface\\n', 'entity relationship diagram\\n', 'environment\\n', 'EPROM\\n', 'equivalence class partitioning\\n', 'erasable programmable read only memory\\n', 'error\\n', 'error analysis\\n', 'error detection\\n', 'error guessing\\n', 'error seeding\\n', 'ESD\\n', 'ESDI\\n', 'event table\\n', 'evolutionary development\\n', 'exception\\n', 'exception\\n', 'exception conditions/responses table\\n', 'execution trace\\n', 'extended ASCII\\n', 'extended binary coded decimal interchange code\\n', 'extremal test data\\n', 'Fagan inspection\\n', 'fail-safe\\n', 'failure\\n', 'failure analysis\\n', 'Failure Modes and Effects Analysis\\n', 'Failure Modes and Effects Criticality Analysis\\n', 'fault\\n', 'fault seeding\\n', 'Fault Tree Analysis\\n', 'FDD\\n', 'feasibility study\\n', 'Federal Information Processing Standards\\n', 'fiber optics\\n', 'field\\n', 'file\\n', 'file maintenance\\n', 'file transfer protocol\\n', 'FIPS\\n', 'firmware\\n', 'flag\\n', 'flat file\\n', 'floppy disk\\n', 'floppy disk drive\\n', 'flowchart or flow diagram\\n', 'FMEA\\n', 'FMECA\\n', 'formal qualification review\\n', 'FORTRAN\\n', 'FTA\\n', 'FTP\\n', 'full duplex\\n', 'function\\n', 'functional analysis\\n', 'functional configuration audit\\n', 'functional decomposition\\n', 'functional design\\n', 'functional requirement\\n', 'GB\\n', 'gigabyte\\n', 'graph\\n', 'graphic software specifications\\n', 'half duplex\\n', 'handshake\\n', 'hard copy\\n', 'hard disk drive\\n', 'hard drive\\n', 'hardware\\n', 'hazard\\n', 'hazard analysis\\n', 'hazard probability\\n', 'hazard severity\\n', 'HDD\\n', 'hertz\\n', 'hexadecimal\\n', 'hierarchical decomposition\\n', 'hierarchy of input-processing-output\\n', 'hierarchy of input-processing-output chart\\n', 'high-level language\\n', 'HIPO\\n', 'Hz\\n', 'I/0\\n', 'I/O port\\n', 'IC\\n', 'IDE\\n', 'IEC\\n', 'IEEE\\n', 'implementation\\n', 'implementation phase\\n', 'implementation requirement\\n', 'incremental development\\n', 'incremental integration\\n', 'industry standard\\n', 'infeasible path\\n', 'information hiding\\n', 'input-process-output chart\\n', 'input-processing-output\\n', 'input/output\\n', 'inspection\\n', 'installation\\n', 'installation and checkout phase\\n', 'installation qualification\\n', 'Institute of Electrical and Electronic Engineers\\n', 'instruction\\n', 'instruction set\\n', 'instrumentation\\n', 'integrated circuit\\n', 'integrated drive electronics\\n', 'interactive\\n', 'interface\\n', 'interface analysis\\n', 'interface requirement\\n', 'International Electrotechnical Commission\\n', 'International Organization for Standardization\\n', 'International Standards Organization\\n', 'International Telecommunications Union - Telecommunications Standards Section\\n', 'interpret\\n', 'interpreter\\n', 'interrupt\\n', 'interrupt analyzer\\n', 'invalid inputs\\n', 'ISO\\n', 'ITU-TSS\\n', 'JCL\\n', 'job\\n', 'job control language\\n', 'KB\\n', 'Kermit\\n', 'key\\n', 'key element\\n', 'kilobyte\\n', 'KLOC\\n', 'ladder logic\\n', 'LAN\\n', 'language\\n', 'large scale integration\\n', 'latency\\n', 'latent defect\\n', 'life cycle\\n', 'life cycle methodology\\n', 'linkage editor\\n', 'loader\\n', 'local area network\\n', 'logic analysis\\n', 'longitudinal redundancy check\\n', 'low-level language\\n', 'LSI\\n', 'machine code\\n', 'machine language\\n', 'macro\\n', 'macroinstruction\\n', 'main memory\\n', 'main program\\n', 'mainframe\\n', 'maintainability\\n', 'maintenance\\n', 'MAN\\n', 'MB\\n', 'Mb\\n', 'mean time between failures\\n', 'mean time to failure\\n', 'mean time to repair\\n', 'measurable\\n', 'measure\\n', 'measurement\\n', 'medium scale integration\\n', 'megabit\\n', 'megabyte\\n', 'megahertz\\n', 'memory\\n', 'menu\\n', 'metal-oxide semiconductor\\n', 'metal-oxide semiconductor field effect transistor\\n', 'metric based test data generation\\n', 'metric\\n', 'metropolitan area network\\n', 'MHz\\n', 'microcode\\n', 'microcomputer\\n', 'microprocessor\\n', 'million instructions per second\\n', 'minicomputer\\n', 'MIPS\\n', 'mishap\\n', 'mnemonic\\n', 'modeling\\n', 'modem\\n', 'modem access\\n', 'modifiability\\n', 'modular decomposition\\n', 'modular software\\n', 'modularity\\n', 'modulate\\n', 'modulation\\n', 'module\\n', 'module interface table\\n', 'MOS\\n', 'MOSFET\\n', 'MSI\\n', 'MTBF\\n', 'MTTF\\n', 'MTTR\\n', 'multi-processing\\n', 'multi-programming\\n', 'multi-tasking\\n', 'multiple condition coverage\\n', 'multiplexer\\n', 'multipurpose systems\\n', 'mutation analysis\\n', 'n-channel MOS\\n', 'National Bureau of Standards\\n', 'National Institute for Standards and Technology\\n', 'NBS\\n', 'network\\n', 'network database\\n', 'nibble\\n', 'NIST\\n', 'NMI\\n', 'NMOS\\n', 'node\\n', 'non-maskable interrupt\\n', 'noncritical code analysis\\n', 'nonincremental integration\\n', 'null\\n', 'null data\\n', 'null string\\n', 'object\\n', 'object code\\n', 'object oriented design\\n', 'object oriented language\\n', 'object oriented programming\\n', 'object program\\n', 'OCR\\n', 'octal\\n', 'OEM\\n', 'on-line\\n', 'OOP\\n', 'operating system\\n', 'operation and maintenance phase\\n', 'operation exception\\n', 'operator\\n', 'optical character recognition\\n', 'optical fiber\\n', 'optimization\\n', 'Oracle\\n', 'original equipment manufacturer\\n', 'overflow\\n', 'overflow exception\\n', 'paging\\n', 'PAL\\n', 'parallel\\n', 'parallel processing\\n', 'parameter\\n', 'parity\\n', 'parity bit\\n', 'parity check\\n', 'Pascal\\n', 'password\\n', 'patch\\n', 'path\\n', 'path analysis\\n', 'path coverage\\n', 'PC\\n', 'PCB\\n', 'PDL\\n', 'perfective maintenance\\n', 'performance requirement\\n', 'peripheral device\\n', 'peripheral equipment\\n', 'personal computer\\n', 'physical configuration audit\\n', 'physical requirement\\n', 'pixel\\n', 'PLA\\n', 'platform\\n', 'PLD\\n', 'PMOS\\n', 'polling\\n', 'positive channel MOS\\n', 'precision\\n', 'preliminary design\\n', 'preliminary design review\\n', 'printed circuit board\\n', 'production database\\n', 'program\\n', 'program design language\\n', 'program mutation\\n', 'programmable array logic\\n', 'programmable logic array\\n', 'programmable logic device\\n', 'programmable read only memory\\n', 'programming language\\n', 'programming standards\\n', 'programming style analysis\\n', 'project plan\\n', 'PROM\\n', 'PROM programmer\\n', 'proof of correctness\\n', 'protection exception\\n', 'protocol\\n', 'prototyping\\n', 'pseudocode\\n', 'QA\\n', 'QC\\n', 'qualification\\n', 'quality assurance\\n', 'quality control\\n', 'radiofrequency interference\\n', 'RAM\\n', 'random access memory\\n', 'range check\\n', 'rapid prototyping\\n', 'read only memory\\n', 'real time\\n', 'real time processing\\n', 'record\\n', 'record of change\\n', 'recursion\\n', 'reduced instruction set computer\\n', 'region\\n', 'register\\n', 'regression analysis and testing\\n', 'relational database\\n', 'release\\n', 'reliability\\n', 'reliability assessment\\n', 'requirement\\n', 'requirements analysis\\n', 'requirements phase\\n', 'requirements review\\n', 'retention period\\n', 'retrospective trace\\n', 'revalidation\\n', 'review\\n', 'revision number\\n', 'RFI\\n', 'RISC\\n', 'risk\\n', 'risk assessment\\n', 'robustness\\n', 'ROM\\n', 'routine\\n', 'RS-232-C\\n', 'safety\\n', 'safety critical\\n', 'safety critical computer software components\\n', 'SCSI\\n', 'security\\n', 'sensor\\n', 'serial\\n', 'server\\n', 'service program\\n', 'servomechanism\\n', 'severity\\n', 'side effect\\n', 'simulation\\n', 'simulation analysis\\n', 'simulator\\n', 'sizing\\n', 'sizing and timing analysis\\n', 'small computer systems interface\\n', 'small scale integration\\n', 'software\\n', 'software audit\\n', 'software characteristic\\n', 'software configuration item\\n', 'software design description\\n', 'software developer\\n', 'software development notebook\\n', 'software development plan\\n', 'software development process\\n', 'software diversity\\n', 'software documentation\\n', 'software element\\n', 'software element analysis\\n', 'software engineering\\n', 'software engineering environment\\n', 'software hazard analysis\\n', 'software item\\n', 'software life cycle\\n', 'software reliability\\n', 'software requirements specification\\n', 'software review\\n', 'software safety change analysis\\n', 'software safety code analysis\\n', 'software safety design analysis\\n', 'software safety requirements analysis\\n', 'software safety test analysis\\n', 'SOPs\\n', 'source code\\n', 'source program\\n', 'spaghetti code\\n', 'special test data\\n', 'specification\\n', 'specification analysis\\n', 'specification tree\\n', 'specification\\n', 'spiral model\\n', 'SQL\\n', 'SSI\\n', 'ST-506\\n', 'standard operating procedures\\n', 'state\\n', 'state diagram\\n', 'state-transition table\\n', 'statement coverage\\n', 'static analysis\\n', 'static analyzer\\n', 'stepwise refinement\\n', 'storage device\\n', 'string\\n', 'structure chart\\n', 'structured design\\n', 'structured programming\\n', 'structured query language\\n', 'stub\\n', 'subprogram\\n', 'subroutine\\n', 'subroutine trace\\n', 'support software\\n', 'symbolic execution\\n', 'symbolic trace\\n', 'synchronous\\n', 'synchronous transmission\\n', 'syntax\\n', 'system\\n', 'system administrator\\n', 'system analysis\\n', 'system design\\n', 'system design review\\n', 'system documentation\\n', 'system integration\\n', 'system life cycle\\n', 'system manager\\n', 'system safety\\n', 'system software\\n', 'tape\\n', 'TB\\n', 'TCP/IP\\n', 'telecommunication system\\n', 'terabyte\\n', 'terminal\\n', 'test\\n', 'test case\\n', 'test case generator\\n', 'test design\\n', 'test documentation\\n', 'test driver\\n', 'test harness\\n', 'test incident report\\n', 'test item\\n', 'test log\\n', 'test phase\\n', 'test plan\\n', 'test procedure\\n', 'test readiness review\\n', 'test report\\n', 'test result analyzer\\n', 'testability\\n', 'testing\\n', 'time sharing\\n', 'timing\\n', 'timing analyzer\\n', 'timing and sizing analysis\\n', 'top-down design\\n', 'touch screen\\n', 'touch sensitive\\n', 'trace\\n', 'traceability\\n', 'traceability analysis\\n', 'traceability matrix\\n', 'transaction\\n', 'transaction analysis\\n', 'transaction flowgraph\\n', 'transaction matrix\\n', 'transform analysis\\n', 'translation\\n', 'transmission control protocol\\n', 'Internet protocol\\n', 'trojan horse\\n', 'truth table\\n', 'tuning\\n', 'twisted pair\\n', 'unambiguous\\n', 'underflow\\n', 'underflow exception\\n', 'unit\\n', 'UNIX\\n', 'usability\\n', 'user\\n', \"user's guide\\n\", 'utility program\\n', 'utility software\\n', 'V&V\\n', 'valid\\n', 'valid input\\n', 'validate\\n', 'validation\\n', 'validation protocol\\n', 'variable\\n', 'variable trace\\n', 'VAX\\n', 'vendor\\n', 'verifiable\\n', 'verification\\n', 'verify\\n', 'version\\n', 'version number\\n', 'very large scale integration\\n', 'virtual address extension\\n', 'virtual memory system\\n', 'virus\\n', 'VLSI\\n', 'VMS\\n', 'volume\\n', 'VV&T\\n', 'walkthrough\\n', 'WAN\\n', 'watchdog timer\\n', 'waterfall model\\n', 'white-box testing\\n', 'wide area network\\n', 'word\\n', 'workaround\\n', 'workstation\\n', 'worm\\n', 'Xmodem\\n', 'Ymodem\\n', 'Zmodem\\n', 'A/B testing\\n', 'abnormal end\\n', 'abuse case\\n', 'acceptance  criteria\\n', 'acceptance  testing\\n', 'acceptance test-driven  development\\n', 'accessibility\\n', 'account harvesting\\n', 'accountability\\n', 'acting\\n', 'actual result\\n', 'adaptability\\n', 'adversarial  example\\n', 'adversarial testing\\n', 'Agile Manifesto\\n', 'Agile software development\\n', 'Agile testing\\n', 'agile testing quadrants\\n', 'alpha testing\\n', 'analytical test strategy\\n', 'analyzability\\n', 'anomaly\\n', 'anti-malware\\n', 'anti-pattern\\n', 'API testing\\n', 'appropriateness recognizability\\n', 'assessment  report\\n', 'assessor\\n', 'atomic  condition\\n', 'attack vector\\n', 'attacker\\n', 'audio testing\\n', 'audit\\n', 'authentication\\n', 'authorization\\n', 'automation code defect density\\n', 'automotive  safety integrity level\\n', 'automotive SPICE\\n', 'availability\\n', 'back-to-back  testing\\n', 'balanced scorecard\\n', 'behavior-driven development\\n', 'beta testing\\n', 'black-box test technique\\n', 'botnet\\n', 'boundary  value\\n', 'boundary  value analysis\\n', 'branch\\n', 'bug hunting\\n', 'build verification  test\\n', 'call graph\\n', 'Capability  Maturity Model Integration\\n', 'capacity\\n', 'capacity testing\\n', 'capture/playback\\n', 'cause-effect  diagram\\n', 'cause-effect  graph\\n', 'certification\\n', 'change management\\n', 'change-related testing\\n', 'checklist-based review\\n', 'checklist-based testing\\n', 'classification tree\\n', 'classification tree technique\\n', 'CLI testing\\n', 'closed-loop-system\\n', 'code injection\\n', 'codependent  behavior\\n', 'coding standard\\n', 'combinatorial testing\\n', 'command-line interface\\n', 'commercial off-the-shelf\\n', 'compatibility\\n', 'complexity\\n', 'compliance\\n', 'compliance testing\\n', 'component integration testing\\n', 'computer  forensics\\n', 'concurrency\\n', 'concurrency  testing\\n', 'condition coverage\\n', 'condition testing\\n', 'confidence interval\\n', 'confidentiality\\n', 'configuration  management\\n', 'configuration item\\n', 'confirmation  testing\\n', 'connectivity\\n', 'consultative  test strategy\\n', 'content-based  model\\n', 'context  of use\\n', 'continuous  integration\\n', 'continuous  representation\\n', 'continuous testing\\n', 'contractual  acceptance testing\\n', 'control chart\\n', 'control flow\\n', 'control flow analysis\\n', 'control flow testing\\n', 'convergence  metric\\n', 'corporate  dashboard\\n', 'cost of quality\\n', 'coverage\\n', 'coverage  item\\n', 'coverage criteria\\n', 'critical success factor\\n', 'Critical Testing Processes\\n', 'cross-browser  compatibility\\n', 'cross-site  scripting\\n', 'crowd testing\\n', 'custom  tool\\n', 'cyclomatic  complexity\\n', 'dashboard\\n', 'data  privacy\\n', 'data flow analysis\\n', 'data obfuscation\\n', 'data-driven testing\\n', 'debugging\\n', 'debugging  tool\\n', 'decision\\n', 'decision coverage\\n', 'decision table testing\\n', 'decision testing\\n', 'defect\\n', 'defect  density\\n', 'Defect Detection Percentage\\n', 'defect management\\n', 'defect management committee\\n', 'defect report\\n', 'defect taxonomy\\n', 'defect-based  test technique\\n', 'definition-use pair\\n', 'demilitarized  zone\\n', 'Deming cycle\\n', 'denial of service\\n', 'device-based testing\\n', 'diagnosing\\n', 'driver\\n', 'dynamic  analysis\\n', 'dynamic testing\\n', 'Effect Analysis\\n', 'effectiveness\\n', 'efficiency\\n', 'egon at\\n', 'egon at\\n', 'emotional intelligence\\n', 'emulator\\n', 'encryption\\n', 'end-to-end testing\\n', 'endurance testing\\n', 'entry criteria\\n', 'environment  model\\n', 'epic\\n', 'equivalence  partition\\n', 'equivalence  partitioning\\n', 'equivalent manual test effort\\n', 'error\\n', 'error guessing\\n', 'escaped defect\\n', 'establishing\\n', 'ethical hacker\\n', 'European Foundation for Quality Management  excellence  model\\n', 'exit criteria\\n', 'expected  result\\n', 'experience-based test technique\\n', 'experience-based testing\\n', 'expert usability  review\\n', 'exploratory testing\\n', 'Extreme Programming\\n', 'failed\\n', 'failover\\n', 'failure\\n', 'Failure blade and Effect Analysis\\n', 'failure mode\\n', 'failure rate\\n', 'false-negative result\\n', 'false-positive result\\n', 'fault injection\\n', 'fault seeding\\n', 'fault seeding tool\\n', 'fault tolerance\\n', 'Fault Tree  Analysis\\n', 'feature-driven development\\n', 'field testing\\n', 'finding\\n', 'firewall\\n', 'follow-up test case\\n', 'formal review\\n', 'formative evaluation\\n', 'functional  testing\\n', 'functional appropriateness\\n', 'functional completeness\\n', 'functional correctness\\n', 'functional safety\\n', 'functional suitability\\n', 'fuzz testing\\n', 'generic test automation architecture\\n', 'Goal Question  Metric\\n', 'graphical user interface\\n', 'GUI  testing\\n', 'hacker\\n', 'hardware in the  loop\\n', 'hashing\\n', 'heuristic\\n', 'heuristic  evaluation\\n', 'high-level test case\\n', 'human-centered design\\n', 'hyperlink\\n', 'hyperlink test tool\\n', 'IDEAL\\n', 'impact analysis\\n', 'incremental development  model\\n', 'independence  of testing\\n', 'independent  test lab\\n', 'indicator\\n', 'informal review\\n', 'information assurance\\n', 'initiating\\n', 'input  data testing\\n', 'insider threat\\n', 'insourced  testing\\n', 'inspection\\n', 'installability\\n', 'integration  testing\\n', 'integrity\\n', 'interface testing\\n', 'interoperability\\n', 'intrusion detection  system\\n', 'iterative development  model\\n', 'keyword-driven testing\\n', 'lead assessor\\n', 'learnability\\n', 'learning\\n', 'level of intrusion\\n', 'level test plan\\n', 'linear scripting\\n', 'load generation\\n', 'load generator\\n', 'load management\\n', 'load profile\\n', 'load testing\\n', 'low-level test case\\n', 'maintenance\\n', 'maintenance testing\\n', 'malware\\n', 'malware scanning\\n', 'management  review\\n', 'manufacturing-based quality\\n', 'master test plan\\n', 'math testing\\n', 'maturity\\n', 'maturity level\\n', 'maturity model\\n', 'MBT model\\n', 'mean time between failures\\n', 'mean time to failure\\n', 'mean time to repair\\n', 'measure\\n', 'measurement\\n', 'memory leak\\n', 'metamorphic  relation\\n', 'metamorphic  testing\\n', 'method table\\n', 'methodical  test strategy\\n', 'metric\\n', 'mind map\\n', 'ML functional performance\\n', 'ML functional performance criteria\\n', 'ML functional performance metrics\\n', 'ML model\\n', 'ML model testing\\n', 'model coverage\\n', 'model in the  loop\\n', 'model-based test strategy\\n', 'model-based testing\\n', 'moderator\\n', 'modifiability\\n', 'modified condition/decision coverage\\n', 'modified condition/decision testing\\n', 'modularity\\n', 'monitoring  tool\\n', 'multiplayer testing\\n', 'multiple condition coverage\\n', 'multiple condition testing\\n', 'Myers-Briggs  Type Indicator\\n', 'N-switch coverage\\n', 'negative testing\\n', 'neighborhood  integration testing\\n', 'network zone\\n', 'neuron coverage\\n', 'non-functional testing\\n', 'non-repudiation\\n', 'offline MBT\\n', 'online MBT\\n', 'open-loop-system\\n', 'operability\\n', 'operational  profile\\n', 'operational  profiling\\n', 'operational acceptance  testing\\n', 'outsourced  testing\\n', 'pair testing\\n', 'pairwise  integration  testing\\n', 'par  sheet testing\\n', 'Pareto analysis\\n', 'pass/fail criteria\\n', 'passed\\n', 'password  cracking\\n', 'path\\n', 'path testing\\n', 'peer review\\n', 'penetration testing\\n', 'performance  efficiency\\n', 'performance  indicator\\n', 'performance  testing\\n', 'performance  testing tool\\n', 'perspective-based reading\\n', 'pharming\\n', 'phase containment\\n', 'phishing\\n', 'planning poker\\n', 'player perspective testing\\n', 'pointer\\n', 'portability\\n', 'post-release  testing\\n', 'postcondition\\n', 'precondition\\n', 'priority\\n', 'PRISMA\\n', 'probe effect\\n', 'process assessment\\n', 'process model\\n', 'process-compliant test strategy\\n', 'process-driven scripting\\n', 'product risk\\n', 'product-based  quality\\n', 'project risk\\n', 'proximity-based testing\\n', 'pseudo-oracle\\n', 'quality\\n', 'quality  risk\\n', 'quality assurance\\n', 'quality characteristic\\n', 'quality control\\n', 'quality function  deployment\\n', 'quality management\\n', 'RACI matrix\\n', 'ramp-down\\n', 'ramp-up\\n', 'random testing\\n', 'Rational Unified Process\\n', 'reactive test  strategy\\n', 'reactive testing\\n', 'reconnaissance\\n', 'recoverability\\n', 'regression testing\\n', 'regression-averse test strategy\\n', 'regulatory acceptance testing\\n', 'reliability\\n', 'reliability growth model\\n', 'remote test lab\\n', 'replaceability\\n', 'requirement\\n', 'requirements-based testing\\n', 'resource  utilization\\n', 'retrospective  meeting\\n', 'reusability\\n', 'review\\n', 'review plan\\n', 'reviewer\\n', 'risk\\n', 'risk analysis\\n', 'risk assessment\\n', 'risk identification\\n', 'risk impact\\n', 'risk level\\n', 'risk likelihood\\n', 'risk management\\n', 'risk mitigation\\n', 'risk-based testing\\n', 'robustness\\n', 'role-based  review\\n', 'root cause\\n', 'root cause analysis\\n', 'safety integrity level\\n', 'salting\\n', 'scalability\\n', 'scalability testing\\n', 'scenario-based review\\n', 'scribe\\n', 'script kiddie\\n', 'scripted testing\\n', 'scrum\\n', 'security\\n', 'security  testing\\n', 'security attack\\n', 'security audit\\n', 'security policy\\n', 'security procedure\\n', 'security risk\\n', 'security vulnerability\\n', 'sequential development  model\\n', 'service virtualization\\n', 'session-based  test  management\\n', 'session-based  testing\\n', 'severity\\n', 'short-circuiting\\n', 'sign change coverage\\n', 'sign-sign coverage\\n', 'simulator\\n', 'smoke test\\n', 'social engineering\\n', 'softwa  e development  lifecycle\\n', 'software  in the  loop\\n', 'software  lifecycle\\n', 'software  process  improvement\\n', 'software qualification  test\\n', 'Software Usability Measurement  Inventory\\n', 'source test case\\n', 'specification  by  example\\n', 'spike testing\\n', 'SQL injection\\n', 'staged representation\\n', 'standard\\n', 'standard-compliant test strategy\\n', 'state transition testing\\n', 'statement\\n', 'statement coverage\\n', 'statement testing\\n', 'static  analysis\\n', 'static testing\\n', 'stress testing\\n', 'structural coverage\\n', 'structured  scripting\\n', 'stub\\n', 'summative  evaluation\\n', 'System  Usability  Scale\\n', 'system hardening\\n', 'system integration testing\\n', 'system of  systems\\n', 'system qualification test\\n', 'system testing\\n', 'system under test\\n', 'Systematic  Test  and Evaluation  Process\\n', 'technical review\\n', 'test\\n', 'test adaptation layer\\n', 'test analysis\\n', 'test approach\\n', 'test architect\\n', 'test automation\\n', 'test automation  architecture\\n', 'test automation  engineer\\n', 'test automation  framework\\n', 'test automation  manager\\n', 'test automation  solution\\n', 'test automation  strategy\\n', 'test basis\\n', 'test case\\n', 'test case explosion\\n', 'test charter\\n', 'test closure\\n', 'test completion\\n', 'test completion report\\n', 'test condition\\n', 'test control\\n', 'test cycle\\n', 'test data\\n', 'test data preparation\\n', 'test data preparation  tool\\n', 'test definition layer\\n', 'test design\\n', 'test design specification\\n', 'test director\\n', 'test environment\\n', 'test estimation\\n', 'test execution\\n', 'test execution  schedule\\n', 'test execution automation\\n', 'test execution layer\\n', 'test execution tool\\n', 'test generation  layer\\n', 'test harness\\n', 'test hook\\n', 'test implementation\\n', 'test improvement  plan\\n', 'test infrastructure\\n', 'test item\\n', 'test leader\\n', 'test level\\n', 'test log\\n', 'test logging\\n', 'test management\\n', 'test management tool\\n', 'test manager\\n', 'Test Maturity Model integration\\n', 'test mission\\n', 'test model\\n', 'test monitoring\\n', 'test object\\n', 'test objective\\n', 'test plan\\n', 'test planning\\n', 'Test Point Analysis\\n', 'test policy\\n', 'test procedure\\n', 'test process\\n', 'test process  improvement  manifesto\\n', 'test process improvement\\n', 'test process improver\\n', 'test progress report\\n', 'test pyramid\\n', 'test report\\n', 'test reporting\\n', 'test result\\n', 'test run\\n', 'test schedule\\n', 'test script\\n', 'test selection criteria\\n', 'test session\\n', 'test specification\\n', 'test strategy\\n', 'test suite\\n', 'test technique\\n', 'test tool\\n', 'test type\\n', 'test-driven development\\n', 'test-first approach\\n', 'testability\\n', 'tester\\n', 'testing\\n', 'testware\\n', 'think aloud usability testing\\n', 'think time\\n', 'threshold  coverage\\n', 'time behavior\\n', 'Total Quality  Management\\n', 'tour\\n', 'TPI  Next\\n', 'traceability\\n', 'traceability  matrix\\n', 'transactional analysis\\n', 'transcendent-based quality\\n', 'unit test framework\\n', 'usability\\n', 'usability  evaluation\\n', 'usability  lab\\n', 'usability  requirement\\n', 'usability test participant\\n', 'usability test script\\n', 'usability test session\\n', 'usability test task\\n', 'usability testing\\n', 'user  interface\\n', 'user acceptance  testing\\n', 'user error  protection\\n', 'user experience\\n', 'user interface aesthetics\\n', 'user interface guideline\\n', 'user story\\n', 'user story testing\\n', 'user survey\\n', 'user-agent based testing\\n', 'user-based  quality\\n', 'V-model\\n', 'validation\\n', 'value change coverage\\n', 'value-based  quality\\n', 'values of several parameters\\n', 'verification\\n', 'virtual test environment\\n', 'virtual user\\n', 'visual testing\\n', 'vulnerability  scanner\\n', 'walkthrough\\n', 'Web Content  Accessibility  Guidelines\\n', 'Website Analysis and Measurement  Inventory\\n', 'white-box  test technique\\n', 'white-box testing\\n', 'Wideband  Delphi\\n', 'wild pointer\\n', 'XiL  test environment\\n']\n",
            "1543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRIV_yn5Inrh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1970511b-0123-4fe9-e2eb-fb3e0d63cb92"
      },
      "source": [
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type=='train'].summary.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=512, #256\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type=='val'].summary.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=512, #256\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(df[df.data_type=='val'].label.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi0fSX43Inrk"
      },
      "source": [
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSOqSf20Inrm",
        "outputId": "ff8b83ef-3996-408e-a842-68055802dc39"
      },
      "source": [
        "len(dataset_train), len(dataset_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(586, 104)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "81afe9d03b924f9386967bf85525a126",
            "082a8f8bd1ac4431b1c27fc058481a16",
            "c7e3e9bc35c845ddac17e5200017e5f4",
            "ac3a788f71564cecac783e9227d4fcaa",
            "c6ca7cc820d5440f893b09dce1f19242",
            "6a31dbed9efd4a738da740424b776e3c",
            "e8dd51dd5c0d4fdca45b5db418b30bda",
            "2841c57a9e92411cbeae549d673316e1",
            "2f710842104c4864bd335a4637fa7b78",
            "9be7727650e34e3398b3f01559835410",
            "141cadc927864bca9a80264e029ce9a1"
          ]
        },
        "id": "o8NRA_j2Inrr",
        "outputId": "96a0c4ca-5651-41a8-e29a-6951b8043569"
      },
      "source": [
        "#model = BertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", #\"allenai/scibert_scivocab_uncased\", #\"bert-base-uncased\",\n",
        "#                                                      num_labels=len(label_dict),\n",
        "#                                                      output_attentions=False,\n",
        "#                                                      output_hidden_states=False)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-base\", #\"allenai/scibert_scivocab_uncased\", #\"bert-base-uncased\",\n",
        "                                                            num_labels=len(label_dict),\n",
        "                                                            output_attentions=False,\n",
        "                                                            output_hidden_states=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81afe9d03b924f9386967bf85525a126",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Mfi7gVzDFAG",
        "outputId": "5a9a3f5b-714f-4fa1-c06c-9d1b9eb63af8"
      },
      "source": [
        "print(\"[ BEFORE ] tokenizer vocab size:\", len(tokenizer))\n",
        "added_tokens = tokenizer.add_tokens(new_tokens)\n",
        "\n",
        "print(\"[ AFTER ] tokenizer vocab size:\", len(tokenizer))\n",
        "print()\n",
        "print('added_tokens:',added_tokens)\n",
        "print()\n",
        "\n",
        "# resize the embeddings matrix of the model\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ BEFORE ] tokenizer vocab size: 30522\n",
            "[ AFTER ] tokenizer vocab size: 31948\n",
            "\n",
            "added_tokens: 1426\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(31948, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHno3bWzInrv"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 3\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train,\n",
        "                              sampler=RandomSampler(dataset_train),\n",
        "                              batch_size=batch_size)\n",
        "\n",
        "dataloader_validation = DataLoader(dataset_val,\n",
        "                                   sampler=SequentialSampler(dataset_val),\n",
        "                                   batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVxhNH0CInrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d84d58f2-0905-4dc2-a4c4-0c24ddd1f0ea"
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=1e-5,\n",
        "                  eps=1e-8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yyd6VE3Inrz"
      },
      "source": [
        "epochs = 5\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=len(dataloader_train)*epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xtxw9fyBInr2"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
        "\n",
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQNkQTBhInr5"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhZwaykYInr7",
        "outputId": "8f76275b-27dc-40a5-9cee-34af729b84ee"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6t4vsdjInr_"
      },
      "source": [
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "\n",
        "    for batch in dataloader_val:\n",
        "\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "\n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "\n",
        "    loss_val_avg = loss_val_total/len(dataloader_val)\n",
        "\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "\n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tAQsG84InsD",
        "outputId": "9161c1ac-2de1-4b77-d782-90eb73ecf474"
      },
      "source": [
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    loss_train_total = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
        "    for batch in progress_bar:\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "\n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        loss_train_total += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "\n",
        "\n",
        "    torch.save(model.state_dict(), f'finetuned_BERT_epoch_{epoch}.model')\n",
        "\n",
        "    tqdm.write(f'\\nEpoch {epoch}')\n",
        "\n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "\n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score (Weighted): {val_f1}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]\n",
            "Epoch 1:   0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 0/196 [00:09<?, ?it/s, training_loss=0.360]\u001b[A\n",
            "Epoch 1:   1%|          | 1/196 [00:09<29:36,  9.11s/it, training_loss=0.360]\u001b[A\n",
            "Epoch 1:   1%|          | 1/196 [00:17<29:36,  9.11s/it, training_loss=0.347]\u001b[A\n",
            "Epoch 1:   1%|          | 2/196 [00:17<28:44,  8.89s/it, training_loss=0.347]\u001b[A\n",
            "Epoch 1:   1%|          | 2/196 [00:26<28:44,  8.89s/it, training_loss=0.366]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3/196 [00:26<27:47,  8.64s/it, training_loss=0.366]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3/196 [00:34<27:47,  8.64s/it, training_loss=0.348]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4/196 [00:34<27:17,  8.53s/it, training_loss=0.348]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4/196 [00:42<27:17,  8.53s/it, training_loss=0.363]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5/196 [00:42<26:55,  8.46s/it, training_loss=0.363]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5/196 [00:51<26:55,  8.46s/it, training_loss=0.391]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6/196 [00:51<26:35,  8.39s/it, training_loss=0.391]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6/196 [00:59<26:35,  8.39s/it, training_loss=0.377]\u001b[A\n",
            "Epoch 1:   4%|▎         | 7/196 [00:59<26:22,  8.38s/it, training_loss=0.377]\u001b[A\n",
            "Epoch 1:   4%|▎         | 7/196 [01:07<26:22,  8.38s/it, training_loss=0.405]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8/196 [01:07<26:14,  8.37s/it, training_loss=0.405]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8/196 [01:16<26:14,  8.37s/it, training_loss=0.373]\u001b[A\n",
            "Epoch 1:   5%|▍         | 9/196 [01:16<26:02,  8.35s/it, training_loss=0.373]\u001b[A\n",
            "Epoch 1:   5%|▍         | 9/196 [01:24<26:02,  8.35s/it, training_loss=0.388]\u001b[A\n",
            "Epoch 1:   5%|▌         | 10/196 [01:24<25:48,  8.33s/it, training_loss=0.388]\u001b[A\n",
            "Epoch 1:   5%|▌         | 10/196 [01:32<25:48,  8.33s/it, training_loss=0.344]\u001b[A\n",
            "Epoch 1:   6%|▌         | 11/196 [01:32<25:37,  8.31s/it, training_loss=0.344]\u001b[A\n",
            "Epoch 1:   6%|▌         | 11/196 [01:40<25:37,  8.31s/it, training_loss=0.380]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12/196 [01:40<25:26,  8.29s/it, training_loss=0.380]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12/196 [01:49<25:26,  8.29s/it, training_loss=0.336]\u001b[A\n",
            "Epoch 1:   7%|▋         | 13/196 [01:49<25:12,  8.27s/it, training_loss=0.336]\u001b[A\n",
            "Epoch 1:   7%|▋         | 13/196 [01:57<25:12,  8.27s/it, training_loss=0.345]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14/196 [01:57<25:04,  8.27s/it, training_loss=0.345]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14/196 [02:05<25:04,  8.27s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 1:   8%|▊         | 15/196 [02:05<24:52,  8.24s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 1:   8%|▊         | 15/196 [02:13<24:52,  8.24s/it, training_loss=0.363]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16/196 [02:13<24:44,  8.25s/it, training_loss=0.363]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16/196 [02:22<24:44,  8.25s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 1:   9%|▊         | 17/196 [02:22<24:41,  8.28s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 1:   9%|▊         | 17/196 [02:30<24:41,  8.28s/it, training_loss=0.339]\u001b[A\n",
            "Epoch 1:   9%|▉         | 18/196 [02:30<24:23,  8.22s/it, training_loss=0.339]\u001b[A\n",
            "Epoch 1:   9%|▉         | 18/196 [02:38<24:23,  8.22s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 1:  10%|▉         | 19/196 [02:38<24:11,  8.20s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 1:  10%|▉         | 19/196 [02:46<24:11,  8.20s/it, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  10%|█         | 20/196 [02:46<24:02,  8.20s/it, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  10%|█         | 20/196 [02:54<24:02,  8.20s/it, training_loss=0.364]\u001b[A\n",
            "Epoch 1:  11%|█         | 21/196 [02:54<23:52,  8.19s/it, training_loss=0.364]\u001b[A\n",
            "Epoch 1:  11%|█         | 21/196 [03:03<23:52,  8.19s/it, training_loss=0.351]\u001b[A\n",
            "Epoch 1:  11%|█         | 22/196 [03:03<23:44,  8.19s/it, training_loss=0.351]\u001b[A\n",
            "Epoch 1:  11%|█         | 22/196 [03:11<23:44,  8.19s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 23/196 [03:11<23:32,  8.16s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 23/196 [03:19<23:32,  8.16s/it, training_loss=0.371]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 24/196 [03:19<23:23,  8.16s/it, training_loss=0.371]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 24/196 [03:27<23:23,  8.16s/it, training_loss=0.350]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 25/196 [03:27<23:14,  8.16s/it, training_loss=0.350]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 25/196 [03:35<23:14,  8.16s/it, training_loss=0.345]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 26/196 [03:35<23:06,  8.16s/it, training_loss=0.345]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 26/196 [03:43<23:06,  8.16s/it, training_loss=0.340]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 27/196 [03:43<23:00,  8.17s/it, training_loss=0.340]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 27/196 [03:52<23:00,  8.17s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 28/196 [03:52<23:02,  8.23s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 28/196 [04:00<23:02,  8.23s/it, training_loss=0.370]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 29/196 [04:00<23:05,  8.30s/it, training_loss=0.370]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 29/196 [04:08<23:05,  8.30s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 30/196 [04:09<23:02,  8.33s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 30/196 [04:17<23:02,  8.33s/it, training_loss=0.366]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 31/196 [04:17<22:56,  8.34s/it, training_loss=0.366]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 31/196 [04:25<22:56,  8.34s/it, training_loss=0.393]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 32/196 [04:25<22:49,  8.35s/it, training_loss=0.393]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 32/196 [04:34<22:49,  8.35s/it, training_loss=0.380]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 33/196 [04:34<22:47,  8.39s/it, training_loss=0.380]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 33/196 [04:42<22:47,  8.39s/it, training_loss=0.353]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 34/196 [04:42<22:40,  8.40s/it, training_loss=0.353]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 34/196 [04:51<22:40,  8.40s/it, training_loss=0.408]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 35/196 [04:51<22:36,  8.43s/it, training_loss=0.408]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 35/196 [04:59<22:36,  8.43s/it, training_loss=0.339]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 36/196 [04:59<22:27,  8.42s/it, training_loss=0.339]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 36/196 [05:07<22:27,  8.42s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 37/196 [05:07<22:10,  8.37s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 37/196 [05:15<22:10,  8.37s/it, training_loss=0.360]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 38/196 [05:15<21:50,  8.29s/it, training_loss=0.360]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 38/196 [05:23<21:50,  8.29s/it, training_loss=0.320]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 39/196 [05:24<21:32,  8.23s/it, training_loss=0.320]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 39/196 [05:32<21:32,  8.23s/it, training_loss=0.327]\u001b[A\n",
            "Epoch 1:  20%|██        | 40/196 [05:32<21:22,  8.22s/it, training_loss=0.327]\u001b[A\n",
            "Epoch 1:  20%|██        | 40/196 [05:40<21:22,  8.22s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:  21%|██        | 41/196 [05:40<21:11,  8.20s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:  21%|██        | 41/196 [05:48<21:11,  8.20s/it, training_loss=0.360]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 42/196 [05:48<20:57,  8.17s/it, training_loss=0.360]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 42/196 [05:56<20:57,  8.17s/it, training_loss=0.332]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 43/196 [05:56<20:49,  8.17s/it, training_loss=0.332]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 43/196 [06:04<20:49,  8.17s/it, training_loss=0.381]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 44/196 [06:04<20:43,  8.18s/it, training_loss=0.381]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 44/196 [06:13<20:43,  8.18s/it, training_loss=0.342]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 45/196 [06:13<20:39,  8.21s/it, training_loss=0.342]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 45/196 [06:21<20:39,  8.21s/it, training_loss=0.329]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 46/196 [06:21<20:31,  8.21s/it, training_loss=0.329]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 46/196 [06:29<20:31,  8.21s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 47/196 [06:29<20:26,  8.23s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 47/196 [06:37<20:26,  8.23s/it, training_loss=0.397]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 48/196 [06:37<20:24,  8.27s/it, training_loss=0.397]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 48/196 [06:46<20:24,  8.27s/it, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 49/196 [06:46<20:23,  8.32s/it, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 49/196 [06:54<20:23,  8.32s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 50/196 [06:54<20:20,  8.36s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 50/196 [07:02<20:20,  8.36s/it, training_loss=0.398]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 51/196 [07:02<20:03,  8.30s/it, training_loss=0.398]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 51/196 [07:11<20:03,  8.30s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 52/196 [07:11<19:49,  8.26s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 52/196 [07:19<19:49,  8.26s/it, training_loss=0.385]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 53/196 [07:19<19:40,  8.25s/it, training_loss=0.385]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 53/196 [07:27<19:40,  8.25s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 54/196 [07:27<19:31,  8.25s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 54/196 [07:35<19:31,  8.25s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 55/196 [07:35<19:26,  8.27s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 55/196 [07:44<19:26,  8.27s/it, training_loss=0.342]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 56/196 [07:44<19:18,  8.28s/it, training_loss=0.342]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 56/196 [07:52<19:18,  8.28s/it, training_loss=0.375]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 57/196 [07:52<19:11,  8.28s/it, training_loss=0.375]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 57/196 [08:00<19:11,  8.28s/it, training_loss=0.349]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 58/196 [08:00<19:01,  8.27s/it, training_loss=0.349]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 58/196 [08:09<19:01,  8.27s/it, training_loss=0.366]\u001b[A\n",
            "Epoch 1:  30%|███       | 59/196 [08:09<18:53,  8.27s/it, training_loss=0.366]\u001b[A\n",
            "Epoch 1:  30%|███       | 59/196 [08:17<18:53,  8.27s/it, training_loss=0.371]\u001b[A\n",
            "Epoch 1:  31%|███       | 60/196 [08:17<18:44,  8.27s/it, training_loss=0.371]\u001b[A\n",
            "Epoch 1:  31%|███       | 60/196 [08:25<18:44,  8.27s/it, training_loss=0.347]\u001b[A\n",
            "Epoch 1:  31%|███       | 61/196 [08:25<18:35,  8.26s/it, training_loss=0.347]\u001b[A\n",
            "Epoch 1:  31%|███       | 61/196 [08:33<18:35,  8.26s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 62/196 [08:33<18:26,  8.25s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 62/196 [08:41<18:26,  8.25s/it, training_loss=0.348]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 63/196 [08:41<18:12,  8.22s/it, training_loss=0.348]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 63/196 [08:50<18:12,  8.22s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 64/196 [08:50<18:00,  8.19s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 64/196 [08:58<18:00,  8.19s/it, training_loss=0.403]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 65/196 [08:58<17:49,  8.17s/it, training_loss=0.403]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 65/196 [09:06<17:49,  8.17s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 66/196 [09:06<17:43,  8.18s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 66/196 [09:14<17:43,  8.18s/it, training_loss=0.370]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 67/196 [09:14<17:31,  8.15s/it, training_loss=0.370]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 67/196 [09:22<17:31,  8.15s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 68/196 [09:22<17:22,  8.15s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 68/196 [09:30<17:22,  8.15s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 69/196 [09:30<17:14,  8.15s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 69/196 [09:38<17:14,  8.15s/it, training_loss=0.336]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 70/196 [09:38<17:08,  8.16s/it, training_loss=0.336]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 70/196 [09:46<17:08,  8.16s/it, training_loss=0.389]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 71/196 [09:46<16:55,  8.13s/it, training_loss=0.389]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 71/196 [09:55<16:55,  8.13s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 72/196 [09:55<16:50,  8.15s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 72/196 [10:03<16:50,  8.15s/it, training_loss=0.363]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 73/196 [10:03<16:44,  8.17s/it, training_loss=0.363]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 73/196 [10:11<16:44,  8.17s/it, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 74/196 [10:11<16:36,  8.16s/it, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 74/196 [10:19<16:36,  8.16s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 75/196 [10:19<16:27,  8.16s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 75/196 [10:27<16:27,  8.16s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 76/196 [10:27<16:19,  8.16s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 76/196 [10:36<16:19,  8.16s/it, training_loss=0.376]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 77/196 [10:36<16:13,  8.18s/it, training_loss=0.376]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 77/196 [10:44<16:13,  8.18s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 78/196 [10:44<16:03,  8.17s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 78/196 [10:52<16:03,  8.17s/it, training_loss=0.434]\u001b[A\n",
            "Epoch 1:  40%|████      | 79/196 [10:52<15:55,  8.17s/it, training_loss=0.434]\u001b[A\n",
            "Epoch 1:  40%|████      | 79/196 [11:00<15:55,  8.17s/it, training_loss=0.375]\u001b[A\n",
            "Epoch 1:  41%|████      | 80/196 [11:00<15:50,  8.19s/it, training_loss=0.375]\u001b[A\n",
            "Epoch 1:  41%|████      | 80/196 [11:08<15:50,  8.19s/it, training_loss=0.368]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 81/196 [11:08<15:45,  8.22s/it, training_loss=0.368]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 81/196 [11:17<15:45,  8.22s/it, training_loss=0.272]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 82/196 [11:17<15:35,  8.20s/it, training_loss=0.272]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 82/196 [11:25<15:35,  8.20s/it, training_loss=0.369]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 83/196 [11:25<15:26,  8.20s/it, training_loss=0.369]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 83/196 [11:33<15:26,  8.20s/it, training_loss=0.320]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 84/196 [11:33<15:17,  8.19s/it, training_loss=0.320]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 84/196 [11:41<15:17,  8.19s/it, training_loss=0.375]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 85/196 [11:41<15:07,  8.17s/it, training_loss=0.375]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 85/196 [11:49<15:07,  8.17s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 86/196 [11:49<14:57,  8.15s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 86/196 [11:57<14:57,  8.15s/it, training_loss=0.381]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 87/196 [11:57<14:50,  8.17s/it, training_loss=0.381]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 87/196 [12:06<14:50,  8.17s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 88/196 [12:06<14:41,  8.16s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 88/196 [12:14<14:41,  8.16s/it, training_loss=0.423]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 89/196 [12:14<14:33,  8.17s/it, training_loss=0.423]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 89/196 [12:22<14:33,  8.17s/it, training_loss=0.390]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 90/196 [12:22<14:24,  8.15s/it, training_loss=0.390]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 90/196 [12:30<14:24,  8.15s/it, training_loss=0.461]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 91/196 [12:30<14:12,  8.12s/it, training_loss=0.461]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 91/196 [12:38<14:12,  8.12s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 92/196 [12:38<14:04,  8.12s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 92/196 [12:46<14:04,  8.12s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 93/196 [12:46<13:56,  8.12s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 93/196 [12:54<13:56,  8.12s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 94/196 [12:54<13:47,  8.11s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 94/196 [13:02<13:47,  8.11s/it, training_loss=0.342]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 95/196 [13:02<13:39,  8.11s/it, training_loss=0.342]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 95/196 [13:10<13:39,  8.11s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 96/196 [13:10<13:30,  8.10s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 96/196 [13:19<13:30,  8.10s/it, training_loss=0.285]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 97/196 [13:19<13:21,  8.10s/it, training_loss=0.285]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 97/196 [13:27<13:21,  8.10s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  50%|█████     | 98/196 [13:27<13:14,  8.11s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  50%|█████     | 98/196 [13:35<13:14,  8.11s/it, training_loss=0.412]\u001b[A\n",
            "Epoch 1:  51%|█████     | 99/196 [13:35<13:08,  8.12s/it, training_loss=0.412]\u001b[A\n",
            "Epoch 1:  51%|█████     | 99/196 [13:43<13:08,  8.12s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  51%|█████     | 100/196 [13:43<12:59,  8.12s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  51%|█████     | 100/196 [13:51<12:59,  8.12s/it, training_loss=0.342]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 101/196 [13:51<12:51,  8.13s/it, training_loss=0.342]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 101/196 [13:59<12:51,  8.13s/it, training_loss=0.321]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 102/196 [13:59<12:43,  8.12s/it, training_loss=0.321]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 102/196 [14:07<12:43,  8.12s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 103/196 [14:07<12:37,  8.14s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 103/196 [14:16<12:37,  8.14s/it, training_loss=0.383]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 104/196 [14:16<12:31,  8.16s/it, training_loss=0.383]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 104/196 [14:24<12:31,  8.16s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 105/196 [14:24<12:24,  8.19s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 105/196 [14:32<12:24,  8.19s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 106/196 [14:32<12:18,  8.21s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 106/196 [14:40<12:18,  8.21s/it, training_loss=0.361]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 107/196 [14:40<12:11,  8.22s/it, training_loss=0.361]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 107/196 [14:49<12:11,  8.22s/it, training_loss=0.334]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 108/196 [14:49<12:02,  8.21s/it, training_loss=0.334]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 108/196 [14:57<12:02,  8.21s/it, training_loss=0.361]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 109/196 [14:57<11:51,  8.18s/it, training_loss=0.361]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 109/196 [15:05<11:51,  8.18s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 110/196 [15:05<11:42,  8.17s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 110/196 [15:13<11:42,  8.17s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 111/196 [15:13<11:32,  8.15s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 111/196 [15:21<11:32,  8.15s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 112/196 [15:21<11:23,  8.13s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 112/196 [15:29<11:23,  8.13s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 113/196 [15:29<11:13,  8.12s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 113/196 [15:37<11:13,  8.12s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 114/196 [15:37<11:06,  8.13s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 114/196 [15:45<11:06,  8.13s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 115/196 [15:45<10:56,  8.11s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 115/196 [15:53<10:56,  8.11s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 116/196 [15:53<10:48,  8.11s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 116/196 [16:02<10:48,  8.11s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 117/196 [16:02<10:42,  8.13s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 117/196 [16:10<10:42,  8.13s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 1:  60%|██████    | 118/196 [16:10<10:33,  8.12s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 1:  60%|██████    | 118/196 [16:18<10:33,  8.12s/it, training_loss=0.303]\u001b[A\n",
            "Epoch 1:  61%|██████    | 119/196 [16:18<10:25,  8.13s/it, training_loss=0.303]\u001b[A\n",
            "Epoch 1:  61%|██████    | 119/196 [16:26<10:25,  8.13s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 1:  61%|██████    | 120/196 [16:26<10:16,  8.11s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 1:  61%|██████    | 120/196 [16:34<10:16,  8.11s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 121/196 [16:34<10:07,  8.10s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 121/196 [16:42<10:07,  8.10s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 122/196 [16:42<09:59,  8.10s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 122/196 [16:50<09:59,  8.10s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 123/196 [16:50<09:48,  8.06s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 123/196 [16:58<09:48,  8.06s/it, training_loss=0.317]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 124/196 [16:58<09:38,  8.03s/it, training_loss=0.317]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 124/196 [17:06<09:38,  8.03s/it, training_loss=0.340]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 125/196 [17:06<09:29,  8.02s/it, training_loss=0.340]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 125/196 [17:14<09:29,  8.02s/it, training_loss=0.393]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 126/196 [17:14<09:20,  8.00s/it, training_loss=0.393]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 126/196 [17:22<09:20,  8.00s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 127/196 [17:22<09:10,  7.98s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 127/196 [17:30<09:10,  7.98s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 128/196 [17:30<09:02,  7.97s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 128/196 [17:38<09:02,  7.97s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 129/196 [17:38<08:55,  8.00s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 129/196 [17:46<08:55,  8.00s/it, training_loss=0.392]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 130/196 [17:46<08:48,  8.00s/it, training_loss=0.392]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 130/196 [17:54<08:48,  8.00s/it, training_loss=0.317]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 131/196 [17:54<08:40,  8.00s/it, training_loss=0.317]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 131/196 [18:02<08:40,  8.00s/it, training_loss=0.393]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 132/196 [18:02<08:33,  8.02s/it, training_loss=0.393]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 132/196 [18:10<08:33,  8.02s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 133/196 [18:10<08:27,  8.05s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 133/196 [18:18<08:27,  8.05s/it, training_loss=0.417]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 134/196 [18:18<08:20,  8.07s/it, training_loss=0.417]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 134/196 [18:26<08:20,  8.07s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 135/196 [18:26<08:12,  8.07s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 135/196 [18:34<08:12,  8.07s/it, training_loss=0.370]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 136/196 [18:34<08:04,  8.08s/it, training_loss=0.370]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 136/196 [18:42<08:04,  8.08s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 137/196 [18:42<07:57,  8.10s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 137/196 [18:51<07:57,  8.10s/it, training_loss=0.339]\u001b[A\n",
            "Epoch 1:  70%|███████   | 138/196 [18:51<07:49,  8.10s/it, training_loss=0.339]\u001b[A\n",
            "Epoch 1:  70%|███████   | 138/196 [18:59<07:49,  8.10s/it, training_loss=0.338]\u001b[A\n",
            "Epoch 1:  71%|███████   | 139/196 [18:59<07:42,  8.11s/it, training_loss=0.338]\u001b[A\n",
            "Epoch 1:  71%|███████   | 139/196 [19:07<07:42,  8.11s/it, training_loss=0.361]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 140/196 [19:07<07:35,  8.14s/it, training_loss=0.361]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 140/196 [19:15<07:35,  8.14s/it, training_loss=0.388]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 141/196 [19:15<07:26,  8.13s/it, training_loss=0.388]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 141/196 [19:23<07:26,  8.13s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 142/196 [19:23<07:17,  8.10s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 142/196 [19:31<07:17,  8.10s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 143/196 [19:31<07:08,  8.09s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 143/196 [19:39<07:08,  8.09s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 144/196 [19:39<07:02,  8.12s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 144/196 [19:47<07:02,  8.12s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 145/196 [19:47<06:54,  8.12s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 145/196 [19:55<06:54,  8.12s/it, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 146/196 [19:56<06:45,  8.10s/it, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 146/196 [20:03<06:45,  8.10s/it, training_loss=0.393]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 147/196 [20:04<06:35,  8.07s/it, training_loss=0.393]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 147/196 [20:12<06:35,  8.07s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 148/196 [20:12<06:27,  8.07s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 148/196 [20:20<06:27,  8.07s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 149/196 [20:20<06:18,  8.05s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 149/196 [20:28<06:18,  8.05s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 150/196 [20:28<06:10,  8.04s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 150/196 [20:36<06:10,  8.04s/it, training_loss=0.437]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 151/196 [20:36<06:02,  8.05s/it, training_loss=0.437]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 151/196 [20:44<06:02,  8.05s/it, training_loss=0.340]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 152/196 [20:44<05:52,  8.02s/it, training_loss=0.340]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 152/196 [20:52<05:52,  8.02s/it, training_loss=0.417]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 153/196 [20:52<05:44,  8.02s/it, training_loss=0.417]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 153/196 [21:00<05:44,  8.02s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 154/196 [21:00<05:37,  8.02s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 154/196 [21:08<05:37,  8.02s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 155/196 [21:08<05:29,  8.03s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 155/196 [21:16<05:29,  8.03s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 156/196 [21:16<05:21,  8.03s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 156/196 [21:24<05:21,  8.03s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  80%|████████  | 157/196 [21:24<05:13,  8.03s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  80%|████████  | 157/196 [21:32<05:13,  8.03s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  81%|████████  | 158/196 [21:32<05:04,  8.01s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  81%|████████  | 158/196 [21:40<05:04,  8.01s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  81%|████████  | 159/196 [21:40<04:57,  8.03s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  81%|████████  | 159/196 [21:48<04:57,  8.03s/it, training_loss=0.373]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 160/196 [21:48<04:48,  8.01s/it, training_loss=0.373]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 160/196 [21:56<04:48,  8.01s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 161/196 [21:56<04:40,  8.02s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 161/196 [22:04<04:40,  8.02s/it, training_loss=0.405]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 162/196 [22:04<04:33,  8.04s/it, training_loss=0.405]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 162/196 [22:12<04:33,  8.04s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 163/196 [22:12<04:25,  8.05s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 163/196 [22:20<04:25,  8.05s/it, training_loss=0.364]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 164/196 [22:20<04:17,  8.05s/it, training_loss=0.364]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 164/196 [22:28<04:17,  8.05s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 165/196 [22:28<04:09,  8.03s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 165/196 [22:36<04:09,  8.03s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 166/196 [22:36<04:00,  8.02s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 166/196 [22:44<04:00,  8.02s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 167/196 [22:44<03:52,  8.02s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 167/196 [22:52<03:52,  8.02s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 168/196 [22:52<03:44,  8.01s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 168/196 [23:00<03:44,  8.01s/it, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 169/196 [23:00<03:36,  8.01s/it, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 169/196 [23:08<03:36,  8.01s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 170/196 [23:08<03:28,  8.03s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 170/196 [23:16<03:28,  8.03s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 171/196 [23:16<03:19,  8.00s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 171/196 [23:24<03:19,  8.00s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 172/196 [23:24<03:11,  7.98s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 172/196 [23:32<03:11,  7.98s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 173/196 [23:32<03:03,  7.98s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 173/196 [23:40<03:03,  7.98s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 174/196 [23:40<02:56,  8.01s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 174/196 [23:48<02:56,  8.01s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 175/196 [23:48<02:48,  8.01s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 175/196 [23:56<02:48,  8.01s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 176/196 [23:56<02:40,  8.03s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 176/196 [24:04<02:40,  8.03s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 177/196 [24:04<02:32,  8.05s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 177/196 [24:12<02:32,  8.05s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 178/196 [24:12<02:24,  8.04s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 178/196 [24:20<02:24,  8.04s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 179/196 [24:20<02:16,  8.03s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 179/196 [24:28<02:16,  8.03s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 180/196 [24:28<02:08,  8.04s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 180/196 [24:36<02:08,  8.04s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 181/196 [24:36<02:00,  8.06s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 181/196 [24:44<02:00,  8.06s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 182/196 [24:44<01:52,  8.05s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 182/196 [24:52<01:52,  8.05s/it, training_loss=0.310]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 183/196 [24:53<01:44,  8.06s/it, training_loss=0.310]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 183/196 [25:01<01:44,  8.06s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 184/196 [25:01<01:36,  8.07s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 184/196 [25:09<01:36,  8.07s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 185/196 [25:09<01:28,  8.08s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 185/196 [25:17<01:28,  8.08s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 186/196 [25:17<01:20,  8.07s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 186/196 [25:25<01:20,  8.07s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 187/196 [25:25<01:12,  8.05s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 187/196 [25:33<01:12,  8.05s/it, training_loss=0.339]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 188/196 [25:33<01:04,  8.04s/it, training_loss=0.339]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 188/196 [25:41<01:04,  8.04s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 189/196 [25:41<00:56,  8.05s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 189/196 [25:49<00:56,  8.05s/it, training_loss=0.320]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 190/196 [25:49<00:48,  8.04s/it, training_loss=0.320]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 190/196 [25:57<00:48,  8.04s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 191/196 [25:57<00:40,  8.04s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 191/196 [26:05<00:40,  8.04s/it, training_loss=0.312]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 192/196 [26:05<00:32,  8.03s/it, training_loss=0.312]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 192/196 [26:13<00:32,  8.03s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 193/196 [26:13<00:24,  8.02s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 193/196 [26:21<00:24,  8.02s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 194/196 [26:21<00:16,  8.01s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 194/196 [26:29<00:16,  8.01s/it, training_loss=0.327]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 195/196 [26:29<00:07,  7.99s/it, training_loss=0.327]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 195/196 [26:32<00:07,  7.99s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 1: 100%|██████████| 196/196 [26:32<00:00,  6.53s/it, training_loss=0.257]\u001b[A\n",
            "  0%|          | 0/5 [26:33<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "Training loss: 0.9669603743419355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 1/5 [27:56<1:51:46, 1676.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.7559147204671587\n",
            "F1 Score (Weighted): 0.6405291650133212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 2:   0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:   0%|          | 0/196 [00:07<?, ?it/s, training_loss=0.378]\u001b[A\n",
            "Epoch 2:   1%|          | 1/196 [00:07<25:40,  7.90s/it, training_loss=0.378]\u001b[A\n",
            "Epoch 2:   1%|          | 1/196 [00:15<25:40,  7.90s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:   1%|          | 2/196 [00:15<25:28,  7.88s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:   1%|          | 2/196 [00:23<25:28,  7.88s/it, training_loss=0.329]\u001b[A\n",
            "Epoch 2:   2%|▏         | 3/196 [00:23<25:14,  7.85s/it, training_loss=0.329]\u001b[A\n",
            "Epoch 2:   2%|▏         | 3/196 [00:31<25:14,  7.85s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 2:   2%|▏         | 4/196 [00:31<25:03,  7.83s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 2:   2%|▏         | 4/196 [00:39<25:03,  7.83s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:   3%|▎         | 5/196 [00:39<24:50,  7.81s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:   3%|▎         | 5/196 [00:46<24:50,  7.81s/it, training_loss=0.451]\u001b[A\n",
            "Epoch 2:   3%|▎         | 6/196 [00:46<24:45,  7.82s/it, training_loss=0.451]\u001b[A\n",
            "Epoch 2:   3%|▎         | 6/196 [00:54<24:45,  7.82s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:   4%|▎         | 7/196 [00:54<24:35,  7.81s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:   4%|▎         | 7/196 [01:02<24:35,  7.81s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 2:   4%|▍         | 8/196 [01:02<24:31,  7.83s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 2:   4%|▍         | 8/196 [01:10<24:31,  7.83s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 2:   5%|▍         | 9/196 [01:10<24:25,  7.84s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 2:   5%|▍         | 9/196 [01:18<24:25,  7.84s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:   5%|▌         | 10/196 [01:18<24:43,  7.97s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:   5%|▌         | 10/196 [01:27<24:43,  7.97s/it, training_loss=0.406]\u001b[A\n",
            "Epoch 2:   6%|▌         | 11/196 [01:27<25:08,  8.15s/it, training_loss=0.406]\u001b[A\n",
            "Epoch 2:   6%|▌         | 11/196 [01:35<25:08,  8.15s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:   6%|▌         | 12/196 [01:35<24:52,  8.11s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:   6%|▌         | 12/196 [01:43<24:52,  8.11s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 2:   7%|▋         | 13/196 [01:43<24:27,  8.02s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 2:   7%|▋         | 13/196 [01:51<24:27,  8.02s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 2:   7%|▋         | 14/196 [01:51<24:10,  7.97s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 2:   7%|▋         | 14/196 [01:58<24:10,  7.97s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:   8%|▊         | 15/196 [01:58<23:55,  7.93s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:   8%|▊         | 15/196 [02:06<23:55,  7.93s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:   8%|▊         | 16/196 [02:06<23:44,  7.91s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:   8%|▊         | 16/196 [02:14<23:44,  7.91s/it, training_loss=0.394]\u001b[A\n",
            "Epoch 2:   9%|▊         | 17/196 [02:14<23:37,  7.92s/it, training_loss=0.394]\u001b[A\n",
            "Epoch 2:   9%|▊         | 17/196 [02:22<23:37,  7.92s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 2:   9%|▉         | 18/196 [02:22<23:28,  7.91s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 2:   9%|▉         | 18/196 [02:30<23:28,  7.91s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  10%|▉         | 19/196 [02:30<23:13,  7.87s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  10%|▉         | 19/196 [02:38<23:13,  7.87s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 2:  10%|█         | 20/196 [02:38<23:03,  7.86s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 2:  10%|█         | 20/196 [02:46<23:03,  7.86s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  11%|█         | 21/196 [02:46<22:54,  7.85s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  11%|█         | 21/196 [02:53<22:54,  7.85s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  11%|█         | 22/196 [02:53<22:43,  7.84s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  11%|█         | 22/196 [03:01<22:43,  7.84s/it, training_loss=0.519]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 23/196 [03:01<22:34,  7.83s/it, training_loss=0.519]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 23/196 [03:09<22:34,  7.83s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 24/196 [03:09<22:28,  7.84s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 24/196 [03:17<22:28,  7.84s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 25/196 [03:17<22:22,  7.85s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 25/196 [03:25<22:22,  7.85s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 26/196 [03:25<22:12,  7.84s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 26/196 [03:32<22:12,  7.84s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 27/196 [03:32<22:00,  7.82s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 27/196 [03:40<22:00,  7.82s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 28/196 [03:40<21:53,  7.82s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 28/196 [03:48<21:53,  7.82s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 29/196 [03:48<21:48,  7.83s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 29/196 [03:56<21:48,  7.83s/it, training_loss=0.521]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 30/196 [03:56<21:42,  7.85s/it, training_loss=0.521]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 30/196 [04:04<21:42,  7.85s/it, training_loss=0.383]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 31/196 [04:04<21:31,  7.83s/it, training_loss=0.383]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 31/196 [04:12<21:31,  7.83s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 32/196 [04:12<21:28,  7.86s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 32/196 [04:20<21:28,  7.86s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 33/196 [04:20<21:24,  7.88s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 33/196 [04:27<21:24,  7.88s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 34/196 [04:27<21:12,  7.86s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 34/196 [04:35<21:12,  7.86s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 35/196 [04:35<21:02,  7.84s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 35/196 [04:43<21:02,  7.84s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 36/196 [04:43<20:54,  7.84s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 36/196 [04:51<20:54,  7.84s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 37/196 [04:51<20:44,  7.83s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 37/196 [04:59<20:44,  7.83s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 38/196 [04:59<20:36,  7.82s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 38/196 [05:07<20:36,  7.82s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 39/196 [05:07<20:29,  7.83s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 39/196 [05:14<20:29,  7.83s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 2:  20%|██        | 40/196 [05:14<20:20,  7.82s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 2:  20%|██        | 40/196 [05:22<20:20,  7.82s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 2:  21%|██        | 41/196 [05:22<20:07,  7.79s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 2:  21%|██        | 41/196 [05:30<20:07,  7.79s/it, training_loss=0.385]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 42/196 [05:30<19:58,  7.78s/it, training_loss=0.385]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 42/196 [05:38<19:58,  7.78s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 43/196 [05:38<19:51,  7.79s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 43/196 [05:45<19:51,  7.79s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 44/196 [05:45<19:44,  7.79s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 44/196 [05:53<19:44,  7.79s/it, training_loss=0.350]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 45/196 [05:53<19:37,  7.80s/it, training_loss=0.350]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 45/196 [06:01<19:37,  7.80s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 46/196 [06:01<19:31,  7.81s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 46/196 [06:09<19:31,  7.81s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 47/196 [06:09<19:25,  7.82s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 47/196 [06:17<19:25,  7.82s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 48/196 [06:17<19:20,  7.84s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 48/196 [06:25<19:20,  7.84s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 49/196 [06:25<19:09,  7.82s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 49/196 [06:32<19:09,  7.82s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 50/196 [06:32<19:01,  7.82s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 50/196 [06:40<19:01,  7.82s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 51/196 [06:40<18:57,  7.84s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 51/196 [06:48<18:57,  7.84s/it, training_loss=0.370]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 52/196 [06:48<18:49,  7.84s/it, training_loss=0.370]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 52/196 [06:56<18:49,  7.84s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 53/196 [06:56<18:38,  7.82s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 53/196 [07:04<18:38,  7.82s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 54/196 [07:04<18:30,  7.82s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 54/196 [07:12<18:30,  7.82s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 55/196 [07:12<18:21,  7.82s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 55/196 [07:19<18:21,  7.82s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 56/196 [07:19<18:15,  7.82s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 56/196 [07:27<18:15,  7.82s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 57/196 [07:27<18:06,  7.82s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 57/196 [07:35<18:06,  7.82s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 58/196 [07:35<17:58,  7.82s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 58/196 [07:43<17:58,  7.82s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  30%|███       | 59/196 [07:43<17:52,  7.83s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  30%|███       | 59/196 [07:51<17:52,  7.83s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 2:  31%|███       | 60/196 [07:51<17:44,  7.83s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 2:  31%|███       | 60/196 [07:58<17:44,  7.83s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 2:  31%|███       | 61/196 [07:58<17:34,  7.81s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 2:  31%|███       | 61/196 [08:06<17:34,  7.81s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 62/196 [08:06<17:28,  7.82s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 62/196 [08:14<17:28,  7.82s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 63/196 [08:14<17:19,  7.82s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 63/196 [08:22<17:19,  7.82s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 64/196 [08:22<17:10,  7.80s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 64/196 [08:30<17:10,  7.80s/it, training_loss=0.370]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 65/196 [08:30<17:02,  7.80s/it, training_loss=0.370]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 65/196 [08:37<17:02,  7.80s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 66/196 [08:37<16:53,  7.80s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 66/196 [08:45<16:53,  7.80s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 67/196 [08:45<16:45,  7.80s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 67/196 [08:53<16:45,  7.80s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 68/196 [08:53<16:38,  7.80s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 68/196 [09:01<16:38,  7.80s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 69/196 [09:01<16:30,  7.80s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 69/196 [09:09<16:30,  7.80s/it, training_loss=0.382]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 70/196 [09:09<16:23,  7.81s/it, training_loss=0.382]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 70/196 [09:16<16:23,  7.81s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 71/196 [09:16<16:14,  7.79s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 71/196 [09:24<16:14,  7.79s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 72/196 [09:24<16:04,  7.78s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 72/196 [09:32<16:04,  7.78s/it, training_loss=0.349]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 73/196 [09:32<15:56,  7.78s/it, training_loss=0.349]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 73/196 [09:40<15:56,  7.78s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 74/196 [09:40<15:48,  7.78s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 74/196 [09:47<15:48,  7.78s/it, training_loss=0.339]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 75/196 [09:48<15:40,  7.77s/it, training_loss=0.339]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 75/196 [09:55<15:40,  7.77s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 76/196 [09:55<15:34,  7.79s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 76/196 [10:03<15:34,  7.79s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 77/196 [10:03<15:26,  7.79s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 77/196 [10:11<15:26,  7.79s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 78/196 [10:11<15:18,  7.78s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 78/196 [10:19<15:18,  7.78s/it, training_loss=0.476]\u001b[A\n",
            "Epoch 2:  40%|████      | 79/196 [10:19<15:11,  7.79s/it, training_loss=0.476]\u001b[A\n",
            "Epoch 2:  40%|████      | 79/196 [10:26<15:11,  7.79s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 2:  41%|████      | 80/196 [10:26<15:03,  7.79s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 2:  41%|████      | 80/196 [10:34<15:03,  7.79s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 81/196 [10:34<14:53,  7.77s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 81/196 [10:42<14:53,  7.77s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 82/196 [10:42<14:47,  7.78s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 82/196 [10:50<14:47,  7.78s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 83/196 [10:50<14:37,  7.76s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 83/196 [10:57<14:37,  7.76s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 84/196 [10:57<14:26,  7.74s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 84/196 [11:05<14:26,  7.74s/it, training_loss=0.327]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 85/196 [11:05<14:18,  7.73s/it, training_loss=0.327]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 85/196 [11:13<14:18,  7.73s/it, training_loss=0.427]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 86/196 [11:13<14:16,  7.78s/it, training_loss=0.427]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 86/196 [11:21<14:16,  7.78s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 87/196 [11:21<14:17,  7.87s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 87/196 [11:29<14:17,  7.87s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 88/196 [11:29<14:17,  7.94s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 88/196 [11:37<14:17,  7.94s/it, training_loss=0.338]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 89/196 [11:37<14:14,  7.98s/it, training_loss=0.338]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 89/196 [11:45<14:14,  7.98s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 90/196 [11:45<14:09,  8.02s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 90/196 [11:54<14:09,  8.02s/it, training_loss=0.446]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 91/196 [11:54<14:05,  8.05s/it, training_loss=0.446]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 91/196 [12:01<14:05,  8.05s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 92/196 [12:01<13:50,  7.98s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 92/196 [12:09<13:50,  7.98s/it, training_loss=0.434]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 93/196 [12:09<13:39,  7.96s/it, training_loss=0.434]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 93/196 [12:17<13:39,  7.96s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 94/196 [12:17<13:31,  7.95s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 94/196 [12:25<13:31,  7.95s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 95/196 [12:25<13:19,  7.92s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 95/196 [12:33<13:19,  7.92s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 96/196 [12:33<13:10,  7.90s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 96/196 [12:41<13:10,  7.90s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 97/196 [12:41<13:02,  7.90s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 97/196 [12:49<13:02,  7.90s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  50%|█████     | 98/196 [12:49<12:52,  7.89s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  50%|█████     | 98/196 [12:57<12:52,  7.89s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  51%|█████     | 99/196 [12:57<12:46,  7.91s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  51%|█████     | 99/196 [13:04<12:46,  7.91s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 2:  51%|█████     | 100/196 [13:04<12:37,  7.89s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 2:  51%|█████     | 100/196 [13:12<12:37,  7.89s/it, training_loss=0.404]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 101/196 [13:12<12:30,  7.90s/it, training_loss=0.404]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 101/196 [13:21<12:30,  7.90s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 102/196 [13:21<12:29,  7.97s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 102/196 [13:29<12:29,  7.97s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 103/196 [13:29<12:28,  8.05s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 103/196 [13:37<12:28,  8.05s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 104/196 [13:37<12:23,  8.08s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 104/196 [13:45<12:23,  8.08s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 105/196 [13:45<12:20,  8.14s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 105/196 [13:53<12:20,  8.14s/it, training_loss=0.476]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 106/196 [13:53<12:17,  8.19s/it, training_loss=0.476]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 106/196 [14:02<12:17,  8.19s/it, training_loss=0.501]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 107/196 [14:02<12:09,  8.19s/it, training_loss=0.501]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 107/196 [14:10<12:09,  8.19s/it, training_loss=0.506]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 108/196 [14:10<12:00,  8.18s/it, training_loss=0.506]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 108/196 [14:18<12:00,  8.18s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 109/196 [14:18<11:55,  8.22s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 109/196 [14:27<11:55,  8.22s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 110/196 [14:27<11:51,  8.28s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 110/196 [14:35<11:51,  8.28s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 111/196 [14:35<11:36,  8.20s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 111/196 [14:43<11:36,  8.20s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 112/196 [14:43<11:24,  8.15s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 112/196 [14:51<11:24,  8.15s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 113/196 [14:51<11:12,  8.10s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 113/196 [14:59<11:12,  8.10s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 114/196 [14:59<11:00,  8.05s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 114/196 [15:06<11:00,  8.05s/it, training_loss=0.427]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 115/196 [15:06<10:49,  8.02s/it, training_loss=0.427]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 115/196 [15:15<10:49,  8.02s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 116/196 [15:15<10:42,  8.03s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 116/196 [15:22<10:42,  8.03s/it, training_loss=0.405]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 117/196 [15:22<10:32,  8.01s/it, training_loss=0.405]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 117/196 [15:30<10:32,  8.01s/it, training_loss=0.446]\u001b[A\n",
            "Epoch 2:  60%|██████    | 118/196 [15:30<10:21,  7.97s/it, training_loss=0.446]\u001b[A\n",
            "Epoch 2:  60%|██████    | 118/196 [15:38<10:21,  7.97s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  61%|██████    | 119/196 [15:38<10:13,  7.97s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  61%|██████    | 119/196 [15:46<10:13,  7.97s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  61%|██████    | 120/196 [15:46<10:04,  7.96s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  61%|██████    | 120/196 [15:54<10:04,  7.96s/it, training_loss=0.350]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 121/196 [15:54<09:56,  7.96s/it, training_loss=0.350]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 121/196 [16:02<09:56,  7.96s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 122/196 [16:02<09:48,  7.95s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 122/196 [16:10<09:48,  7.95s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 123/196 [16:10<09:41,  7.97s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 123/196 [16:18<09:41,  7.97s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 124/196 [16:18<09:33,  7.96s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 124/196 [16:26<09:33,  7.96s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 125/196 [16:26<09:23,  7.94s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 125/196 [16:34<09:23,  7.94s/it, training_loss=0.467]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 126/196 [16:34<09:15,  7.93s/it, training_loss=0.467]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 126/196 [16:42<09:15,  7.93s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 127/196 [16:42<09:07,  7.94s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 127/196 [16:50<09:07,  7.94s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 128/196 [16:50<08:59,  7.93s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 128/196 [16:58<08:59,  7.93s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 129/196 [16:58<08:50,  7.91s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 129/196 [17:06<08:50,  7.91s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 130/196 [17:06<08:42,  7.91s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 130/196 [17:13<08:42,  7.91s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 131/196 [17:13<08:33,  7.91s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 131/196 [17:21<08:33,  7.91s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 132/196 [17:21<08:25,  7.90s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 132/196 [17:29<08:25,  7.90s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 133/196 [17:29<08:18,  7.91s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 133/196 [17:38<08:18,  7.91s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 134/196 [17:38<08:17,  8.03s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 134/196 [17:46<08:17,  8.03s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 135/196 [17:46<08:18,  8.17s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 135/196 [17:55<08:18,  8.17s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 136/196 [17:55<08:15,  8.25s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 136/196 [18:03<08:15,  8.25s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 137/196 [18:03<08:08,  8.28s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 137/196 [18:11<08:08,  8.28s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  70%|███████   | 138/196 [18:11<08:03,  8.33s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  70%|███████   | 138/196 [18:20<08:03,  8.33s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  71%|███████   | 139/196 [18:20<07:56,  8.35s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  71%|███████   | 139/196 [18:28<07:56,  8.35s/it, training_loss=0.412]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 140/196 [18:28<07:46,  8.34s/it, training_loss=0.412]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 140/196 [18:36<07:46,  8.34s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 141/196 [18:36<07:36,  8.29s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 141/196 [18:44<07:36,  8.29s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 142/196 [18:44<07:26,  8.27s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 142/196 [18:53<07:26,  8.27s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 143/196 [18:53<07:18,  8.28s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 143/196 [19:01<07:18,  8.28s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 144/196 [19:01<07:10,  8.28s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 144/196 [19:09<07:10,  8.28s/it, training_loss=0.386]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 145/196 [19:09<06:59,  8.23s/it, training_loss=0.386]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 145/196 [19:17<06:59,  8.23s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 146/196 [19:17<06:49,  8.18s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 146/196 [19:25<06:49,  8.18s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 147/196 [19:25<06:38,  8.14s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 147/196 [19:33<06:38,  8.14s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 148/196 [19:33<06:28,  8.10s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 148/196 [19:41<06:28,  8.10s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 149/196 [19:41<06:18,  8.06s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 149/196 [19:49<06:18,  8.06s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 150/196 [19:49<06:09,  8.03s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 150/196 [19:57<06:09,  8.03s/it, training_loss=0.415]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 151/196 [19:57<06:01,  8.03s/it, training_loss=0.415]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 151/196 [20:05<06:01,  8.03s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 152/196 [20:05<05:52,  8.02s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 152/196 [20:13<05:52,  8.02s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 153/196 [20:13<05:45,  8.03s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 153/196 [20:21<05:45,  8.03s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 154/196 [20:21<05:36,  8.02s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 154/196 [20:29<05:36,  8.02s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 155/196 [20:29<05:28,  8.01s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 155/196 [20:37<05:28,  8.01s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 156/196 [20:37<05:20,  8.02s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 156/196 [20:45<05:20,  8.02s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  80%|████████  | 157/196 [20:45<05:13,  8.04s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  80%|████████  | 157/196 [20:53<05:13,  8.04s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  81%|████████  | 158/196 [20:53<05:04,  8.03s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  81%|████████  | 158/196 [21:01<05:04,  8.03s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  81%|████████  | 159/196 [21:01<04:56,  8.01s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  81%|████████  | 159/196 [21:09<04:56,  8.01s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 160/196 [21:09<04:48,  8.01s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 160/196 [21:17<04:48,  8.01s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 161/196 [21:17<04:40,  8.01s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 161/196 [21:25<04:40,  8.01s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 162/196 [21:25<04:31,  7.99s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 162/196 [21:33<04:31,  7.99s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 163/196 [21:33<04:22,  7.97s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 163/196 [21:41<04:22,  7.97s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 164/196 [21:41<04:15,  7.98s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 164/196 [21:49<04:15,  7.98s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 165/196 [21:49<04:07,  7.99s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 165/196 [21:57<04:07,  7.99s/it, training_loss=0.604]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 166/196 [21:57<03:59,  7.98s/it, training_loss=0.604]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 166/196 [22:05<03:59,  7.98s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 167/196 [22:05<03:51,  7.99s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 167/196 [22:13<03:51,  7.99s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 168/196 [22:13<03:43,  8.00s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 168/196 [22:21<03:43,  8.00s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 169/196 [22:21<03:36,  8.00s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 169/196 [22:29<03:36,  8.00s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 170/196 [22:29<03:27,  7.99s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 170/196 [22:37<03:27,  7.99s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 171/196 [22:37<03:20,  8.01s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 171/196 [22:45<03:20,  8.01s/it, training_loss=0.398]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 172/196 [22:45<03:13,  8.05s/it, training_loss=0.398]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 172/196 [22:54<03:13,  8.05s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 173/196 [22:54<03:06,  8.12s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 173/196 [23:02<03:06,  8.12s/it, training_loss=0.339]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 174/196 [23:02<02:59,  8.17s/it, training_loss=0.339]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 174/196 [23:10<02:59,  8.17s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 175/196 [23:10<02:51,  8.16s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 175/196 [23:18<02:51,  8.16s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 176/196 [23:18<02:44,  8.22s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 176/196 [23:27<02:44,  8.22s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 177/196 [23:27<02:37,  8.29s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 177/196 [23:36<02:37,  8.29s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 178/196 [23:36<02:30,  8.38s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 178/196 [23:44<02:30,  8.38s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 179/196 [23:44<02:23,  8.46s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 179/196 [23:53<02:23,  8.46s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 180/196 [23:53<02:16,  8.52s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 180/196 [24:01<02:16,  8.52s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 181/196 [24:01<02:07,  8.53s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 181/196 [24:10<02:07,  8.53s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 182/196 [24:10<01:59,  8.54s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 182/196 [24:18<01:59,  8.54s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 183/196 [24:19<01:51,  8.55s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 183/196 [24:27<01:51,  8.55s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 184/196 [24:27<01:42,  8.55s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 184/196 [24:36<01:42,  8.55s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 185/196 [24:36<01:33,  8.52s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 185/196 [24:44<01:33,  8.52s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 186/196 [24:44<01:25,  8.55s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 186/196 [24:53<01:25,  8.55s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 187/196 [24:53<01:17,  8.58s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 187/196 [25:01<01:17,  8.58s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 188/196 [25:01<01:08,  8.60s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 188/196 [25:10<01:08,  8.60s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 189/196 [25:10<01:00,  8.63s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 189/196 [25:19<01:00,  8.63s/it, training_loss=0.368]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 190/196 [25:19<00:51,  8.66s/it, training_loss=0.368]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 190/196 [25:27<00:51,  8.66s/it, training_loss=0.505]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 191/196 [25:27<00:43,  8.64s/it, training_loss=0.505]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 191/196 [25:36<00:43,  8.64s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 192/196 [25:36<00:34,  8.64s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 192/196 [25:45<00:34,  8.64s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 193/196 [25:45<00:25,  8.66s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 193/196 [25:53<00:25,  8.66s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 194/196 [25:53<00:17,  8.67s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 194/196 [26:02<00:17,  8.67s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 195/196 [26:02<00:08,  8.66s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 195/196 [26:05<00:08,  8.66s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2: 100%|██████████| 196/196 [26:06<00:00,  7.08s/it, training_loss=0.178]\u001b[A\n",
            " 20%|██        | 1/5 [54:03<1:51:46, 1676.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2\n",
            "Training loss: 0.7198263136099796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 2/5 [55:32<1:23:13, 1664.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.6757904099566596\n",
            "F1 Score (Weighted): 0.7451117799219065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 3:   0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:   0%|          | 0/196 [00:08<?, ?it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 3:   1%|          | 1/196 [00:08<28:00,  8.62s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 3:   1%|          | 1/196 [00:17<28:00,  8.62s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:   1%|          | 2/196 [00:17<27:55,  8.64s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:   1%|          | 2/196 [00:25<27:55,  8.64s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 3:   2%|▏         | 3/196 [00:25<27:47,  8.64s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 3:   2%|▏         | 3/196 [00:34<27:47,  8.64s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 3:   2%|▏         | 4/196 [00:34<27:39,  8.64s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 3:   2%|▏         | 4/196 [00:43<27:39,  8.64s/it, training_loss=0.409]\u001b[A\n",
            "Epoch 3:   3%|▎         | 5/196 [00:43<27:26,  8.62s/it, training_loss=0.409]\u001b[A\n",
            "Epoch 3:   3%|▎         | 5/196 [00:51<27:26,  8.62s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:   3%|▎         | 6/196 [00:51<27:13,  8.60s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:   3%|▎         | 6/196 [01:00<27:13,  8.60s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 3:   4%|▎         | 7/196 [01:00<27:02,  8.59s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 3:   4%|▎         | 7/196 [01:08<27:02,  8.59s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:   4%|▍         | 8/196 [01:08<26:44,  8.53s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:   4%|▍         | 8/196 [01:17<26:44,  8.53s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:   5%|▍         | 9/196 [01:17<26:40,  8.56s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:   5%|▍         | 9/196 [01:25<26:40,  8.56s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 3:   5%|▌         | 10/196 [01:25<26:30,  8.55s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 3:   5%|▌         | 10/196 [01:34<26:30,  8.55s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 3:   6%|▌         | 11/196 [01:34<26:20,  8.54s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 3:   6%|▌         | 11/196 [01:42<26:20,  8.54s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:   6%|▌         | 12/196 [01:42<26:11,  8.54s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:   6%|▌         | 12/196 [01:51<26:11,  8.54s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 3:   7%|▋         | 13/196 [01:51<26:03,  8.54s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 3:   7%|▋         | 13/196 [01:59<26:03,  8.54s/it, training_loss=0.440]\u001b[A\n",
            "Epoch 3:   7%|▋         | 14/196 [01:59<25:53,  8.54s/it, training_loss=0.440]\u001b[A\n",
            "Epoch 3:   7%|▋         | 14/196 [02:08<25:53,  8.54s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 3:   8%|▊         | 15/196 [02:08<25:46,  8.54s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 3:   8%|▊         | 15/196 [02:16<25:46,  8.54s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:   8%|▊         | 16/196 [02:16<25:32,  8.52s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:   8%|▊         | 16/196 [02:25<25:32,  8.52s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:   9%|▊         | 17/196 [02:25<25:27,  8.53s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:   9%|▊         | 17/196 [02:34<25:27,  8.53s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 3:   9%|▉         | 18/196 [02:34<25:21,  8.55s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 3:   9%|▉         | 18/196 [02:42<25:21,  8.55s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 3:  10%|▉         | 19/196 [02:42<25:12,  8.55s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 3:  10%|▉         | 19/196 [02:51<25:12,  8.55s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 3:  10%|█         | 20/196 [02:51<25:03,  8.54s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 3:  10%|█         | 20/196 [02:59<25:03,  8.54s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  11%|█         | 21/196 [02:59<24:53,  8.54s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  11%|█         | 21/196 [03:08<24:53,  8.54s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  11%|█         | 22/196 [03:08<24:45,  8.54s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  11%|█         | 22/196 [03:16<24:45,  8.54s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 23/196 [03:16<24:26,  8.48s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 23/196 [03:25<24:26,  8.48s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 24/196 [03:25<24:21,  8.49s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 24/196 [03:33<24:21,  8.49s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 25/196 [03:33<24:14,  8.50s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 25/196 [03:42<24:14,  8.50s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 26/196 [03:42<24:07,  8.52s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 26/196 [03:50<24:07,  8.52s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 27/196 [03:50<23:59,  8.52s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 27/196 [03:59<23:59,  8.52s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 28/196 [03:59<23:51,  8.52s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 28/196 [04:07<23:51,  8.52s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 29/196 [04:07<23:43,  8.52s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 29/196 [04:16<23:43,  8.52s/it, training_loss=0.491]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 30/196 [04:16<23:36,  8.53s/it, training_loss=0.491]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 30/196 [04:24<23:36,  8.53s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 31/196 [04:24<23:19,  8.48s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 31/196 [04:33<23:19,  8.48s/it, training_loss=0.348]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 32/196 [04:33<23:15,  8.51s/it, training_loss=0.348]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 32/196 [04:41<23:15,  8.51s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 33/196 [04:41<23:06,  8.50s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 33/196 [04:50<23:06,  8.50s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 34/196 [04:50<23:00,  8.52s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 34/196 [04:58<23:00,  8.52s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 35/196 [04:58<22:52,  8.52s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 35/196 [05:07<22:52,  8.52s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 36/196 [05:07<22:42,  8.51s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 36/196 [05:15<22:42,  8.51s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 37/196 [05:15<22:34,  8.52s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 37/196 [05:24<22:34,  8.52s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 38/196 [05:24<22:21,  8.49s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 38/196 [05:32<22:21,  8.49s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 39/196 [05:32<22:15,  8.51s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 39/196 [05:41<22:15,  8.51s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  20%|██        | 40/196 [05:41<22:10,  8.53s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  20%|██        | 40/196 [05:49<22:10,  8.53s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 3:  21%|██        | 41/196 [05:49<22:00,  8.52s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 3:  21%|██        | 41/196 [05:58<22:00,  8.52s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 42/196 [05:58<21:47,  8.49s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 42/196 [06:06<21:47,  8.49s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 43/196 [06:06<21:37,  8.48s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 43/196 [06:15<21:37,  8.48s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 44/196 [06:15<21:30,  8.49s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 44/196 [06:23<21:30,  8.49s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 45/196 [06:23<21:21,  8.49s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 45/196 [06:32<21:21,  8.49s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 46/196 [06:32<21:03,  8.43s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 46/196 [06:40<21:03,  8.43s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 47/196 [06:40<20:59,  8.45s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 47/196 [06:49<20:59,  8.45s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 48/196 [06:49<20:52,  8.46s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 48/196 [06:57<20:52,  8.46s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 49/196 [06:57<20:47,  8.48s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 49/196 [07:06<20:47,  8.48s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 50/196 [07:06<20:45,  8.53s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 50/196 [07:14<20:45,  8.53s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 51/196 [07:14<20:40,  8.55s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 51/196 [07:23<20:40,  8.55s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 52/196 [07:23<20:30,  8.55s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 52/196 [07:31<20:30,  8.55s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 53/196 [07:31<20:14,  8.49s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 53/196 [07:40<20:14,  8.49s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 54/196 [07:40<20:04,  8.48s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 54/196 [07:48<20:04,  8.48s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 55/196 [07:48<19:57,  8.49s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 55/196 [07:57<19:57,  8.49s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 56/196 [07:57<19:49,  8.49s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 56/196 [08:05<19:49,  8.49s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 57/196 [08:05<19:39,  8.49s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 57/196 [08:14<19:39,  8.49s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 58/196 [08:14<19:33,  8.50s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 58/196 [08:22<19:33,  8.50s/it, training_loss=0.601]\u001b[A\n",
            "Epoch 3:  30%|███       | 59/196 [08:22<19:28,  8.53s/it, training_loss=0.601]\u001b[A\n",
            "Epoch 3:  30%|███       | 59/196 [08:31<19:28,  8.53s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 3:  31%|███       | 60/196 [08:31<19:23,  8.55s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 3:  31%|███       | 60/196 [08:39<19:23,  8.55s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 3:  31%|███       | 61/196 [08:39<19:11,  8.53s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 3:  31%|███       | 61/196 [08:48<19:11,  8.53s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 62/196 [08:48<19:08,  8.57s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 62/196 [08:57<19:08,  8.57s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 63/196 [08:57<19:01,  8.59s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 63/196 [09:05<19:01,  8.59s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 64/196 [09:05<18:53,  8.59s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 64/196 [09:14<18:53,  8.59s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 65/196 [09:14<18:42,  8.57s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 65/196 [09:22<18:42,  8.57s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 66/196 [09:22<18:33,  8.56s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 66/196 [09:31<18:33,  8.56s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 67/196 [09:31<18:25,  8.57s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 67/196 [09:39<18:25,  8.57s/it, training_loss=0.557]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 68/196 [09:39<18:11,  8.53s/it, training_loss=0.557]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 68/196 [09:48<18:11,  8.53s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 69/196 [09:48<18:03,  8.53s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 69/196 [09:57<18:03,  8.53s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 70/196 [09:57<17:57,  8.55s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 70/196 [10:05<17:57,  8.55s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 71/196 [10:05<17:51,  8.58s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 71/196 [10:14<17:51,  8.58s/it, training_loss=0.393]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 72/196 [10:14<17:45,  8.59s/it, training_loss=0.393]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 72/196 [10:22<17:45,  8.59s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 73/196 [10:22<17:39,  8.61s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 73/196 [10:31<17:39,  8.61s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 74/196 [10:31<17:31,  8.62s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 74/196 [10:40<17:31,  8.62s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 75/196 [10:40<17:24,  8.63s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 75/196 [10:48<17:24,  8.63s/it, training_loss=0.411]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 76/196 [10:48<17:15,  8.63s/it, training_loss=0.411]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 76/196 [10:57<17:15,  8.63s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 77/196 [10:57<17:07,  8.63s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 77/196 [11:06<17:07,  8.63s/it, training_loss=0.417]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 78/196 [11:06<16:56,  8.61s/it, training_loss=0.417]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 78/196 [11:14<16:56,  8.61s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 3:  40%|████      | 79/196 [11:14<16:46,  8.60s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 3:  40%|████      | 79/196 [11:23<16:46,  8.60s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 3:  41%|████      | 80/196 [11:23<16:35,  8.58s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 3:  41%|████      | 80/196 [11:31<16:35,  8.58s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  41%|████▏     | 81/196 [11:31<16:22,  8.55s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  41%|████▏     | 81/196 [11:40<16:22,  8.55s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 82/196 [11:40<16:14,  8.55s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 82/196 [11:48<16:14,  8.55s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 83/196 [11:48<16:02,  8.52s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 83/196 [11:57<16:02,  8.52s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 84/196 [11:57<15:54,  8.53s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 84/196 [12:05<15:54,  8.53s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 85/196 [12:05<15:46,  8.53s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 85/196 [12:14<15:46,  8.53s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 86/196 [12:14<15:38,  8.53s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 86/196 [12:22<15:38,  8.53s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 87/196 [12:22<15:31,  8.54s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 87/196 [12:31<15:31,  8.54s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 88/196 [12:31<15:21,  8.53s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 88/196 [12:39<15:21,  8.53s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 89/196 [12:39<15:11,  8.52s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 89/196 [12:48<15:11,  8.52s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 90/196 [12:48<15:03,  8.52s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 90/196 [12:56<15:03,  8.52s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 91/196 [12:56<14:49,  8.47s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 91/196 [13:05<14:49,  8.47s/it, training_loss=0.524]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 92/196 [13:05<14:42,  8.49s/it, training_loss=0.524]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 92/196 [13:13<14:42,  8.49s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 93/196 [13:13<14:34,  8.49s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 93/196 [13:22<14:34,  8.49s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 94/196 [13:22<14:26,  8.50s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 94/196 [13:30<14:26,  8.50s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 95/196 [13:30<14:17,  8.49s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 95/196 [13:39<14:17,  8.49s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 96/196 [13:39<14:09,  8.50s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 96/196 [13:47<14:09,  8.50s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 97/196 [13:47<14:01,  8.50s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 97/196 [13:56<14:01,  8.50s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  50%|█████     | 98/196 [13:56<13:48,  8.46s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  50%|█████     | 98/196 [14:04<13:48,  8.46s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  51%|█████     | 99/196 [14:04<13:40,  8.46s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  51%|█████     | 99/196 [14:13<13:40,  8.46s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 3:  51%|█████     | 100/196 [14:13<13:34,  8.48s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 3:  51%|█████     | 100/196 [14:21<13:34,  8.48s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 101/196 [14:21<13:26,  8.49s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 101/196 [14:30<13:26,  8.49s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 102/196 [14:30<13:17,  8.49s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 102/196 [14:38<13:17,  8.49s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 103/196 [14:38<13:09,  8.49s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 103/196 [14:47<13:09,  8.49s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 104/196 [14:47<13:00,  8.49s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 104/196 [14:55<13:00,  8.49s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 105/196 [14:55<12:53,  8.50s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 105/196 [15:03<12:53,  8.50s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 106/196 [15:03<12:40,  8.45s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 106/196 [15:12<12:40,  8.45s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 107/196 [15:12<12:31,  8.44s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 107/196 [15:20<12:31,  8.44s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 108/196 [15:20<12:24,  8.46s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 108/196 [15:29<12:24,  8.46s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 109/196 [15:29<12:16,  8.47s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 109/196 [15:37<12:16,  8.47s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 110/196 [15:37<12:08,  8.47s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 110/196 [15:46<12:08,  8.47s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 111/196 [15:46<12:00,  8.47s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 111/196 [15:54<12:00,  8.47s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 112/196 [15:54<11:52,  8.48s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 112/196 [16:03<11:52,  8.48s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 113/196 [16:03<11:42,  8.47s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 113/196 [16:11<11:42,  8.47s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 114/196 [16:11<11:32,  8.45s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 114/196 [16:20<11:32,  8.45s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 3:  59%|█████▊    | 115/196 [16:20<11:25,  8.47s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 3:  59%|█████▊    | 115/196 [16:28<11:25,  8.47s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 116/196 [16:28<11:18,  8.48s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 116/196 [16:37<11:18,  8.48s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 117/196 [16:37<11:11,  8.50s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 117/196 [16:45<11:11,  8.50s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  60%|██████    | 118/196 [16:45<11:00,  8.47s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  60%|██████    | 118/196 [16:53<11:00,  8.47s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  61%|██████    | 119/196 [16:54<10:50,  8.45s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  61%|██████    | 119/196 [17:02<10:50,  8.45s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 3:  61%|██████    | 120/196 [17:02<10:42,  8.45s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 3:  61%|██████    | 120/196 [17:10<10:42,  8.45s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 121/196 [17:10<10:29,  8.39s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 121/196 [17:19<10:29,  8.39s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 122/196 [17:19<10:22,  8.41s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 122/196 [17:27<10:22,  8.41s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 123/196 [17:27<10:17,  8.45s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 123/196 [17:36<10:17,  8.45s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 124/196 [17:36<10:10,  8.47s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 124/196 [17:44<10:10,  8.47s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 125/196 [17:44<10:01,  8.47s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 125/196 [17:53<10:01,  8.47s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 126/196 [17:53<09:51,  8.45s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 126/196 [18:01<09:51,  8.45s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 127/196 [18:01<09:43,  8.46s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 127/196 [18:09<09:43,  8.46s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 128/196 [18:10<09:34,  8.45s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 128/196 [18:18<09:34,  8.45s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 129/196 [18:18<09:24,  8.42s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 129/196 [18:26<09:24,  8.42s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 130/196 [18:26<09:15,  8.42s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 130/196 [18:35<09:15,  8.42s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 131/196 [18:35<09:07,  8.42s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 131/196 [18:43<09:07,  8.42s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 132/196 [18:43<08:58,  8.42s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 132/196 [18:52<08:58,  8.42s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 133/196 [18:52<08:51,  8.44s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 133/196 [19:00<08:51,  8.44s/it, training_loss=0.512]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 134/196 [19:00<08:44,  8.46s/it, training_loss=0.512]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 134/196 [19:09<08:44,  8.46s/it, training_loss=0.647]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 135/196 [19:09<08:36,  8.47s/it, training_loss=0.647]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 135/196 [19:17<08:36,  8.47s/it, training_loss=0.378]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 136/196 [19:17<08:25,  8.43s/it, training_loss=0.378]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 136/196 [19:25<08:25,  8.43s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 137/196 [19:25<08:17,  8.44s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 137/196 [19:34<08:17,  8.44s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 3:  70%|███████   | 138/196 [19:34<08:09,  8.44s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 3:  70%|███████   | 138/196 [19:42<08:09,  8.44s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 3:  71%|███████   | 139/196 [19:42<08:00,  8.43s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 3:  71%|███████   | 139/196 [19:51<08:00,  8.43s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 140/196 [19:51<07:51,  8.43s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 140/196 [19:59<07:51,  8.43s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 141/196 [19:59<07:43,  8.42s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 141/196 [20:07<07:43,  8.42s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 142/196 [20:07<07:34,  8.41s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 142/196 [20:16<07:34,  8.41s/it, training_loss=0.399]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 143/196 [20:16<07:26,  8.42s/it, training_loss=0.399]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 143/196 [20:24<07:26,  8.42s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 144/196 [20:24<07:15,  8.37s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 144/196 [20:33<07:15,  8.37s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 145/196 [20:33<07:06,  8.37s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 145/196 [20:41<07:06,  8.37s/it, training_loss=0.725]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 146/196 [20:41<07:00,  8.40s/it, training_loss=0.725]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 146/196 [20:49<07:00,  8.40s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 147/196 [20:49<06:52,  8.43s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 147/196 [20:58<06:52,  8.43s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 148/196 [20:58<06:44,  8.42s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 148/196 [21:06<06:44,  8.42s/it, training_loss=0.410]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 149/196 [21:06<06:36,  8.44s/it, training_loss=0.410]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 149/196 [21:15<06:36,  8.44s/it, training_loss=0.387]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 150/196 [21:15<06:28,  8.45s/it, training_loss=0.387]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 150/196 [21:23<06:28,  8.45s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 151/196 [21:23<06:18,  8.41s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 151/196 [21:32<06:18,  8.41s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 152/196 [21:32<06:09,  8.40s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 152/196 [21:40<06:09,  8.40s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 153/196 [21:40<06:01,  8.41s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 153/196 [21:48<06:01,  8.41s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 154/196 [21:48<05:53,  8.42s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 154/196 [21:57<05:53,  8.42s/it, training_loss=0.592]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 155/196 [21:57<05:45,  8.42s/it, training_loss=0.592]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 155/196 [22:05<05:45,  8.42s/it, training_loss=0.377]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 156/196 [22:05<05:36,  8.41s/it, training_loss=0.377]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 156/196 [22:14<05:36,  8.41s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  80%|████████  | 157/196 [22:14<05:27,  8.40s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  80%|████████  | 157/196 [22:22<05:27,  8.40s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  81%|████████  | 158/196 [22:22<05:19,  8.41s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  81%|████████  | 158/196 [22:30<05:19,  8.41s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 3:  81%|████████  | 159/196 [22:30<05:09,  8.36s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 3:  81%|████████  | 159/196 [22:39<05:09,  8.36s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 160/196 [22:39<05:01,  8.37s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 160/196 [22:47<05:01,  8.37s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 161/196 [22:47<04:53,  8.39s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 161/196 [22:55<04:53,  8.39s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 162/196 [22:55<04:45,  8.38s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 162/196 [23:04<04:45,  8.38s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 163/196 [23:04<04:36,  8.39s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 163/196 [23:12<04:36,  8.39s/it, training_loss=0.517]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 164/196 [23:12<04:28,  8.39s/it, training_loss=0.517]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 164/196 [23:21<04:28,  8.39s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 165/196 [23:21<04:20,  8.40s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 165/196 [23:29<04:20,  8.40s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 166/196 [23:29<04:11,  8.38s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 166/196 [23:37<04:11,  8.38s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 167/196 [23:37<04:02,  8.36s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 167/196 [23:46<04:02,  8.36s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 168/196 [23:46<03:54,  8.39s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 168/196 [23:54<03:54,  8.39s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 169/196 [23:54<03:47,  8.41s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 169/196 [24:03<03:47,  8.41s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 170/196 [24:03<03:39,  8.43s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 170/196 [24:11<03:39,  8.43s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 171/196 [24:11<03:30,  8.42s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 171/196 [24:20<03:30,  8.42s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 172/196 [24:20<03:22,  8.42s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 172/196 [24:28<03:22,  8.42s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 173/196 [24:28<03:13,  8.42s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 173/196 [24:36<03:13,  8.42s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 174/196 [24:36<03:03,  8.36s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 174/196 [24:45<03:03,  8.36s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 175/196 [24:45<02:55,  8.35s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 175/196 [24:53<02:55,  8.35s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 176/196 [24:53<02:47,  8.37s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 176/196 [25:01<02:47,  8.37s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 177/196 [25:01<02:39,  8.38s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 177/196 [25:10<02:39,  8.38s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 178/196 [25:10<02:30,  8.39s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 178/196 [25:18<02:30,  8.39s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 3:  91%|█████████▏| 179/196 [25:18<02:22,  8.40s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 3:  91%|█████████▏| 179/196 [25:27<02:22,  8.40s/it, training_loss=0.429]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 180/196 [25:27<02:14,  8.42s/it, training_loss=0.429]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 180/196 [25:35<02:14,  8.42s/it, training_loss=0.397]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 181/196 [25:35<02:06,  8.41s/it, training_loss=0.397]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 181/196 [25:43<02:06,  8.41s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 182/196 [25:43<01:56,  8.35s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 182/196 [25:52<01:56,  8.35s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 183/196 [25:52<01:48,  8.38s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 183/196 [26:00<01:48,  8.38s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 184/196 [26:00<01:41,  8.44s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 184/196 [26:09<01:41,  8.44s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 185/196 [26:09<01:33,  8.51s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 185/196 [26:18<01:33,  8.51s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 186/196 [26:18<01:25,  8.57s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 186/196 [26:26<01:25,  8.57s/it, training_loss=0.320]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 187/196 [26:26<01:17,  8.58s/it, training_loss=0.320]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 187/196 [26:35<01:17,  8.58s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 188/196 [26:35<01:08,  8.58s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 188/196 [26:43<01:08,  8.58s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 189/196 [26:43<00:59,  8.55s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 189/196 [26:52<00:59,  8.55s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 190/196 [26:52<00:51,  8.54s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 190/196 [27:00<00:51,  8.54s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 191/196 [27:00<00:42,  8.53s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 191/196 [27:09<00:42,  8.53s/it, training_loss=0.303]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 192/196 [27:09<00:34,  8.52s/it, training_loss=0.303]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 192/196 [27:17<00:34,  8.52s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 193/196 [27:17<00:25,  8.52s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 193/196 [27:26<00:25,  8.52s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 194/196 [27:26<00:17,  8.51s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 194/196 [27:34<00:17,  8.51s/it, training_loss=0.548]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 195/196 [27:34<00:08,  8.51s/it, training_loss=0.548]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 195/196 [27:38<00:08,  8.51s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 3: 100%|██████████| 196/196 [27:38<00:00,  6.96s/it, training_loss=0.113]\u001b[A\n",
            " 40%|████      | 2/5 [1:23:11<1:23:13, 1664.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3\n",
            "Training loss: 0.5616139327841145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 3/5 [1:24:42<56:46, 1703.49s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.7633674928120204\n",
            "F1 Score (Weighted): 0.6628710542644968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 4:   0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:   0%|          | 0/196 [00:08<?, ?it/s, training_loss=0.031]\u001b[A\n",
            "Epoch 4:   1%|          | 1/196 [00:08<28:05,  8.65s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 4:   1%|          | 1/196 [00:17<28:05,  8.65s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 4:   1%|          | 2/196 [00:17<27:51,  8.61s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 4:   1%|          | 2/196 [00:25<27:51,  8.61s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 4:   2%|▏         | 3/196 [00:25<27:39,  8.60s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 4:   2%|▏         | 3/196 [00:34<27:39,  8.60s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 4:   2%|▏         | 4/196 [00:34<27:28,  8.58s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 4:   2%|▏         | 4/196 [00:42<27:28,  8.58s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 4:   3%|▎         | 5/196 [00:42<27:11,  8.54s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 4:   3%|▎         | 5/196 [00:51<27:11,  8.54s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 4:   3%|▎         | 6/196 [00:51<26:55,  8.50s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 4:   3%|▎         | 6/196 [00:59<26:55,  8.50s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 4:   4%|▎         | 7/196 [00:59<26:46,  8.50s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 4:   4%|▎         | 7/196 [01:08<26:46,  8.50s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 4:   4%|▍         | 8/196 [01:08<26:36,  8.49s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 4:   4%|▍         | 8/196 [01:16<26:36,  8.49s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 4:   5%|▍         | 9/196 [01:16<26:26,  8.49s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 4:   5%|▍         | 9/196 [01:25<26:26,  8.49s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 4:   5%|▌         | 10/196 [01:25<26:15,  8.47s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 4:   5%|▌         | 10/196 [01:33<26:15,  8.47s/it, training_loss=0.399]\u001b[A\n",
            "Epoch 4:   6%|▌         | 11/196 [01:33<26:05,  8.46s/it, training_loss=0.399]\u001b[A\n",
            "Epoch 4:   6%|▌         | 11/196 [01:42<26:05,  8.46s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 4:   6%|▌         | 12/196 [01:42<25:56,  8.46s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 4:   6%|▌         | 12/196 [01:50<25:56,  8.46s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 4:   7%|▋         | 13/196 [01:50<25:39,  8.41s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 4:   7%|▋         | 13/196 [01:58<25:39,  8.41s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 4:   7%|▋         | 14/196 [01:58<25:33,  8.43s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 4:   7%|▋         | 14/196 [02:07<25:33,  8.43s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 4:   8%|▊         | 15/196 [02:07<25:28,  8.44s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 4:   8%|▊         | 15/196 [02:15<25:28,  8.44s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 4:   8%|▊         | 16/196 [02:15<25:21,  8.45s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 4:   8%|▊         | 16/196 [02:24<25:21,  8.45s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 4:   9%|▊         | 17/196 [02:24<25:14,  8.46s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 4:   9%|▊         | 17/196 [02:32<25:14,  8.46s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 4:   9%|▉         | 18/196 [02:32<25:05,  8.46s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 4:   9%|▉         | 18/196 [02:41<25:05,  8.46s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 4:  10%|▉         | 19/196 [02:41<24:55,  8.45s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 4:  10%|▉         | 19/196 [02:49<24:55,  8.45s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 4:  10%|█         | 20/196 [02:49<24:44,  8.44s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 4:  10%|█         | 20/196 [02:57<24:44,  8.44s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 4:  11%|█         | 21/196 [02:57<24:29,  8.40s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 4:  11%|█         | 21/196 [03:06<24:29,  8.40s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 4:  11%|█         | 22/196 [03:06<24:23,  8.41s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 4:  11%|█         | 22/196 [03:14<24:23,  8.41s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 4:  12%|█▏        | 23/196 [03:14<24:18,  8.43s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 4:  12%|█▏        | 23/196 [03:23<24:18,  8.43s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 4:  12%|█▏        | 24/196 [03:23<24:09,  8.43s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 4:  12%|█▏        | 24/196 [03:31<24:09,  8.43s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 4:  13%|█▎        | 25/196 [03:31<24:00,  8.42s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 4:  13%|█▎        | 25/196 [03:40<24:00,  8.42s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 4:  13%|█▎        | 26/196 [03:40<23:53,  8.43s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 4:  13%|█▎        | 26/196 [03:48<23:53,  8.43s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 4:  14%|█▍        | 27/196 [03:48<23:44,  8.43s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 4:  14%|█▍        | 27/196 [03:56<23:44,  8.43s/it, training_loss=0.433]\u001b[A\n",
            "Epoch 4:  14%|█▍        | 28/196 [03:56<23:32,  8.41s/it, training_loss=0.433]\u001b[A\n",
            "Epoch 4:  14%|█▍        | 28/196 [04:05<23:32,  8.41s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 4:  15%|█▍        | 29/196 [04:05<23:27,  8.43s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 4:  15%|█▍        | 29/196 [04:13<23:27,  8.43s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 4:  15%|█▌        | 30/196 [04:13<23:22,  8.45s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 4:  15%|█▌        | 30/196 [04:22<23:22,  8.45s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 4:  16%|█▌        | 31/196 [04:22<23:16,  8.47s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 4:  16%|█▌        | 31/196 [04:30<23:16,  8.47s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 4:  16%|█▋        | 32/196 [04:30<23:05,  8.45s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 4:  16%|█▋        | 32/196 [04:39<23:05,  8.45s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 4:  17%|█▋        | 33/196 [04:39<22:54,  8.43s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 4:  17%|█▋        | 33/196 [04:47<22:54,  8.43s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 4:  17%|█▋        | 34/196 [04:47<22:44,  8.42s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 4:  17%|█▋        | 34/196 [04:55<22:44,  8.42s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 4:  18%|█▊        | 35/196 [04:55<22:36,  8.43s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 4:  18%|█▊        | 35/196 [05:04<22:36,  8.43s/it, training_loss=0.416]\u001b[A\n",
            "Epoch 4:  18%|█▊        | 36/196 [05:04<22:27,  8.42s/it, training_loss=0.416]\u001b[A\n",
            "Epoch 4:  18%|█▊        | 36/196 [05:12<22:27,  8.42s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 4:  19%|█▉        | 37/196 [05:12<22:29,  8.48s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 4:  19%|█▉        | 37/196 [05:21<22:29,  8.48s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 4:  19%|█▉        | 38/196 [05:21<22:25,  8.52s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 4:  19%|█▉        | 38/196 [05:30<22:25,  8.52s/it, training_loss=0.276]\u001b[A\n",
            "Epoch 4:  20%|█▉        | 39/196 [05:30<22:20,  8.54s/it, training_loss=0.276]\u001b[A\n",
            "Epoch 4:  20%|█▉        | 39/196 [05:38<22:20,  8.54s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 4:  20%|██        | 40/196 [05:38<22:16,  8.57s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 4:  20%|██        | 40/196 [05:47<22:16,  8.57s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 4:  21%|██        | 41/196 [05:47<22:02,  8.53s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 4:  21%|██        | 41/196 [05:55<22:02,  8.53s/it, training_loss=0.556]\u001b[A\n",
            "Epoch 4:  21%|██▏       | 42/196 [05:55<21:55,  8.54s/it, training_loss=0.556]\u001b[A\n",
            "Epoch 4:  21%|██▏       | 42/196 [06:04<21:55,  8.54s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 4:  22%|██▏       | 43/196 [06:04<21:43,  8.52s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 4:  22%|██▏       | 43/196 [06:12<21:43,  8.52s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 4:  22%|██▏       | 44/196 [06:12<21:40,  8.55s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 4:  22%|██▏       | 44/196 [06:21<21:40,  8.55s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 4:  23%|██▎       | 45/196 [06:21<21:31,  8.55s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 4:  23%|██▎       | 45/196 [06:30<21:31,  8.55s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 4:  23%|██▎       | 46/196 [06:30<21:24,  8.57s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 4:  23%|██▎       | 46/196 [06:38<21:24,  8.57s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 4:  24%|██▍       | 47/196 [06:38<21:19,  8.59s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 4:  24%|██▍       | 47/196 [06:47<21:19,  8.59s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 4:  24%|██▍       | 48/196 [06:47<21:12,  8.60s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 4:  24%|██▍       | 48/196 [06:55<21:12,  8.60s/it, training_loss=0.475]\u001b[A\n",
            "Epoch 4:  25%|██▌       | 49/196 [06:55<21:06,  8.62s/it, training_loss=0.475]\u001b[A\n",
            "Epoch 4:  25%|██▌       | 49/196 [07:04<21:06,  8.62s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 4:  26%|██▌       | 50/196 [07:04<20:59,  8.63s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 4:  26%|██▌       | 50/196 [07:13<20:59,  8.63s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 4:  26%|██▌       | 51/196 [07:13<20:51,  8.63s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 4:  26%|██▌       | 51/196 [07:21<20:51,  8.63s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 4:  27%|██▋       | 52/196 [07:21<20:44,  8.65s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 4:  27%|██▋       | 52/196 [07:30<20:44,  8.65s/it, training_loss=0.501]\u001b[A\n",
            "Epoch 4:  27%|██▋       | 53/196 [07:30<20:37,  8.66s/it, training_loss=0.501]\u001b[A\n",
            "Epoch 4:  27%|██▋       | 53/196 [07:39<20:37,  8.66s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 4:  28%|██▊       | 54/196 [07:39<20:30,  8.66s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 4:  28%|██▊       | 54/196 [07:47<20:30,  8.66s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 4:  28%|██▊       | 55/196 [07:47<20:18,  8.64s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 4:  28%|██▊       | 55/196 [07:56<20:18,  8.64s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 4:  29%|██▊       | 56/196 [07:56<20:11,  8.65s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 4:  29%|██▊       | 56/196 [08:05<20:11,  8.65s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 4:  29%|██▉       | 57/196 [08:05<20:02,  8.65s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 4:  29%|██▉       | 57/196 [08:13<20:02,  8.65s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 4:  30%|██▉       | 58/196 [08:13<19:49,  8.62s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 4:  30%|██▉       | 58/196 [08:22<19:49,  8.62s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 4:  30%|███       | 59/196 [08:22<19:43,  8.64s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 4:  30%|███       | 59/196 [08:31<19:43,  8.64s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 4:  31%|███       | 60/196 [08:31<19:36,  8.65s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 4:  31%|███       | 60/196 [08:39<19:36,  8.65s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 4:  31%|███       | 61/196 [08:39<19:30,  8.67s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 4:  31%|███       | 61/196 [08:48<19:30,  8.67s/it, training_loss=0.569]\u001b[A\n",
            "Epoch 4:  32%|███▏      | 62/196 [08:48<19:20,  8.66s/it, training_loss=0.569]\u001b[A\n",
            "Epoch 4:  32%|███▏      | 62/196 [08:57<19:20,  8.66s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 4:  32%|███▏      | 63/196 [08:57<19:13,  8.67s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 4:  32%|███▏      | 63/196 [09:05<19:13,  8.67s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 4:  33%|███▎      | 64/196 [09:05<19:06,  8.69s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 4:  33%|███▎      | 64/196 [09:14<19:06,  8.69s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 4:  33%|███▎      | 65/196 [09:14<18:56,  8.68s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 4:  33%|███▎      | 65/196 [09:23<18:56,  8.68s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 4:  34%|███▎      | 66/196 [09:23<18:47,  8.67s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 4:  34%|███▎      | 66/196 [09:31<18:47,  8.67s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 4:  34%|███▍      | 67/196 [09:31<18:39,  8.68s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 4:  34%|███▍      | 67/196 [09:40<18:39,  8.68s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 4:  35%|███▍      | 68/196 [09:40<18:31,  8.69s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 4:  35%|███▍      | 68/196 [09:49<18:31,  8.69s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 4:  35%|███▌      | 69/196 [09:49<18:24,  8.70s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 4:  35%|███▌      | 69/196 [09:58<18:24,  8.70s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 4:  36%|███▌      | 70/196 [09:58<18:17,  8.71s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 4:  36%|███▌      | 70/196 [10:06<18:17,  8.71s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 4:  36%|███▌      | 71/196 [10:06<18:07,  8.70s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 4:  36%|███▌      | 71/196 [10:15<18:07,  8.70s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 4:  37%|███▋      | 72/196 [10:15<17:58,  8.70s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 4:  37%|███▋      | 72/196 [10:24<17:58,  8.70s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 4:  37%|███▋      | 73/196 [10:24<17:48,  8.69s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 4:  37%|███▋      | 73/196 [10:32<17:48,  8.69s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 4:  38%|███▊      | 74/196 [10:32<17:39,  8.68s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 4:  38%|███▊      | 74/196 [10:41<17:39,  8.68s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 4:  38%|███▊      | 75/196 [10:41<17:31,  8.69s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 4:  38%|███▊      | 75/196 [10:50<17:31,  8.69s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 4:  39%|███▉      | 76/196 [10:50<17:22,  8.69s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 4:  39%|███▉      | 76/196 [10:58<17:22,  8.69s/it, training_loss=0.475]\u001b[A\n",
            "Epoch 4:  39%|███▉      | 77/196 [10:58<17:13,  8.68s/it, training_loss=0.475]\u001b[A\n",
            "Epoch 4:  39%|███▉      | 77/196 [11:07<17:13,  8.68s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 4:  40%|███▉      | 78/196 [11:07<17:05,  8.69s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 4:  40%|███▉      | 78/196 [11:16<17:05,  8.69s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 4:  40%|████      | 79/196 [11:16<16:56,  8.69s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 4:  40%|████      | 79/196 [11:24<16:56,  8.69s/it, training_loss=0.443]\u001b[A\n",
            "Epoch 4:  41%|████      | 80/196 [11:24<16:41,  8.64s/it, training_loss=0.443]\u001b[A\n",
            "Epoch 4:  41%|████      | 80/196 [11:33<16:41,  8.64s/it, training_loss=0.411]\u001b[A\n",
            "Epoch 4:  41%|████▏     | 81/196 [11:33<16:34,  8.64s/it, training_loss=0.411]\u001b[A\n",
            "Epoch 4:  41%|████▏     | 81/196 [11:42<16:34,  8.64s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 4:  42%|████▏     | 82/196 [11:42<16:25,  8.65s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 4:  42%|████▏     | 82/196 [11:50<16:25,  8.65s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 4:  42%|████▏     | 83/196 [11:50<16:17,  8.65s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 4:  42%|████▏     | 83/196 [11:59<16:17,  8.65s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 4:  43%|████▎     | 84/196 [11:59<16:08,  8.65s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 4:  43%|████▎     | 84/196 [12:08<16:08,  8.65s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 4:  43%|████▎     | 85/196 [12:08<16:00,  8.66s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 4:  43%|████▎     | 85/196 [12:16<16:00,  8.66s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 4:  44%|████▍     | 86/196 [12:16<15:51,  8.65s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 4:  44%|████▍     | 86/196 [12:25<15:51,  8.65s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 4:  44%|████▍     | 87/196 [12:25<15:40,  8.63s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 4:  44%|████▍     | 87/196 [12:33<15:40,  8.63s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 4:  45%|████▍     | 88/196 [12:33<15:29,  8.60s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 4:  45%|████▍     | 88/196 [12:42<15:29,  8.60s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 4:  45%|████▌     | 89/196 [12:42<15:22,  8.62s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 4:  45%|████▌     | 89/196 [12:51<15:22,  8.62s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 4:  46%|████▌     | 90/196 [12:51<15:14,  8.63s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 4:  46%|████▌     | 90/196 [12:59<15:14,  8.63s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 4:  46%|████▋     | 91/196 [12:59<15:06,  8.63s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 4:  46%|████▋     | 91/196 [13:08<15:06,  8.63s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 4:  47%|████▋     | 92/196 [13:08<14:58,  8.64s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 4:  47%|████▋     | 92/196 [13:17<14:58,  8.64s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 4:  47%|████▋     | 93/196 [13:17<14:50,  8.65s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 4:  47%|████▋     | 93/196 [13:25<14:50,  8.65s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 4:  48%|████▊     | 94/196 [13:25<14:43,  8.66s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 4:  48%|████▊     | 94/196 [13:34<14:43,  8.66s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 4:  48%|████▊     | 95/196 [13:34<14:31,  8.63s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 4:  48%|████▊     | 95/196 [13:43<14:31,  8.63s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 4:  49%|████▉     | 96/196 [13:43<14:24,  8.64s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 4:  49%|████▉     | 96/196 [13:51<14:24,  8.64s/it, training_loss=0.441]\u001b[A\n",
            "Epoch 4:  49%|████▉     | 97/196 [13:51<14:16,  8.65s/it, training_loss=0.441]\u001b[A\n",
            "Epoch 4:  49%|████▉     | 97/196 [14:00<14:16,  8.65s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 4:  50%|█████     | 98/196 [14:00<14:08,  8.66s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 4:  50%|█████     | 98/196 [14:09<14:08,  8.66s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 4:  51%|█████     | 99/196 [14:09<13:59,  8.66s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 4:  51%|█████     | 99/196 [14:17<13:59,  8.66s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 4:  51%|█████     | 100/196 [14:17<13:51,  8.66s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 4:  51%|█████     | 100/196 [14:26<13:51,  8.66s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 4:  52%|█████▏    | 101/196 [14:26<13:42,  8.65s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 4:  52%|█████▏    | 101/196 [14:34<13:42,  8.65s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 4:  52%|█████▏    | 102/196 [14:34<13:30,  8.62s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 4:  52%|█████▏    | 102/196 [14:43<13:30,  8.62s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 4:  53%|█████▎    | 103/196 [14:43<13:21,  8.62s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 4:  53%|█████▎    | 103/196 [14:52<13:21,  8.62s/it, training_loss=0.427]\u001b[A\n",
            "Epoch 4:  53%|█████▎    | 104/196 [14:52<13:14,  8.63s/it, training_loss=0.427]\u001b[A\n",
            "Epoch 4:  53%|█████▎    | 104/196 [15:00<13:14,  8.63s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 4:  54%|█████▎    | 105/196 [15:00<13:05,  8.63s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 4:  54%|█████▎    | 105/196 [15:09<13:05,  8.63s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 4:  54%|█████▍    | 106/196 [15:09<12:57,  8.64s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 4:  54%|█████▍    | 106/196 [15:18<12:57,  8.64s/it, training_loss=0.349]\u001b[A\n",
            "Epoch 4:  55%|█████▍    | 107/196 [15:18<12:49,  8.64s/it, training_loss=0.349]\u001b[A\n",
            "Epoch 4:  55%|█████▍    | 107/196 [15:26<12:49,  8.64s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 4:  55%|█████▌    | 108/196 [15:26<12:40,  8.64s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 4:  55%|█████▌    | 108/196 [15:35<12:40,  8.64s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 4:  56%|█████▌    | 109/196 [15:35<12:31,  8.63s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 4:  56%|█████▌    | 109/196 [15:43<12:31,  8.63s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 4:  56%|█████▌    | 110/196 [15:43<12:19,  8.60s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 4:  56%|█████▌    | 110/196 [15:52<12:19,  8.60s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 4:  57%|█████▋    | 111/196 [15:52<12:11,  8.61s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 4:  57%|█████▋    | 111/196 [16:01<12:11,  8.61s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 4:  57%|█████▋    | 112/196 [16:01<12:02,  8.60s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 4:  57%|█████▋    | 112/196 [16:09<12:02,  8.60s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 4:  58%|█████▊    | 113/196 [16:09<11:53,  8.60s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 4:  58%|█████▊    | 113/196 [16:18<11:53,  8.60s/it, training_loss=0.331]\u001b[A\n",
            "Epoch 4:  58%|█████▊    | 114/196 [16:18<11:44,  8.59s/it, training_loss=0.331]\u001b[A\n",
            "Epoch 4:  58%|█████▊    | 114/196 [16:26<11:44,  8.59s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 4:  59%|█████▊    | 115/196 [16:26<11:34,  8.58s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 4:  59%|█████▊    | 115/196 [16:35<11:34,  8.58s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 4:  59%|█████▉    | 116/196 [16:35<11:25,  8.57s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 4:  59%|█████▉    | 116/196 [16:43<11:25,  8.57s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 4:  60%|█████▉    | 117/196 [16:43<11:14,  8.54s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 4:  60%|█████▉    | 117/196 [16:52<11:14,  8.54s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 4:  60%|██████    | 118/196 [16:52<11:05,  8.53s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 4:  60%|██████    | 118/196 [17:00<11:05,  8.53s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 4:  61%|██████    | 119/196 [17:00<10:56,  8.53s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 4:  61%|██████    | 119/196 [17:09<10:56,  8.53s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 4:  61%|██████    | 120/196 [17:09<10:49,  8.55s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 4:  61%|██████    | 120/196 [17:18<10:49,  8.55s/it, training_loss=0.514]\u001b[A\n",
            "Epoch 4:  62%|██████▏   | 121/196 [17:18<10:42,  8.57s/it, training_loss=0.514]\u001b[A\n",
            "Epoch 4:  62%|██████▏   | 121/196 [17:26<10:42,  8.57s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 4:  62%|██████▏   | 122/196 [17:26<10:33,  8.56s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 4:  62%|██████▏   | 122/196 [17:35<10:33,  8.56s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 4:  63%|██████▎   | 123/196 [17:35<10:24,  8.55s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 4:  63%|██████▎   | 123/196 [17:43<10:24,  8.55s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 4:  63%|██████▎   | 124/196 [17:43<10:13,  8.53s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 4:  63%|██████▎   | 124/196 [17:52<10:13,  8.53s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 4:  64%|██████▍   | 125/196 [17:52<10:04,  8.52s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 4:  64%|██████▍   | 125/196 [18:00<10:04,  8.52s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 4:  64%|██████▍   | 126/196 [18:00<09:55,  8.50s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 4:  64%|██████▍   | 126/196 [18:09<09:55,  8.50s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 4:  65%|██████▍   | 127/196 [18:09<09:46,  8.50s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 4:  65%|██████▍   | 127/196 [18:17<09:46,  8.50s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 4:  65%|██████▌   | 128/196 [18:17<09:36,  8.49s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 4:  65%|██████▌   | 128/196 [18:25<09:36,  8.49s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 4:  66%|██████▌   | 129/196 [18:25<09:26,  8.46s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 4:  66%|██████▌   | 129/196 [18:34<09:26,  8.46s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 4:  66%|██████▋   | 130/196 [18:34<09:16,  8.44s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 4:  66%|██████▋   | 130/196 [18:42<09:16,  8.44s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 4:  67%|██████▋   | 131/196 [18:42<09:08,  8.43s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 4:  67%|██████▋   | 131/196 [18:51<09:08,  8.43s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 4:  67%|██████▋   | 132/196 [18:51<08:58,  8.41s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 4:  67%|██████▋   | 132/196 [18:59<08:58,  8.41s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 4:  68%|██████▊   | 133/196 [18:59<08:50,  8.42s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 4:  68%|██████▊   | 133/196 [19:07<08:50,  8.42s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 4:  68%|██████▊   | 134/196 [19:07<08:42,  8.43s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 4:  68%|██████▊   | 134/196 [19:16<08:42,  8.43s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 4:  69%|██████▉   | 135/196 [19:16<08:33,  8.41s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 4:  69%|██████▉   | 135/196 [19:24<08:33,  8.41s/it, training_loss=0.382]\u001b[A\n",
            "Epoch 4:  69%|██████▉   | 136/196 [19:24<08:23,  8.40s/it, training_loss=0.382]\u001b[A\n",
            "Epoch 4:  69%|██████▉   | 136/196 [19:32<08:23,  8.40s/it, training_loss=0.450]\u001b[A\n",
            "Epoch 4:  70%|██████▉   | 137/196 [19:32<08:13,  8.36s/it, training_loss=0.450]\u001b[A\n",
            "Epoch 4:  70%|██████▉   | 137/196 [19:41<08:13,  8.36s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 4:  70%|███████   | 138/196 [19:41<08:03,  8.33s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 4:  70%|███████   | 138/196 [19:49<08:03,  8.33s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 4:  71%|███████   | 139/196 [19:49<07:58,  8.39s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 4:  71%|███████   | 139/196 [19:58<07:58,  8.39s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 4:  71%|███████▏  | 140/196 [19:58<07:51,  8.42s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 4:  71%|███████▏  | 140/196 [20:06<07:51,  8.42s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 4:  72%|███████▏  | 141/196 [20:06<07:46,  8.48s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 4:  72%|███████▏  | 141/196 [20:15<07:46,  8.48s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 4:  72%|███████▏  | 142/196 [20:15<07:38,  8.49s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 4:  72%|███████▏  | 142/196 [20:23<07:38,  8.49s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 4:  73%|███████▎  | 143/196 [20:23<07:31,  8.51s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 4:  73%|███████▎  | 143/196 [20:32<07:31,  8.51s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 4:  73%|███████▎  | 144/196 [20:32<07:22,  8.50s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 4:  73%|███████▎  | 144/196 [20:40<07:22,  8.50s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 4:  74%|███████▍  | 145/196 [20:40<07:12,  8.48s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 4:  74%|███████▍  | 145/196 [20:49<07:12,  8.48s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 4:  74%|███████▍  | 146/196 [20:49<07:04,  8.49s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 4:  74%|███████▍  | 146/196 [20:57<07:04,  8.49s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 4:  75%|███████▌  | 147/196 [20:57<06:55,  8.48s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 4:  75%|███████▌  | 147/196 [21:06<06:55,  8.48s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 4:  76%|███████▌  | 148/196 [21:06<06:46,  8.48s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 4:  76%|███████▌  | 148/196 [21:14<06:46,  8.48s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 4:  76%|███████▌  | 149/196 [21:14<06:38,  8.48s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 4:  76%|███████▌  | 149/196 [21:23<06:38,  8.48s/it, training_loss=0.379]\u001b[A\n",
            "Epoch 4:  77%|███████▋  | 150/196 [21:23<06:29,  8.47s/it, training_loss=0.379]\u001b[A\n",
            "Epoch 4:  77%|███████▋  | 150/196 [21:31<06:29,  8.47s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 4:  77%|███████▋  | 151/196 [21:31<06:20,  8.46s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 4:  77%|███████▋  | 151/196 [21:40<06:20,  8.46s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 4:  78%|███████▊  | 152/196 [21:40<06:11,  8.44s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 4:  78%|███████▊  | 152/196 [21:48<06:11,  8.44s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 4:  78%|███████▊  | 153/196 [21:48<06:02,  8.44s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 4:  78%|███████▊  | 153/196 [21:57<06:02,  8.44s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 4:  79%|███████▊  | 154/196 [21:57<05:55,  8.46s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 4:  79%|███████▊  | 154/196 [22:05<05:55,  8.46s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 4:  79%|███████▉  | 155/196 [22:05<05:45,  8.42s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 4:  79%|███████▉  | 155/196 [22:13<05:45,  8.42s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 4:  80%|███████▉  | 156/196 [22:13<05:37,  8.44s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 4:  80%|███████▉  | 156/196 [22:22<05:37,  8.44s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 4:  80%|████████  | 157/196 [22:22<05:28,  8.43s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 4:  80%|████████  | 157/196 [22:30<05:28,  8.43s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 4:  81%|████████  | 158/196 [22:30<05:20,  8.43s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 4:  81%|████████  | 158/196 [22:39<05:20,  8.43s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 4:  81%|████████  | 159/196 [22:39<05:11,  8.42s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 4:  81%|████████  | 159/196 [22:47<05:11,  8.42s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 4:  82%|████████▏ | 160/196 [22:47<05:03,  8.42s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 4:  82%|████████▏ | 160/196 [22:55<05:03,  8.42s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 4:  82%|████████▏ | 161/196 [22:55<04:55,  8.43s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 4:  82%|████████▏ | 161/196 [23:04<04:55,  8.43s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 4:  83%|████████▎ | 162/196 [23:04<04:45,  8.40s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 4:  83%|████████▎ | 162/196 [23:12<04:45,  8.40s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 4:  83%|████████▎ | 163/196 [23:12<04:37,  8.42s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 4:  83%|████████▎ | 163/196 [23:21<04:37,  8.42s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 4:  84%|████████▎ | 164/196 [23:21<04:30,  8.44s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 4:  84%|████████▎ | 164/196 [23:29<04:30,  8.44s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 4:  84%|████████▍ | 165/196 [23:29<04:21,  8.45s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 4:  84%|████████▍ | 165/196 [23:38<04:21,  8.45s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 4:  85%|████████▍ | 166/196 [23:38<04:13,  8.45s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 4:  85%|████████▍ | 166/196 [23:46<04:13,  8.45s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 4:  85%|████████▌ | 167/196 [23:46<04:05,  8.45s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 4:  85%|████████▌ | 167/196 [23:55<04:05,  8.45s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 4:  86%|████████▌ | 168/196 [23:55<03:56,  8.45s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 4:  86%|████████▌ | 168/196 [24:03<03:56,  8.45s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 4:  86%|████████▌ | 169/196 [24:03<03:48,  8.45s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 4:  86%|████████▌ | 169/196 [24:11<03:48,  8.45s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 4:  87%|████████▋ | 170/196 [24:11<03:38,  8.42s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 4:  87%|████████▋ | 170/196 [24:20<03:38,  8.42s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 4:  87%|████████▋ | 171/196 [24:20<03:30,  8.43s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 4:  87%|████████▋ | 171/196 [24:28<03:30,  8.43s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 4:  88%|████████▊ | 172/196 [24:28<03:22,  8.43s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 4:  88%|████████▊ | 172/196 [24:37<03:22,  8.43s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 4:  88%|████████▊ | 173/196 [24:37<03:14,  8.46s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 4:  88%|████████▊ | 173/196 [24:45<03:14,  8.46s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 4:  89%|████████▉ | 174/196 [24:45<03:05,  8.45s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 4:  89%|████████▉ | 174/196 [24:54<03:05,  8.45s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 4:  89%|████████▉ | 175/196 [24:54<02:56,  8.43s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 4:  89%|████████▉ | 175/196 [25:02<02:56,  8.43s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 4:  90%|████████▉ | 176/196 [25:02<02:47,  8.39s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 4:  90%|████████▉ | 176/196 [25:10<02:47,  8.39s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 4:  90%|█████████ | 177/196 [25:10<02:38,  8.35s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 4:  90%|█████████ | 177/196 [25:18<02:38,  8.35s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 4:  91%|█████████ | 178/196 [25:18<02:29,  8.29s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 4:  91%|█████████ | 178/196 [25:27<02:29,  8.29s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 4:  91%|█████████▏| 179/196 [25:27<02:21,  8.30s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 4:  91%|█████████▏| 179/196 [25:35<02:21,  8.30s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 4:  92%|█████████▏| 180/196 [25:35<02:12,  8.30s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 4:  92%|█████████▏| 180/196 [25:43<02:12,  8.30s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 4:  92%|█████████▏| 181/196 [25:43<02:04,  8.29s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 4:  92%|█████████▏| 181/196 [25:51<02:04,  8.29s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 4:  93%|█████████▎| 182/196 [25:51<01:56,  8.29s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 4:  93%|█████████▎| 182/196 [26:00<01:56,  8.29s/it, training_loss=0.675]\u001b[A\n",
            "Epoch 4:  93%|█████████▎| 183/196 [26:00<01:47,  8.28s/it, training_loss=0.675]\u001b[A\n",
            "Epoch 4:  93%|█████████▎| 183/196 [26:08<01:47,  8.28s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 4:  94%|█████████▍| 184/196 [26:08<01:39,  8.26s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 4:  94%|█████████▍| 184/196 [26:16<01:39,  8.26s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 4:  94%|█████████▍| 185/196 [26:16<01:30,  8.22s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 4:  94%|█████████▍| 185/196 [26:24<01:30,  8.22s/it, training_loss=0.909]\u001b[A\n",
            "Epoch 4:  95%|█████████▍| 186/196 [26:24<01:22,  8.23s/it, training_loss=0.909]\u001b[A\n",
            "Epoch 4:  95%|█████████▍| 186/196 [26:32<01:22,  8.23s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 4:  95%|█████████▌| 187/196 [26:32<01:13,  8.22s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 4:  95%|█████████▌| 187/196 [26:41<01:13,  8.22s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 4:  96%|█████████▌| 188/196 [26:41<01:05,  8.24s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 4:  96%|█████████▌| 188/196 [26:49<01:05,  8.24s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 4:  96%|█████████▋| 189/196 [26:49<00:57,  8.25s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 4:  96%|█████████▋| 189/196 [26:57<00:57,  8.25s/it, training_loss=0.684]\u001b[A\n",
            "Epoch 4:  97%|█████████▋| 190/196 [26:57<00:49,  8.26s/it, training_loss=0.684]\u001b[A\n",
            "Epoch 4:  97%|█████████▋| 190/196 [27:06<00:49,  8.26s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 4:  97%|█████████▋| 191/196 [27:06<00:41,  8.27s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 4:  97%|█████████▋| 191/196 [27:14<00:41,  8.27s/it, training_loss=0.376]\u001b[A\n",
            "Epoch 4:  98%|█████████▊| 192/196 [27:14<00:33,  8.28s/it, training_loss=0.376]\u001b[A\n",
            "Epoch 4:  98%|█████████▊| 192/196 [27:22<00:33,  8.28s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 4:  98%|█████████▊| 193/196 [27:22<00:24,  8.24s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 4:  98%|█████████▊| 193/196 [27:30<00:24,  8.24s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 4:  99%|█████████▉| 194/196 [27:30<00:16,  8.25s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 4:  99%|█████████▉| 194/196 [27:39<00:16,  8.25s/it, training_loss=0.332]\u001b[A\n",
            "Epoch 4:  99%|█████████▉| 195/196 [27:39<00:08,  8.26s/it, training_loss=0.332]\u001b[A\n",
            "Epoch 4:  99%|█████████▉| 195/196 [27:42<00:08,  8.26s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 4: 100%|██████████| 196/196 [27:42<00:00,  6.75s/it, training_loss=0.109]\u001b[A\n",
            " 60%|██████    | 3/5 [1:52:25<56:46, 1703.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4\n",
            "Training loss: 0.44515592365392614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 4/5 [1:53:53<28:42, 1722.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.7136821965021747\n",
            "F1 Score (Weighted): 0.7203054298642534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 5:   0%|          | 0/196 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5:   0%|          | 0/196 [00:08<?, ?it/s, training_loss=0.024]\u001b[A\n",
            "Epoch 5:   1%|          | 1/196 [00:08<26:52,  8.27s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 5:   1%|          | 1/196 [00:16<26:52,  8.27s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 5:   1%|          | 2/196 [00:16<26:30,  8.20s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 5:   1%|          | 2/196 [00:24<26:30,  8.20s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 5:   2%|▏         | 3/196 [00:24<26:19,  8.18s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 5:   2%|▏         | 3/196 [00:32<26:19,  8.18s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 5:   2%|▏         | 4/196 [00:32<26:16,  8.21s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 5:   2%|▏         | 4/196 [00:41<26:16,  8.21s/it, training_loss=0.369]\u001b[A\n",
            "Epoch 5:   3%|▎         | 5/196 [00:41<26:16,  8.25s/it, training_loss=0.369]\u001b[A\n",
            "Epoch 5:   3%|▎         | 5/196 [00:49<26:16,  8.25s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 5:   3%|▎         | 6/196 [00:49<26:13,  8.28s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 5:   3%|▎         | 6/196 [00:57<26:13,  8.28s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 5:   4%|▎         | 7/196 [00:57<26:07,  8.30s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 5:   4%|▎         | 7/196 [01:06<26:07,  8.30s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 5:   4%|▍         | 8/196 [01:06<26:00,  8.30s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 5:   4%|▍         | 8/196 [01:14<26:00,  8.30s/it, training_loss=0.437]\u001b[A\n",
            "Epoch 5:   5%|▍         | 9/196 [01:14<25:51,  8.29s/it, training_loss=0.437]\u001b[A\n",
            "Epoch 5:   5%|▍         | 9/196 [01:22<25:51,  8.29s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 5:   5%|▌         | 10/196 [01:22<25:32,  8.24s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 5:   5%|▌         | 10/196 [01:30<25:32,  8.24s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 5:   6%|▌         | 11/196 [01:30<25:25,  8.25s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 5:   6%|▌         | 11/196 [01:39<25:25,  8.25s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 5:   6%|▌         | 12/196 [01:39<25:22,  8.28s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 5:   6%|▌         | 12/196 [01:47<25:22,  8.28s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 5:   7%|▋         | 13/196 [01:47<25:17,  8.29s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 5:   7%|▋         | 13/196 [01:55<25:17,  8.29s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 5:   7%|▋         | 14/196 [01:55<25:13,  8.31s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 5:   7%|▋         | 14/196 [02:04<25:13,  8.31s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 5:   8%|▊         | 15/196 [02:04<25:04,  8.31s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 5:   8%|▊         | 15/196 [02:12<25:04,  8.31s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 5:   8%|▊         | 16/196 [02:12<24:49,  8.27s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 5:   8%|▊         | 16/196 [02:20<24:49,  8.27s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 5:   9%|▊         | 17/196 [02:20<24:37,  8.26s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 5:   9%|▊         | 17/196 [02:28<24:37,  8.26s/it, training_loss=0.533]\u001b[A\n",
            "Epoch 5:   9%|▉         | 18/196 [02:28<24:15,  8.18s/it, training_loss=0.533]\u001b[A\n",
            "Epoch 5:   9%|▉         | 18/196 [02:36<24:15,  8.18s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 5:  10%|▉         | 19/196 [02:36<24:05,  8.17s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 5:  10%|▉         | 19/196 [02:44<24:05,  8.17s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 5:  10%|█         | 20/196 [02:44<23:57,  8.17s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 5:  10%|█         | 20/196 [02:52<23:57,  8.17s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 5:  11%|█         | 21/196 [02:53<23:48,  8.16s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 5:  11%|█         | 21/196 [03:01<23:48,  8.16s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 5:  11%|█         | 22/196 [03:01<23:40,  8.16s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 5:  11%|█         | 22/196 [03:09<23:40,  8.16s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 5:  12%|█▏        | 23/196 [03:09<23:31,  8.16s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 5:  12%|█▏        | 23/196 [03:17<23:31,  8.16s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 5:  12%|█▏        | 24/196 [03:17<23:21,  8.15s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 5:  12%|█▏        | 24/196 [03:25<23:21,  8.15s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 5:  13%|█▎        | 25/196 [03:25<23:13,  8.15s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 5:  13%|█▎        | 25/196 [03:33<23:13,  8.15s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 5:  13%|█▎        | 26/196 [03:33<22:55,  8.09s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 5:  13%|█▎        | 26/196 [03:41<22:55,  8.09s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 5:  14%|█▍        | 27/196 [03:41<22:50,  8.11s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 5:  14%|█▍        | 27/196 [03:49<22:50,  8.11s/it, training_loss=0.411]\u001b[A\n",
            "Epoch 5:  14%|█▍        | 28/196 [03:49<22:42,  8.11s/it, training_loss=0.411]\u001b[A\n",
            "Epoch 5:  14%|█▍        | 28/196 [03:57<22:42,  8.11s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 5:  15%|█▍        | 29/196 [03:58<22:38,  8.13s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 5:  15%|█▍        | 29/196 [04:06<22:38,  8.13s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 5:  15%|█▌        | 30/196 [04:06<22:31,  8.14s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 5:  15%|█▌        | 30/196 [04:14<22:31,  8.14s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 5:  16%|█▌        | 31/196 [04:14<22:28,  8.17s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 5:  16%|█▌        | 31/196 [04:22<22:28,  8.17s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 5:  16%|█▋        | 32/196 [04:22<22:21,  8.18s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 5:  16%|█▋        | 32/196 [04:30<22:21,  8.18s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 5:  17%|█▋        | 33/196 [04:30<22:11,  8.17s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 5:  17%|█▋        | 33/196 [04:38<22:11,  8.17s/it, training_loss=0.419]\u001b[A\n",
            "Epoch 5:  17%|█▋        | 34/196 [04:38<21:55,  8.12s/it, training_loss=0.419]\u001b[A\n",
            "Epoch 5:  17%|█▋        | 34/196 [04:46<21:55,  8.12s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 5:  18%|█▊        | 35/196 [04:46<21:51,  8.15s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 5:  18%|█▊        | 35/196 [04:55<21:51,  8.15s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 5:  18%|█▊        | 36/196 [04:55<21:46,  8.17s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 5:  18%|█▊        | 36/196 [05:03<21:46,  8.17s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 5:  19%|█▉        | 37/196 [05:03<21:39,  8.17s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 5:  19%|█▉        | 37/196 [05:11<21:39,  8.17s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 5:  19%|█▉        | 38/196 [05:11<21:28,  8.15s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 5:  19%|█▉        | 38/196 [05:19<21:28,  8.15s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 5:  20%|█▉        | 39/196 [05:19<21:19,  8.15s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 5:  20%|█▉        | 39/196 [05:27<21:19,  8.15s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 5:  20%|██        | 40/196 [05:27<21:08,  8.13s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 5:  20%|██        | 40/196 [05:35<21:08,  8.13s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 5:  21%|██        | 41/196 [05:35<20:58,  8.12s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 5:  21%|██        | 41/196 [05:43<20:58,  8.12s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 5:  21%|██▏       | 42/196 [05:43<20:47,  8.10s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 5:  21%|██▏       | 42/196 [05:51<20:47,  8.10s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 5:  22%|██▏       | 43/196 [05:51<20:39,  8.10s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 5:  22%|██▏       | 43/196 [06:00<20:39,  8.10s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 5:  22%|██▏       | 44/196 [06:00<20:36,  8.13s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 5:  22%|██▏       | 44/196 [06:08<20:36,  8.13s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 5:  23%|██▎       | 45/196 [06:08<20:30,  8.15s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 5:  23%|██▎       | 45/196 [06:16<20:30,  8.15s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 5:  23%|██▎       | 46/196 [06:16<20:24,  8.16s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 5:  23%|██▎       | 46/196 [06:24<20:24,  8.16s/it, training_loss=0.303]\u001b[A\n",
            "Epoch 5:  24%|██▍       | 47/196 [06:24<20:18,  8.18s/it, training_loss=0.303]\u001b[A\n",
            "Epoch 5:  24%|██▍       | 47/196 [06:32<20:18,  8.18s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 5:  24%|██▍       | 48/196 [06:32<20:08,  8.17s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 5:  24%|██▍       | 48/196 [06:40<20:08,  8.17s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 5:  25%|██▌       | 49/196 [06:40<19:56,  8.14s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 5:  25%|██▌       | 49/196 [06:49<19:56,  8.14s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 5:  26%|██▌       | 50/196 [06:49<19:47,  8.13s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 5:  26%|██▌       | 50/196 [06:57<19:47,  8.13s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 5:  26%|██▌       | 51/196 [06:57<19:39,  8.13s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 5:  26%|██▌       | 51/196 [07:05<19:39,  8.13s/it, training_loss=0.471]\u001b[A\n",
            "Epoch 5:  27%|██▋       | 52/196 [07:05<19:32,  8.14s/it, training_loss=0.471]\u001b[A\n",
            "Epoch 5:  27%|██▋       | 52/196 [07:13<19:32,  8.14s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 5:  27%|██▋       | 53/196 [07:13<19:25,  8.15s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 5:  27%|██▋       | 53/196 [07:21<19:25,  8.15s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 5:  28%|██▊       | 54/196 [07:21<19:22,  8.19s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 5:  28%|██▊       | 54/196 [07:30<19:22,  8.19s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 5:  28%|██▊       | 55/196 [07:30<19:17,  8.21s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 5:  28%|██▊       | 55/196 [07:38<19:17,  8.21s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 5:  29%|██▊       | 56/196 [07:38<19:11,  8.22s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 5:  29%|██▊       | 56/196 [07:46<19:11,  8.22s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 5:  29%|██▉       | 57/196 [07:46<18:59,  8.20s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 5:  29%|██▉       | 57/196 [07:54<18:59,  8.20s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 5:  30%|██▉       | 58/196 [07:54<18:52,  8.21s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 5:  30%|██▉       | 58/196 [08:03<18:52,  8.21s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 5:  30%|███       | 59/196 [08:03<18:50,  8.25s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 5:  30%|███       | 59/196 [08:11<18:50,  8.25s/it, training_loss=0.532]\u001b[A\n",
            "Epoch 5:  31%|███       | 60/196 [08:11<18:41,  8.24s/it, training_loss=0.532]\u001b[A\n",
            "Epoch 5:  31%|███       | 60/196 [08:19<18:41,  8.24s/it, training_loss=0.540]\u001b[A\n",
            "Epoch 5:  31%|███       | 61/196 [08:19<18:28,  8.21s/it, training_loss=0.540]\u001b[A\n",
            "Epoch 5:  31%|███       | 61/196 [08:27<18:28,  8.21s/it, training_loss=0.400]\u001b[A\n",
            "Epoch 5:  32%|███▏      | 62/196 [08:27<18:20,  8.21s/it, training_loss=0.400]\u001b[A\n",
            "Epoch 5:  32%|███▏      | 62/196 [08:35<18:20,  8.21s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 5:  32%|███▏      | 63/196 [08:35<18:07,  8.17s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 5:  32%|███▏      | 63/196 [08:43<18:07,  8.17s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 5:  33%|███▎      | 64/196 [08:43<17:58,  8.17s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 5:  33%|███▎      | 64/196 [08:51<17:58,  8.17s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 5:  33%|███▎      | 65/196 [08:51<17:40,  8.09s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 5:  33%|███▎      | 65/196 [08:59<17:40,  8.09s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 5:  34%|███▎      | 66/196 [08:59<17:35,  8.12s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 5:  34%|███▎      | 66/196 [09:08<17:35,  8.12s/it, training_loss=0.361]\u001b[A\n",
            "Epoch 5:  34%|███▍      | 67/196 [09:08<17:28,  8.13s/it, training_loss=0.361]\u001b[A\n",
            "Epoch 5:  34%|███▍      | 67/196 [09:16<17:28,  8.13s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 5:  35%|███▍      | 68/196 [09:16<17:23,  8.15s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 5:  35%|███▍      | 68/196 [09:24<17:23,  8.15s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 5:  35%|███▌      | 69/196 [09:24<17:17,  8.17s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 5:  35%|███▌      | 69/196 [09:32<17:17,  8.17s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 5:  36%|███▌      | 70/196 [09:32<17:09,  8.17s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 5:  36%|███▌      | 70/196 [09:40<17:09,  8.17s/it, training_loss=0.365]\u001b[A\n",
            "Epoch 5:  36%|███▌      | 71/196 [09:40<16:59,  8.16s/it, training_loss=0.365]\u001b[A\n",
            "Epoch 5:  36%|███▌      | 71/196 [09:48<16:59,  8.16s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 5:  37%|███▋      | 72/196 [09:48<16:50,  8.15s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 5:  37%|███▋      | 72/196 [09:56<16:50,  8.15s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 5:  37%|███▋      | 73/196 [09:56<16:33,  8.08s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 5:  37%|███▋      | 73/196 [10:05<16:33,  8.08s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 5:  38%|███▊      | 74/196 [10:05<16:31,  8.13s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 5:  38%|███▊      | 74/196 [10:13<16:31,  8.13s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 5:  38%|███▊      | 75/196 [10:13<16:26,  8.15s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 5:  38%|███▊      | 75/196 [10:21<16:26,  8.15s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 5:  39%|███▉      | 76/196 [10:21<16:22,  8.19s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 5:  39%|███▉      | 76/196 [10:29<16:22,  8.19s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 5:  39%|███▉      | 77/196 [10:29<16:15,  8.19s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 5:  39%|███▉      | 77/196 [10:38<16:15,  8.19s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 5:  40%|███▉      | 78/196 [10:38<16:06,  8.19s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 5:  40%|███▉      | 78/196 [10:46<16:06,  8.19s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 5:  40%|████      | 79/196 [10:46<15:58,  8.20s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 5:  40%|████      | 79/196 [10:54<15:58,  8.20s/it, training_loss=0.438]\u001b[A\n",
            "Epoch 5:  41%|████      | 80/196 [10:54<15:51,  8.20s/it, training_loss=0.438]\u001b[A\n",
            "Epoch 5:  41%|████      | 80/196 [11:02<15:51,  8.20s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 5:  41%|████▏     | 81/196 [11:02<15:36,  8.14s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 5:  41%|████▏     | 81/196 [11:10<15:36,  8.14s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 5:  42%|████▏     | 82/196 [11:10<15:29,  8.16s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 5:  42%|████▏     | 82/196 [11:18<15:29,  8.16s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 5:  42%|████▏     | 83/196 [11:18<15:23,  8.17s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 5:  42%|████▏     | 83/196 [11:27<15:23,  8.17s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 5:  43%|████▎     | 84/196 [11:27<15:16,  8.18s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 5:  43%|████▎     | 84/196 [11:35<15:16,  8.18s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 5:  43%|████▎     | 85/196 [11:35<15:06,  8.17s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 5:  43%|████▎     | 85/196 [11:43<15:06,  8.17s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 5:  44%|████▍     | 86/196 [11:43<14:59,  8.17s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 5:  44%|████▍     | 86/196 [11:51<14:59,  8.17s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 5:  44%|████▍     | 87/196 [11:51<14:51,  8.17s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 5:  44%|████▍     | 87/196 [11:59<14:51,  8.17s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 5:  45%|████▍     | 88/196 [11:59<14:42,  8.17s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 5:  45%|████▍     | 88/196 [12:07<14:42,  8.17s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 5:  45%|████▌     | 89/196 [12:07<14:28,  8.12s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 5:  45%|████▌     | 89/196 [12:15<14:28,  8.12s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 5:  46%|████▌     | 90/196 [12:15<14:21,  8.12s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 5:  46%|████▌     | 90/196 [12:23<14:21,  8.12s/it, training_loss=0.403]\u001b[A\n",
            "Epoch 5:  46%|████▋     | 91/196 [12:23<14:14,  8.13s/it, training_loss=0.403]\u001b[A\n",
            "Epoch 5:  46%|████▋     | 91/196 [12:32<14:14,  8.13s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 5:  47%|████▋     | 92/196 [12:32<14:06,  8.14s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 5:  47%|████▋     | 92/196 [12:40<14:06,  8.14s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 5:  47%|████▋     | 93/196 [12:40<14:00,  8.16s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 5:  47%|████▋     | 93/196 [12:48<14:00,  8.16s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 5:  48%|████▊     | 94/196 [12:48<13:55,  8.19s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 5:  48%|████▊     | 94/196 [12:56<13:55,  8.19s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 5:  48%|████▊     | 95/196 [12:56<13:49,  8.21s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 5:  48%|████▊     | 95/196 [13:05<13:49,  8.21s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 5:  49%|████▉     | 96/196 [13:05<13:38,  8.19s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 5:  49%|████▉     | 96/196 [13:12<13:38,  8.19s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 5:  49%|████▉     | 97/196 [13:12<13:24,  8.13s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 5:  49%|████▉     | 97/196 [13:21<13:24,  8.13s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 5:  50%|█████     | 98/196 [13:21<13:16,  8.13s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 5:  50%|█████     | 98/196 [13:29<13:16,  8.13s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 5:  51%|█████     | 99/196 [13:29<13:07,  8.12s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 5:  51%|█████     | 99/196 [13:37<13:07,  8.12s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 5:  51%|█████     | 100/196 [13:37<12:59,  8.12s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 5:  51%|█████     | 100/196 [13:45<12:59,  8.12s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 5:  52%|█████▏    | 101/196 [13:45<12:58,  8.19s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 5:  52%|█████▏    | 101/196 [13:54<12:58,  8.19s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 5:  52%|█████▏    | 102/196 [13:54<12:57,  8.27s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 5:  52%|█████▏    | 102/196 [14:02<12:57,  8.27s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 5:  53%|█████▎    | 103/196 [14:02<12:56,  8.35s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 5:  53%|█████▎    | 103/196 [14:11<12:56,  8.35s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 5:  53%|█████▎    | 104/196 [14:11<12:52,  8.39s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 5:  53%|█████▎    | 104/196 [14:19<12:52,  8.39s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 5:  54%|█████▎    | 105/196 [14:19<12:48,  8.44s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 5:  54%|█████▎    | 105/196 [14:28<12:48,  8.44s/it, training_loss=0.489]\u001b[A\n",
            "Epoch 5:  54%|█████▍    | 106/196 [14:28<12:39,  8.44s/it, training_loss=0.489]\u001b[A\n",
            "Epoch 5:  54%|█████▍    | 106/196 [14:36<12:39,  8.44s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 5:  55%|█████▍    | 107/196 [14:36<12:28,  8.41s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 5:  55%|█████▍    | 107/196 [14:44<12:28,  8.41s/it, training_loss=0.511]\u001b[A\n",
            "Epoch 5:  55%|█████▌    | 108/196 [14:44<12:18,  8.39s/it, training_loss=0.511]\u001b[A\n",
            "Epoch 5:  55%|█████▌    | 108/196 [14:53<12:18,  8.39s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 5:  56%|█████▌    | 109/196 [14:53<12:07,  8.36s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 5:  56%|█████▌    | 109/196 [15:01<12:07,  8.36s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 5:  56%|█████▌    | 110/196 [15:01<11:57,  8.35s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 5:  56%|█████▌    | 110/196 [15:09<11:57,  8.35s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 5:  57%|█████▋    | 111/196 [15:09<11:47,  8.32s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 5:  57%|█████▋    | 111/196 [15:17<11:47,  8.32s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 5:  57%|█████▋    | 112/196 [15:17<11:32,  8.25s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 5:  57%|█████▋    | 112/196 [15:26<11:32,  8.25s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 5:  58%|█████▊    | 113/196 [15:26<11:25,  8.26s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 5:  58%|█████▊    | 113/196 [15:34<11:25,  8.26s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 5:  58%|█████▊    | 114/196 [15:34<11:18,  8.27s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 5:  58%|█████▊    | 114/196 [15:42<11:18,  8.27s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 5:  59%|█████▊    | 115/196 [15:42<11:11,  8.29s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 5:  59%|█████▊    | 115/196 [15:51<11:11,  8.29s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 5:  59%|█████▉    | 116/196 [15:51<11:04,  8.30s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 5:  59%|█████▉    | 116/196 [15:59<11:04,  8.30s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 5:  60%|█████▉    | 117/196 [15:59<10:57,  8.32s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 5:  60%|█████▉    | 117/196 [16:07<10:57,  8.32s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 5:  60%|██████    | 118/196 [16:07<10:52,  8.36s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 5:  60%|██████    | 118/196 [16:16<10:52,  8.36s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 5:  61%|██████    | 119/196 [16:16<10:46,  8.40s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 5:  61%|██████    | 119/196 [16:24<10:46,  8.40s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 5:  61%|██████    | 120/196 [16:24<10:37,  8.39s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 5:  61%|██████    | 120/196 [16:33<10:37,  8.39s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 5:  62%|██████▏   | 121/196 [16:33<10:33,  8.44s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 5:  62%|██████▏   | 121/196 [16:41<10:33,  8.44s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 5:  62%|██████▏   | 122/196 [16:41<10:28,  8.50s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 5:  62%|██████▏   | 122/196 [16:50<10:28,  8.50s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 5:  63%|██████▎   | 123/196 [16:50<10:20,  8.50s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 5:  63%|██████▎   | 123/196 [16:58<10:20,  8.50s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 5:  63%|██████▎   | 124/196 [16:58<10:11,  8.50s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 5:  63%|██████▎   | 124/196 [17:07<10:11,  8.50s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 5:  64%|██████▍   | 125/196 [17:07<10:00,  8.46s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 5:  64%|██████▍   | 125/196 [17:15<10:00,  8.46s/it, training_loss=0.406]\u001b[A\n",
            "Epoch 5:  64%|██████▍   | 126/196 [17:15<09:49,  8.42s/it, training_loss=0.406]\u001b[A\n",
            "Epoch 5:  64%|██████▍   | 126/196 [17:23<09:49,  8.42s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  65%|██████▍   | 127/196 [17:23<09:34,  8.33s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  65%|██████▍   | 127/196 [17:31<09:34,  8.33s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 5:  65%|██████▌   | 128/196 [17:32<09:24,  8.30s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 5:  65%|██████▌   | 128/196 [17:40<09:24,  8.30s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 5:  66%|██████▌   | 129/196 [17:40<09:14,  8.28s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 5:  66%|██████▌   | 129/196 [17:48<09:14,  8.28s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 5:  66%|██████▋   | 130/196 [17:48<09:06,  8.27s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 5:  66%|██████▋   | 130/196 [17:56<09:06,  8.27s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 5:  67%|██████▋   | 131/196 [17:56<08:57,  8.26s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 5:  67%|██████▋   | 131/196 [18:04<08:57,  8.26s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 5:  67%|██████▋   | 132/196 [18:04<08:48,  8.26s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 5:  67%|██████▋   | 132/196 [18:13<08:48,  8.26s/it, training_loss=0.496]\u001b[A\n",
            "Epoch 5:  68%|██████▊   | 133/196 [18:13<08:39,  8.25s/it, training_loss=0.496]\u001b[A\n",
            "Epoch 5:  68%|██████▊   | 133/196 [18:21<08:39,  8.25s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 5:  68%|██████▊   | 134/196 [18:21<08:33,  8.28s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 5:  68%|██████▊   | 134/196 [18:29<08:33,  8.28s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 5:  69%|██████▉   | 135/196 [18:29<08:20,  8.21s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 5:  69%|██████▉   | 135/196 [18:37<08:20,  8.21s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 5:  69%|██████▉   | 136/196 [18:37<08:09,  8.16s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 5:  69%|██████▉   | 136/196 [18:45<08:09,  8.16s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 5:  70%|██████▉   | 137/196 [18:45<07:59,  8.13s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 5:  70%|██████▉   | 137/196 [18:53<07:59,  8.13s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 5:  70%|███████   | 138/196 [18:53<07:49,  8.10s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 5:  70%|███████   | 138/196 [19:01<07:49,  8.10s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 5:  71%|███████   | 139/196 [19:01<07:40,  8.08s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 5:  71%|███████   | 139/196 [19:09<07:40,  8.08s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 5:  71%|███████▏  | 140/196 [19:09<07:31,  8.06s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 5:  71%|███████▏  | 140/196 [19:17<07:31,  8.06s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 5:  72%|███████▏  | 141/196 [19:17<07:22,  8.04s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 5:  72%|███████▏  | 141/196 [19:25<07:22,  8.04s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 5:  72%|███████▏  | 142/196 [19:25<07:14,  8.04s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 5:  72%|███████▏  | 142/196 [19:33<07:14,  8.04s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 5:  73%|███████▎  | 143/196 [19:33<07:02,  7.97s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 5:  73%|███████▎  | 143/196 [19:41<07:02,  7.97s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 5:  73%|███████▎  | 144/196 [19:41<06:56,  8.01s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 5:  73%|███████▎  | 144/196 [19:49<06:56,  8.01s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 5:  74%|███████▍  | 145/196 [19:49<06:50,  8.04s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 5:  74%|███████▍  | 145/196 [19:57<06:50,  8.04s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 5:  74%|███████▍  | 146/196 [19:57<06:43,  8.06s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 5:  74%|███████▍  | 146/196 [20:06<06:43,  8.06s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 5:  75%|███████▌  | 147/196 [20:06<06:35,  8.06s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 5:  75%|███████▌  | 147/196 [20:14<06:35,  8.06s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 5:  76%|███████▌  | 148/196 [20:14<06:26,  8.05s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 5:  76%|███████▌  | 148/196 [20:22<06:26,  8.05s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 5:  76%|███████▌  | 149/196 [20:22<06:19,  8.07s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 5:  76%|███████▌  | 149/196 [20:30<06:19,  8.07s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 5:  77%|███████▋  | 150/196 [20:30<06:12,  8.09s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 5:  77%|███████▋  | 150/196 [20:38<06:12,  8.09s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 5:  77%|███████▋  | 151/196 [20:38<06:02,  8.05s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 5:  77%|███████▋  | 151/196 [20:46<06:02,  8.05s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 5:  78%|███████▊  | 152/196 [20:46<05:53,  8.05s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 5:  78%|███████▊  | 152/196 [20:54<05:53,  8.05s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 5:  78%|███████▊  | 153/196 [20:54<05:44,  8.02s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 5:  78%|███████▊  | 153/196 [21:02<05:44,  8.02s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 5:  79%|███████▊  | 154/196 [21:02<05:36,  8.02s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 5:  79%|███████▊  | 154/196 [21:10<05:36,  8.02s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 5:  79%|███████▉  | 155/196 [21:10<05:28,  8.01s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 5:  79%|███████▉  | 155/196 [21:18<05:28,  8.01s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 5:  80%|███████▉  | 156/196 [21:18<05:21,  8.03s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 5:  80%|███████▉  | 156/196 [21:26<05:21,  8.03s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 5:  80%|████████  | 157/196 [21:26<05:13,  8.03s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 5:  80%|████████  | 157/196 [21:34<05:13,  8.03s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 5:  81%|████████  | 158/196 [21:34<05:05,  8.04s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 5:  81%|████████  | 158/196 [21:42<05:05,  8.04s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 5:  81%|████████  | 159/196 [21:42<04:54,  7.96s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 5:  81%|████████  | 159/196 [21:50<04:54,  7.96s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 5:  82%|████████▏ | 160/196 [21:50<04:46,  7.95s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 5:  82%|████████▏ | 160/196 [21:58<04:46,  7.95s/it, training_loss=1.109]\u001b[A\n",
            "Epoch 5:  82%|████████▏ | 161/196 [21:58<04:37,  7.94s/it, training_loss=1.109]\u001b[A\n",
            "Epoch 5:  82%|████████▏ | 161/196 [22:06<04:37,  7.94s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 5:  83%|████████▎ | 162/196 [22:06<04:31,  7.97s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 5:  83%|████████▎ | 162/196 [22:14<04:31,  7.97s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 5:  83%|████████▎ | 163/196 [22:14<04:23,  7.99s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 5:  83%|████████▎ | 163/196 [22:22<04:23,  7.99s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 5:  84%|████████▎ | 164/196 [22:22<04:15,  7.99s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 5:  84%|████████▎ | 164/196 [22:30<04:15,  7.99s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 5:  84%|████████▍ | 165/196 [22:30<04:07,  7.97s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 5:  84%|████████▍ | 165/196 [22:37<04:07,  7.97s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 5:  85%|████████▍ | 166/196 [22:37<03:58,  7.95s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 5:  85%|████████▍ | 166/196 [22:45<03:58,  7.95s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 5:  85%|████████▌ | 167/196 [22:45<03:49,  7.90s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 5:  85%|████████▌ | 167/196 [22:53<03:49,  7.90s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 5:  86%|████████▌ | 168/196 [22:53<03:41,  7.89s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 5:  86%|████████▌ | 168/196 [23:01<03:41,  7.89s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 5:  86%|████████▌ | 169/196 [23:01<03:33,  7.89s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 5:  86%|████████▌ | 169/196 [23:09<03:33,  7.89s/it, training_loss=0.354]\u001b[A\n",
            "Epoch 5:  87%|████████▋ | 170/196 [23:09<03:24,  7.88s/it, training_loss=0.354]\u001b[A\n",
            "Epoch 5:  87%|████████▋ | 170/196 [23:17<03:24,  7.88s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 5:  87%|████████▋ | 171/196 [23:17<03:17,  7.90s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 5:  87%|████████▋ | 171/196 [23:25<03:17,  7.90s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 5:  88%|████████▊ | 172/196 [23:25<03:09,  7.92s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 5:  88%|████████▊ | 172/196 [23:33<03:09,  7.92s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 5:  88%|████████▊ | 173/196 [23:33<03:01,  7.91s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 5:  88%|████████▊ | 173/196 [23:41<03:01,  7.91s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 5:  89%|████████▉ | 174/196 [23:41<02:54,  7.92s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 5:  89%|████████▉ | 174/196 [23:48<02:54,  7.92s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 5:  89%|████████▉ | 175/196 [23:48<02:45,  7.88s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 5:  89%|████████▉ | 175/196 [23:56<02:45,  7.88s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 5:  90%|████████▉ | 176/196 [23:56<02:37,  7.88s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 5:  90%|████████▉ | 176/196 [24:04<02:37,  7.88s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 5:  90%|█████████ | 177/196 [24:04<02:30,  7.90s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 5:  90%|█████████ | 177/196 [24:12<02:30,  7.90s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 5:  91%|█████████ | 178/196 [24:12<02:22,  7.90s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 5:  91%|█████████ | 178/196 [24:20<02:22,  7.90s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 5:  91%|█████████▏| 179/196 [24:20<02:14,  7.92s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 5:  91%|█████████▏| 179/196 [24:28<02:14,  7.92s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 5:  92%|█████████▏| 180/196 [24:28<02:06,  7.92s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 5:  92%|█████████▏| 180/196 [24:36<02:06,  7.92s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 5:  92%|█████████▏| 181/196 [24:36<01:58,  7.92s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 5:  92%|█████████▏| 181/196 [24:44<01:58,  7.92s/it, training_loss=0.606]\u001b[A\n",
            "Epoch 5:  93%|█████████▎| 182/196 [24:44<01:50,  7.91s/it, training_loss=0.606]\u001b[A\n",
            "Epoch 5:  93%|█████████▎| 182/196 [24:52<01:50,  7.91s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 5:  93%|█████████▎| 183/196 [24:52<01:42,  7.89s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 5:  93%|█████████▎| 183/196 [25:00<01:42,  7.89s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 5:  94%|█████████▍| 184/196 [25:00<01:34,  7.90s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 5:  94%|█████████▍| 184/196 [25:07<01:34,  7.90s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 5:  94%|█████████▍| 185/196 [25:07<01:27,  7.92s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 5:  94%|█████████▍| 185/196 [25:15<01:27,  7.92s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 5:  95%|█████████▍| 186/196 [25:15<01:19,  7.92s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 5:  95%|█████████▍| 186/196 [25:23<01:19,  7.92s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 5:  95%|█████████▌| 187/196 [25:23<01:11,  7.93s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 5:  95%|█████████▌| 187/196 [25:31<01:11,  7.93s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 5:  96%|█████████▌| 188/196 [25:31<01:03,  7.94s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 5:  96%|█████████▌| 188/196 [25:39<01:03,  7.94s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 5:  96%|█████████▋| 189/196 [25:39<00:55,  7.93s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 5:  96%|█████████▋| 189/196 [25:47<00:55,  7.93s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 5:  97%|█████████▋| 190/196 [25:47<00:47,  7.92s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 5:  97%|█████████▋| 190/196 [25:55<00:47,  7.92s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 5:  97%|█████████▋| 191/196 [25:55<00:39,  7.91s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 5:  97%|█████████▋| 191/196 [26:03<00:39,  7.91s/it, training_loss=0.334]\u001b[A\n",
            "Epoch 5:  98%|█████████▊| 192/196 [26:03<00:31,  7.92s/it, training_loss=0.334]\u001b[A\n",
            "Epoch 5:  98%|█████████▊| 192/196 [26:11<00:31,  7.92s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 5:  98%|█████████▊| 193/196 [26:11<00:23,  7.93s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 5:  98%|█████████▊| 193/196 [26:19<00:23,  7.93s/it, training_loss=0.394]\u001b[A\n",
            "Epoch 5:  99%|█████████▉| 194/196 [26:19<00:15,  7.94s/it, training_loss=0.394]\u001b[A\n",
            "Epoch 5:  99%|█████████▉| 194/196 [26:27<00:15,  7.94s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 5:  99%|█████████▉| 195/196 [26:27<00:07,  7.98s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 5:  99%|█████████▉| 195/196 [26:30<00:07,  7.98s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 5: 100%|██████████| 196/196 [26:30<00:00,  6.53s/it, training_loss=0.014]\u001b[A\n",
            " 80%|████████  | 4/5 [2:20:24<28:42, 1722.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5\n",
            "Training loss: 0.38858945358886704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [2:21:48<00:00, 1701.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.7844776429235936\n",
            "F1 Score (Weighted): 0.7282464197232461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roVPOv6zInsG",
        "scrolled": false,
        "outputId": "b5dcda4b-30f1-4c53-b26c-5992f68364f9"
      },
      "source": [
        "#model = BertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\",#\"allenai/scibert_scivocab_uncased\", #\"bert-base-uncased\",\n",
        "#                                                      num_labels=len(label_dict),\n",
        "#                                                      output_attentions=False,\n",
        "#                                                      output_hidden_states=False)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-base\",#\"allenai/scibert_scivocab_uncased\", #\"bert-base-uncased\",\n",
        "                                                            num_labels=len(label_dict),\n",
        "                                                            output_attentions=False,\n",
        "                                                            output_hidden_states=False)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "W2YtAP_5InsI",
        "outputId": "ca51a931-a525-4168-96d6-7006f8940ee5"
      },
      "source": [
        "model.load_state_dict(torch.load('finetuned_BERT_epoch_5.model', map_location=torch.device('cuda')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-8376645e8fab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'finetuned_BERT_epoch_5.model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    605\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    880\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mrestore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[1;32m    136\u001b[0m                            \u001b[0;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                            \u001b[0;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxuefcj2InsK"
      },
      "source": [
        "_, predictions, true_vals = evaluate(dataloader_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU80BMwEInsN",
        "outputId": "1f685cc6-a9c4-4959-bae7-b174d5e14f81"
      },
      "source": [
        "accuracy_per_class(predictions, true_vals)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class: New Feature\n",
            "Accuracy: 34/34\n",
            "\n",
            "Class: Bug\n",
            "Accuracy: 0/35\n",
            "\n",
            "Class: Improvement\n",
            "Accuracy: 0/35\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dVIh5jsInsT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "034066b9-4a7b-4d2b-e5ad-3edafbb54131"
      },
      "source": [
        "# Clasificacion de New Feature\n",
        "a = df[['summary', 'type', 'data_type']]\n",
        "#print(a)\n",
        "filter1 = a[\"data_type\"]==\"val\"\n",
        "filter2 = a[\"type\"]==\"New Feature\"\n",
        "a.where(filter1 & filter2, inplace = True)\n",
        "b = a.dropna()\n",
        "print(b)\n",
        "b.to_csv('new_feature_val.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cd6d32b6a7df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Clasificacion de New Feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'summary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(a)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfilter1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfilter2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"New Feature\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "I2EODVms_GG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvCPDRBg94r7"
      },
      "source": [
        "def verify_modal_verb(text, model=nlp):\n",
        "    # Create doc object\n",
        "    doc = model(text)\n",
        "    modal = False\n",
        "\n",
        "    # Generate list of POS tags\n",
        "    for token in doc:\n",
        "        if token.text in ('can', 'could', 'may', 'might', 'shall', 'should', 'will', 'would', 'must') :\n",
        "           modal = True\n",
        "           break\n",
        "\n",
        "    pos = [token.pos_ for token in doc]\n",
        "    #print(pos)\n",
        "\n",
        "    # Return number of proper nouns\n",
        "    if pos.count('VERB') > 0 and modal == True :\n",
        "       return 1\n",
        "    else :\n",
        "       return 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdfnIuD9-epk",
        "outputId": "bf640af0-c1ce-4f6b-ebf8-4094fe61f32c"
      },
      "source": [
        "df1 = pd.read_csv('new_feature_val.csv')\n",
        "cont_good_class_nf = 0\n",
        "cont_bad_class_nf = 0\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    print(row['summary'])\n",
        "    print(verify_modal_verb(row['summary']))\n",
        "    row['summary'] = row['summary'].lower()\n",
        "\n",
        "    if verify_modal_verb(row['summary']) == 1:\n",
        "       cont_good_class_nf = cont_good_class_nf + 1\n",
        "    else:\n",
        "       cont_bad_class_nf = cont_bad_class_nf + 1\n",
        "\n",
        "print('Nro de regs bien clasificados NF: ', cont_good_class_nf)\n",
        "print('Nro de regs mal clasificados NF: ', cont_bad_class_nf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "other properties  expose properties  expose properties in storyreporterbuilder\n",
            "0\n",
            "screencast com  click story name  \n",
            "0\n",
            "dallas geeknight  add crossreference report  \n",
            "0\n",
            "story timeout  allow configuration is via embeddercontrols allow configuration of storytimeoutinsecs\n",
            "0\n",
            "  provide extension  provide extension of embeddercontrols\n",
            "0\n",
            "composite step   executing of sub steps \n",
            "0\n",
            "generic parameter converter generic parameter converter for enum classes convert enum fields  \n",
            "0\n",
            "dependency injection support for weld context framework provide support  provide support for cdi context injection\n",
            "0\n",
            " override of embedder methods add extension  add extension of embedder\n",
            "0\n",
            "annotated embedder  run stories run with embedder goal run stories with annotated embedder\n",
            "0\n",
            "  organise stories  \n",
            "0\n",
            "afterstories xml  break plugin afterstories xml  have invalid xml on occasion\n",
            "0\n",
            "storyreporter calls m opening browsers in saucelabs need way  \n",
            "0\n",
            "  load resources  have loadfromclasspath as default resourceloader\n",
            "0\n",
            "pending annotation  provide pending annotation  \n",
            "0\n",
            "null entries  specifying meta filters  \n",
            "0\n",
            "  enqueue stories  \n",
            "0\n",
            "utility methods  using matcherassert depend on unit framework assertions \n",
            "0\n",
            " line in multiline steps require space work without space require space before new line\n",
            "0\n",
            "  have multiple scenarios  have multiple scenarios in story\n",
            "0\n",
            "  have many scenarios  see output from broken scenarios\n",
            "0\n",
            "stack issue  improve regex suffer from regex provide alternative implementation of scenario parser\n",
            "0\n",
            "custom converters custom converters as developer provide converters convert from string \n",
            "0\n",
            "file paths  viewing fails use for separator normalising paths viewing fails on windows\n",
            "0\n",
            " aliases for steps introduce aliases  introduce aliases for steps\n",
            "0\n",
            "  has narrative  \n",
            "0\n",
            "pending steps  break build  break build with pending steps\n",
            "0\n",
            "unarchived files  compress test moving to commons \n",
            "0\n",
            "natural order  support scenario templates  \n",
            "0\n",
            "story titles  has title  see title in output\n",
            "0\n",
            "utility class steps from classpath look resources keeping with dry principle look resources in scenario\n",
            "0\n",
            "  add monitoring  allow monitoring of runtime events\n",
            "0\n",
            "  generate stepdoc  generate stepdoc from annotated methods\n",
            "0\n",
            "w w z regexp in dollarsteppatternbuilder have chars allows for empty markers have chars of length\n",
            "0\n",
            "data file  need tmpdir  need tmpdir as upload directory\n",
            "0\n",
            "archive content  view actual contents viewing of unarchived file contents view actual contents of unarchived files\n",
            "0\n",
            "newline escape  has wrong order  has wrong order of line separator\n",
            "0\n",
            "based storyloader based storyloader as story developer load stories  load stories via urls\n",
            "0\n",
            "file name cellswith with neighbours find scenarios  find scenarios with numbers\n",
            "0\n",
            "jbehave code  improve javadocs  \n",
            "0\n",
            "systems e path of tmpdir using relative paths  \n",
            "0\n",
            "candidatesteps interface  candidatesteps interface  allow composition over inheritance\n",
            "0\n",
            "real parameter names real parameter names via paranamer jbehave   \n",
            "0\n",
            "multi scenario beforescenario as developer reset state  reset state after scenario\n",
            "0\n",
            "same title  title scenarios appear in output title scenarios before scenario\n",
            "0\n",
            "    \n",
            "0\n",
            "undoable steps  set context set up context \n",
            "0\n",
            "available source  find test 's in jar \n",
            "0\n",
            "consistent adopt consistent adopt with convention specify build specification  \n",
            "0\n",
            "groovy bindings groovy bindings for adriano bonat thoughtworker invoking step methods  \n",
            "0\n",
            "  allow filtering  allow filtering of stories\n",
            "0\n",
            "step creation creation concern from steps stepcreator creation concern  stepcreator creation concern from steps\n",
            "0\n",
            "webdriver api support for webdriver api add support  add support for webdriver api\n",
            "0\n",
            "givenstory finishes  execute scenarios  execute scenarios within story\n",
            "0\n",
            " newlines between rows fix rendering  fix rendering of newlines\n",
            "0\n",
            "support htmlunit support htmlunit in propertywebdriverprovider add browser enum html  support htmlunitwebdriver via value html\n",
            "0\n",
            "pluggable strategy  resolve file paths  resolve file paths for directory\n",
            "0\n",
            "different names  add selenium webdriversteps capture upon failing scenario add instances of selenium webdriversteps\n",
            "0\n",
            "usingguice pico   be via annotations \n",
            "0\n",
            "webdriver instance  extending separate method  \n",
            "0\n",
            "rename embeddedstory flag name of boolean flag supports running givenstories  avoid confusion with storyembedder\n",
            "0\n",
            "common use case  find paths add to storyfinder method find paths by url code location\n",
            "0\n",
            "story name story name in report sells stocks  \n",
            "0\n",
            "maven goals  requires explicit annotation requiresdependencyresolution  resolve dependencies in abstractembeddermojo\n",
            "0\n",
            "grammer definition  details availability is in real terms \n",
            "0\n",
            "  running givenstory behaviour  \n",
            "0\n",
            "  add configurable sorting strategies  add configurable sorting strategies for stories\n",
            "0\n",
            "confusion change terminology of report view generation rendering to stories \n",
            "0\n",
            "getter setter getter setter for filepathresolver add getter setter missing from springstoryreporterbuilder add getter setter for filepathresolver\n",
            "0\n",
            " declaration of abstract beans instantiate spring  \n",
            "0\n",
            "significant digits  makes type representation fails for numbers makes type representation like e\n",
            "0\n",
            "default json  add format json format  \n",
            "0\n",
            "  have complex scenarios  have complex scenarios with use\n",
            "0\n",
            "zh cn properties with keywords map add support  add support for simplified chinese locale\n",
            "0\n",
            "  perform manipulations  \n",
            "0\n",
            "default value  changing value separator  changing value separator of jbehave\n",
            "0\n",
            "  provide default constructor  \n",
            "0\n",
            "date formats configurable formats for value types   \n",
            "0\n",
            "html output    \n",
            "0\n",
            "  provide default values  provide default values for separators instantiation\n",
            "0\n",
            "russian keywords support for russian locale add support  add support for russian locale\n",
            "0\n",
            "specified delegate  add storynameresolver iterates through configurable number \n",
            "0\n",
            "story level  contains scenarios  \n",
            "0\n",
            "  close storydurations  \n",
            "0\n",
            "own threadlocal stuff    \n",
            "0\n",
            "custom implementations custom implementations of metamatcher setup custom  \n",
            "0\n",
            "snapshots releases  use local nexus work around https issues \n",
            "0\n",
            "cross reference  add start  see start of stories scenarios\n",
            "0\n",
            "  annotation requirement analysts  annotation requirement analysts at company\n",
            "0\n",
            "results problem  add flaky status  \n",
            "0\n",
            " map of story sauce urls  \n",
            "0\n",
            "filter code  have story elements filtering on story elements \n",
            "0\n",
            "interop saucelabs  improve saucelabs settings be by system property \n",
            "0\n",
            "web interface  manage run context submit in background multiple stories manage run context of multiple stories\n",
            "0\n",
            "scenario title  parse scenario title works on other platforms \n",
            "0\n",
            "  add saucelabs contextview  \n",
            "0\n",
            "  have separate plugins  track different versions of tools\n",
            "0\n",
            "saucelabs saucelabs   robustness around job timeout \n",
            "0\n",
            "non spring  fix typos  fix typos in archetypes\n",
            "0\n",
            "  ignoring failures  ignoring failures in stories reports\n",
            "0\n",
            "step failures  view generation  cause build failure in view generation\n",
            "0\n",
            "jbehave story cancellations  add keywords  add keywords for story cancellation\n",
            "0\n",
            "flashdriver javascript    \n",
            "0\n",
            "templateable output  provide xml similar template  \n",
            "0\n",
            "httpcommandexecutor wrapcommandexecutor httpcommandexecutor wrapping of selenium commandexecutor implement following httpcommandexecutor httpcommandexecutor  implement following httpcommandexecutor httpcommandexecutor in saucelabs provider\n",
            "0\n",
            "oo separation format as factory kill format class is as result \n",
            "0\n",
            "fatal outcome  avoid outcome runtime exceptions play with ci systems \n",
            "0\n",
            " support with annotation support e g  support e g with tag\n",
            "0\n",
            "cross reference  add standalone reference navigator  allows navigation of report output\n",
            "0\n",
            "long start calculation of stories   \n",
            "0\n",
            "  support alternative narrative syntax  \n",
            "0\n",
            "formatting table  transformer tabletransformer according to max width \n",
            "0\n",
            "story editor   work in editor spell checking \n",
            "0\n",
            "  add jirametamatcher  \n",
            "0\n",
            "org jbehave  has afterstep method  \n",
            "0\n",
            "normal scenario story in file using givenstories  running scenario with givenstories\n",
            "0\n",
            " steps by meta filter allow matching  allow matching of lifecycle\n",
            "0\n",
            "command ctlr add for selected formatting text formatting ctlr f  \n",
            "0\n",
            "failinguponpendingsteps strategy  run story jbehave exits work in version \n",
            "0\n",
            "  support custom implementations  support custom implementations of meta\n",
            "0\n",
            " support in turn upgrade selenium version  using jbehave web with selenium\n",
            "0\n",
            "other view types  support configurable multiple view types  \n",
            "0\n",
            " value for timeout  run without timeout \n",
            "0\n",
            "polish language    \n",
            "0\n",
            "text changes plugin for next version   \n",
            "0\n",
            "java doc  add documented annotation  containing annotated strings with test steps\n",
            "0\n",
            "finnish language  support finnish language translations  \n",
            "0\n",
            "upgrade story navigator upgrade story navigator to new xref storynavigator has anything  \n",
            "0\n",
            "odf unit   tests for odf fail \n",
            "0\n",
            "new wizard  create eclipse category  create eclipse category for jbehave\n",
            "0\n",
            "actual tag correct span for parameters contains few encoded html tags  \n",
            "0\n",
            "junit tests read from file results  linefeed on read line \n",
            "0\n",
            "localised story locale of given story allow specification allowing for story parsing allow specification of locale\n",
            "0\n",
            "misspelled xmltemplateouput  breaking current user code  \n",
            "0\n",
            "java u noclassdeffounderror in java  compiling with u results \n",
            "0\n",
            "eclipse plugin  installing new m e plugin  \n",
            "0\n",
            "textual stories  parsing story transformation  \n",
            "0\n",
            "running time  provide configurable timeout value  provide configurable timeout value for story\n",
            "0\n",
            "failinguponpendingstep strategy   work on case patch \n",
            "0\n",
            "template reports  contains special chars  contains special chars with html template code\n",
            "0\n",
            "class gherkinstoryparser  has sysout  has system near end\n",
            "0\n",
            "src test files in reporters reports   \n",
            "0\n",
            "jbehave website  needs facelifting need  update jbehave website from buildmaster\n",
            "0\n",
            "  add cglib support  add cglib support to jmock extension\n",
            "0\n",
            "behaviour discovery  discover behaviours  \n",
            "0\n",
            "velocity code generator velocity code generator for story generates classes  generates classes for given story\n",
            "0\n",
            "ant task   talk about specs \n",
            "0\n",
            "svn svn   url on website \n",
            "0\n",
            "cglib mock  integrate usingjmock  \n",
            "0\n",
            "  add dependencies  core declare dependencies in core pom\n",
            "0\n",
            "  needs intellij plugin  begin work on intellij\n",
            "0\n",
            "story code  add mojo  run generate code goal from given story\n",
            "0\n",
            "  calling usingmatchers  calling usingmatchers of usingmatchers\n",
            "0\n",
            "appropriate pattern  using narrateto  \n",
            "0\n",
            " method of same name stub method  stub method with arguments\n",
            "0\n",
            "jbehave core codebase for jbehave core   \n",
            "0\n",
            "document junitadapter document junitadapter on website use excellent eclipse hack  run current behaviour class under cursor\n",
            "0\n",
            "broken links broken links in website has couple  has couple of broken links\n",
            "0\n",
            "minute intro minute intro for jbehave needs work  needs good update before release\n",
            "0\n",
            "world keys  use enums think of reason allowing strings as world keys\n",
            "0\n",
            "scenario steps  throw exception  throw exception in signature\n",
            "0\n",
            "build script  running behaviours times picking up allbehaviours \n",
            "0\n",
            "good idea  visit outcome expectations  visit outcome expectations from scenario\n",
            "0\n",
            "non failure framework error like missing behaviour class return failure status use in batch environment \n",
            "0\n",
            "refactor storyloader  throw runtime class instantiation  \n",
            "0\n",
            "  throwing pending exception  throwing pending exception in story component\n",
            "0\n",
            "method invocation  specifying invocation expectations fail upon matched method expecations \n",
            "0\n",
            "unspecified call  fail unmatched calls waiting for verification \n",
            "0\n",
            "integration acceptance junit to behaviour test converter facilitate conversion  facilitate conversion of acceptance tests\n",
            "0\n",
            "website generator  using old api work with new buildmaster using old api for buildmaster\n",
            "0\n",
            "  add root package  generate code from story text file\n",
            "0\n",
            "jbehave maven plugin jbehave maven plugin as jbehave user type mvn jbehave  verify behaviours of system\n",
            "0\n",
            "multiple stories  includes patterns  \n",
            "0\n",
            "story parser    \n",
            "0\n",
            "plugin spanish language  add spanish language  \n",
            "0\n",
            "create project create project from archetype take standard sample story  \n",
            "0\n",
            "story execution  add configurable flag  add configurable flag in embeddercontrols\n",
            "0\n",
            "lifecycle story lifecycle in story syntax add support  add support for scenario\n",
            "0\n",
            "  use delegating model  \n",
            "0\n",
            "  add enum converters  \n",
            "0\n",
            "ignore annotation  ignores ignore annotation  \n",
            "0\n",
            " export via rest providing includes pattern export via rest \n",
            "0\n",
            "meta info gherkin  add meta tag support  provides support for tags\n",
            "0\n",
            "rest providers  add name defaulting to strategy resolving strategy for rest resources\n",
            "0\n",
            "running embeddables failures in view ignore failures  ignore failures in view\n",
            "0\n",
            "  match filters  \n",
            "0\n",
            "ignore comments ignore comments in meta jenkins  finding during transform xunit plugin \n",
            "0\n",
            "com tanob    \n",
            "0\n",
            "system properties  missing specification  missing specification of system properties\n",
            "0\n",
            "ignorable steps  generate methods  generate methods for ignorable steps\n",
            "0\n",
            "beforestories xml  causing xunit  \n",
            "0\n",
            "  starting scenario  \n",
            "0\n",
            "other way scenarios after example add support  add support for annotated steps\n",
            "0\n",
            "table parameters    \n",
            "0\n",
            "public void  throw new knownfailure corba failing without stack trace \n",
            "0\n",
            "story scenario poor version of jbehave accept parameters  have bq void mybeforestory at moment\n",
            "0\n",
            "  add failed step  add failed step as uuidexceptionwrapper message\n",
            "0\n",
            "swf object  supports invocation  supports invocation of object methods\n",
            "0\n",
            "annotated embedder   running in cli \n",
            "0\n",
            "field cause instances of printstreamoutput   \n",
            "0\n",
            "wrapped outcomesfailed exception    \n",
            "0\n",
            "multiline scenario  follows keyword scenario is over multiple lines \n",
            "0\n",
            "  defining step  \n",
            "0\n",
            "methods post  executing long scenarios  \n",
            "0\n",
            "  add stepfinder  avoid duplication of steps\n",
            "0\n",
            "table examplestable java  trailing whitespaces  \n",
            "0\n",
            "non html  rendering html reports  \n",
            "0\n",
            "candidate step  steps needs  \n",
            "0\n",
            "builder syntax builder syntax for story stepsconfiguration  make for reading \n",
            "0\n",
            "separate step pattern  produces stepmatcher parsing from matching \n",
            "0\n",
            "matched method  add method information  add method information to matching events\n",
            "0\n",
            "double nan  throws parseexception be into double nan \n",
            "0\n",
            "step configuration  improve documentation  improve documentation on scenario\n",
            "0\n",
            "starting words  starting words  \n",
            "0\n",
            "  scenarioreporter scenario reporter  \n",
            "0\n",
            " refactors in story configuration running stories  \n",
            "0\n",
            "maven ant maven ant execution of scenario provide exception fails with classloader \n",
            "0\n",
            "based configuration  allow based configuration annotations  \n",
            "0\n",
            "scenario level selenium under jbehave control  be at story \n",
            "0\n",
            "jbehave web selenium    \n",
            "0\n",
            "output scenario  handle parametrised scenarios reset at execution \n",
            "0\n",
            "beforestep method beforestep method in storyreporter add beforestep method  add beforestep method in storyreporter\n",
            "0\n",
            "support spring annotationconfigapplicationcontext patch for jbehave spring allows based spring configurations  allows based spring configurations for java annotation\n",
            "0\n",
            "numberformat instance numberformat instance in parameterconverters   \n",
            "0\n",
            "freemarker templateprocessor  load custom template loading in order specify different class for template loading\n",
            "0\n",
            "story level  require scenario  \n",
            "0\n",
            "Nro de regs bien clasificados NF:  0\n",
            "Nro de regs mal clasificados NF:  226\n"
          ]
        }
      ]
    }
  ]
}